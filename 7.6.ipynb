{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rucci Emanuele 2053183 - Elective in AI\n",
    "Project description: create an efficient classifier based on autoencoder applied on EEG signal\n",
    "\n",
    "https://github.com/syorami/Autoencoders-Variants/tree/master\n",
    "\n",
    "https://github.com/alemme/pytorch-nnsae/blob/master/NNSAE.py\n",
    "\n",
    "This file contains the set of experiments dedicated to the extracted features of the dataset: discard the information related to the trials and keep only the information related to the task (the movements performed by the subject)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch_lightning --quiet\n",
    "!pip install wandb --quiet\n",
    "!pip install pandas --quiet\n",
    "!pip install numpy --quiet\n",
    "!pip install scikit-learn --quiet\n",
    "!pip install matplotlib --quiet\n",
    "!pip install seaborn --quiet\n",
    "!pip install info-nce-pytorch --quiet #https://github.com/RElbers/info-nce-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import wandb\n",
    "import pprint\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from info_nce import InfoNCE, info_nce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1372dd6b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reproducibility\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "dataset_base_path = \"Dataset/Extracted_features/\"\n",
    "project_base_path = \"/\"\n",
    "dataset_path_list = [\n",
    "    'dataset_task_1.csv', # Task 1\n",
    "    'dataset_task_2.csv', # Task 2\n",
    "    'dataset_task_3.csv', # Task 3\n",
    "    'dataset_task_4.csv', # Task 4\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "window_size = 1 # size of the window to consider when selecting a sample, then a sample will be composed of window_size rows\n",
    "enable_wandb = False\n",
    "\n",
    "# Definition of an utity object that divides the dataset files according to the task they belong to\n",
    "dataset_task_mapping = {}\n",
    "dataset_task_mapping['task_1'] = []\n",
    "\n",
    "# Task 1\n",
    "task_1_file_index = [0]\n",
    "for index in task_1_file_index:\n",
    "    dict_file = {}\n",
    "    dict_file['file_path'] = os.path.join(dataset_base_path, dataset_path_list[index])\n",
    "    #file_name\n",
    "    dict_file['file_name'] = dataset_path_list[index].split(\"/\")[-1]\n",
    "    #remove the extension\n",
    "    dict_file['file_name'] = dict_file['file_name'].split(\".\")[0]\n",
    "    dataset_task_mapping['task_1'].append(dict_file)\n",
    "\n",
    "# Task 2\n",
    "dataset_task_mapping['task_2'] = []\n",
    "task_2_file_index = [1]\n",
    "for index in task_2_file_index:\n",
    "    dict_file = {}\n",
    "    dict_file['file_path'] = os.path.join(dataset_base_path, dataset_path_list[index])\n",
    "    dict_file['file_name'] = dataset_path_list[index].split(\"/\")[-1]\n",
    "    dict_file['file_name'] = dict_file['file_name'].split(\".\")[0]\n",
    "    dataset_task_mapping['task_2'].append(dict_file)\n",
    "\n",
    "# Task 3\n",
    "dataset_task_mapping['task_3'] = []\n",
    "task_3_file_index = [2]\n",
    "for index in task_3_file_index:\n",
    "    dict_file = {}\n",
    "    dict_file['file_path'] = os.path.join(dataset_base_path, dataset_path_list[index])\n",
    "    dict_file['file_name'] = dataset_path_list[index].split(\"/\")[-1]\n",
    "    dict_file['file_name'] = dict_file['file_name'].split(\".\")[0]\n",
    "    dataset_task_mapping['task_3'].append(dict_file)\n",
    "\n",
    "# Task 4\n",
    "dataset_task_mapping['task_4'] = []\n",
    "task_4_file_index = [3]\n",
    "for index in task_4_file_index:\n",
    "    dict_file = {}\n",
    "    dict_file['file_path'] = os.path.join(dataset_base_path, dataset_path_list[index])\n",
    "    dict_file['file_name'] = dataset_path_list[index].split(\"/\")[-1]\n",
    "    dict_file['file_name'] = dict_file['file_name'].split(\".\")[0]\n",
    "    dataset_task_mapping['task_4'].append(dict_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2\n",
    "This is to address the study: \"**Observe the performance of a general model that can be used to identify states across all the tasks.**\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetApproach2(Dataset):\n",
    "  def __init__(self, window_size=1):\n",
    "    self.dataset = pd.DataFrame()\n",
    "\n",
    "    # Create a unique dataframe that is composed by the concatenation of all the files that belong to the task\n",
    "    tasks_name = ['task_1','task_2','task_3','task_4']\n",
    "    for task_name in tasks_name:\n",
    "      for file in dataset_task_mapping[task_name]:\n",
    "        df = pd.read_csv(file['file_path'])\n",
    "        # Concatenate the dataframes by rows but remove the first row\n",
    "        df = df.iloc[1:]\n",
    "        self.dataset = pd.concat([self.dataset, df], ignore_index=True)\n",
    "\n",
    "    print(f\"Concatenating the dataframes ({len(self.dataset)})\")\n",
    "    print(f\"Dataset shape: {self.dataset.shape}\")\n",
    "\n",
    "    # Windowing\n",
    "    self.window_size = window_size\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset) - self.window_size\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # return as a tensor\n",
    "    print(f\"Index: {idx}\")\n",
    "    return torch.tensor(self.dataset.iloc[idx].values)\n",
    "\n",
    "  def get_dataframe(self):\n",
    "    return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating the dataframes (1953)\n",
      "Dataset shape: (1953, 71)\n"
     ]
    }
   ],
   "source": [
    "dataset = DatasetApproach2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating the dataframes (1953)\n",
      "Dataset shape: (1953, 71)\n",
      "Dataset length: 1952, Number of files used (Task 1: 1 + Task 2: 1 + Task 3: 1 + Task 4: 1)\n",
      "Unique values of the labels: [1 2 3 4]\n",
      "Data: 1953 ,Train size: 1411, Val size: 249, Test size: 293\n"
     ]
    }
   ],
   "source": [
    "dataset = DatasetApproach2()\n",
    "print(f\"Dataset length: {len(dataset)}, Number of files used (Task 1: {len(dataset_task_mapping['task_1'])} + Task 2: {len(dataset_task_mapping['task_2'])} + Task 3: {len(dataset_task_mapping['task_3'])} + Task 4: {len(dataset_task_mapping['task_4'])})\")\n",
    "# Unique values of the labels from the last column of the dataset\n",
    "print(f\"Unique values of the labels: {dataset.get_dataframe().iloc[:,-1].unique()}\")\n",
    "\n",
    "# Shuffle the rows of the dataset using sklearn (making sure the shuffle is reproducible)\n",
    "from sklearn.utils import shuffle\n",
    "data = shuffle(dataset.get_dataframe(), random_state=0)\n",
    "# Remove the index column\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Splitting into train and test sets (80% training data, 20% testing data)\n",
    "train_df, test_df = train_test_split(data, test_size=0.15, random_state=42)\n",
    "\n",
    "# Splitting the train_df further into train and validation sets (70% training data, 30% validation data)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.15, random_state=42)\n",
    "\n",
    "print(f\"Data: {len(data)} ,Train size: {len(train_df)}, Val size: {len(val_df)}, Test size: {len(test_df)}\")\n",
    "\n",
    "\n",
    "#Create the Dataframe classe Approach 2\n",
    "class DataFrameApproach2(Dataset):\n",
    "    def __init__(self, dataframe, selected_columns=None):\n",
    "        # Set as data the columns from the parameter selected_columns if are passed, otherwise set all the columns except the last one\n",
    "        if selected_columns:\n",
    "            self.data = dataframe.iloc[:, selected_columns].values\n",
    "        else:\n",
    "            self.data = dataframe.iloc[:, :-1].values\n",
    "\n",
    "        self.targets = dataframe.iloc[:, -1].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.data[idx])\n",
    "        y = self.targets[idx]\n",
    "        return x, y\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "\n",
    "    # Apply min-max normalization to each column\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(data)\n",
    "\n",
    "    return torch.tensor(normalized_data), targets\n",
    "\n",
    "# Creating datasets and data loaders for each split\n",
    "selected_columns = [17,18,19,52,53,54]\n",
    "train_dataset = DataFrameApproach2(train_df, selected_columns)\n",
    "val_dataset = DataFrameApproach2(val_df, selected_columns)\n",
    "test_dataset = DataFrameApproach2(test_df, selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, window_size = 1, enable_sparsity_loss=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(128),\n",
    "        )\n",
    "\n",
    "        # Apply He initialization to the linear layers\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, input_dim = x.size()  # Obtain the shape of the input [bs, input_dim]\n",
    "        input = x\n",
    "        x = self.encoder(input)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, window_size, enable_sparsity_loss=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, window_size * input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Apply He initialization to the linear layers\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.to(torch.float32)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AE Lightning Module ⚡️⚡️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(LightningModule):\n",
    "    def __init__(self, input_dim, batch_size, sparsity_factor=0.1, sparsity_loss_coef = 1e-3, weight_decay=0.001, window_size=window_size, enable_sparsity_loss=False, enable_weight_decay_loss=False ,enable_non_negativity_constraint=False,enable_wandb = False):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        if( enable_sparsity_loss == True and enable_non_negativity_constraint== True):\n",
    "          print(\"The combination of constraints enable_sparsity_loss and enable_non_negativity_constraint both true leads to error in to the model matrix multiplication. This will be solved by setting enable_non_negativity_constraint to False.\")\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.encoder = Encoder(input_dim=input_dim, window_size=window_size, enable_sparsity_loss = enable_sparsity_loss)\n",
    "        self.decoder = Decoder(input_dim=input_dim, window_size=window_size, enable_sparsity_loss = enable_sparsity_loss)\n",
    "        self.train_loss_memory = []\n",
    "        self.train_rec_loss_memory = []\n",
    "\n",
    "        self.val_loss_memory = []\n",
    "        self.val_rec_loss_memory = []\n",
    "\n",
    "        self.test_loss_memory = []\n",
    "        self.test_rec_loss_memory = []\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "\n",
    "\n",
    "        # --- Loss Settings\n",
    "        self.enable_sparsity_loss = enable_sparsity_loss\n",
    "        if enable_sparsity_loss:\n",
    "          self.sparsity_loss_coef = sparsity_loss_coef\n",
    "          self.sparsity_factor = sparsity_factor\n",
    "          print(f\"Enabled Sparsity term in the loss with sparsity loss coeff => {self.sparsity_loss_coef} and sparsity factor=>{self.sparsity_factor}\")\n",
    "\n",
    "          # self.sparsity_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "          # Memory logs for sparsity\n",
    "          self.train_sparsity_loss_memory = []\n",
    "          self.val_sparsity_loss_memory = []\n",
    "          self.test_sparsity_loss_memory = []\n",
    "\n",
    "          self.enable_non_negativity_constraint = False\n",
    "        else:\n",
    "          self.enable_non_negativity_constraint = enable_non_negativity_constraint\n",
    "          if enable_non_negativity_constraint:\n",
    "            print(\"Enabled non negativity constraint\")\n",
    "\n",
    "\n",
    "        self.enable_weight_decay_loss = enable_weight_decay_loss\n",
    "        if enable_weight_decay_loss:\n",
    "          print(\"Enabled weight decay\")\n",
    "          self.weight_decay = weight_decay\n",
    "\n",
    "        self.wandb_log = enable_wandb\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        if torch.cuda.is_available():\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                device = torch.device('cuda:0')\n",
    "                print('Using device:', device)\n",
    "            else:\n",
    "                device = torch.device('cuda')\n",
    "                print('Using device:', device)\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "            print('Using device:', device)\n",
    "\n",
    "\n",
    "        print('Using device:', device)\n",
    "\n",
    "        self.to(device)\n",
    "        print(f\"Initialized Model on {self.device}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "    def kl_div(self, p, p_hat):\n",
    "      funcs = nn.Sigmoid()\n",
    "      p_hat = torch.mean(funcs(p_hat), 1)\n",
    "      p_tensor = torch.Tensor([p] * p_hat.shape[0]).to(self.device)\n",
    "\n",
    "\n",
    "      return torch.sum(p_tensor * torch.log(p_tensor) - p_tensor * torch.log(p_hat) + (1 - p_tensor) * torch.log(1 - p_tensor) - (1 - p_tensor) * torch.log(1 - p_hat))\n",
    "\n",
    "    def sparse_loss(self, values):\n",
    "      loss = 0\n",
    "      values = values.view(self.batch_size, -1)\n",
    "\n",
    "      # Encoder sparsity\n",
    "      lyrs_encoder = list(self.encoder.encoder.children())\n",
    "      for i, lyr in enumerate(lyrs_encoder):\n",
    "          if isinstance(lyr, nn.Linear):\n",
    "            values = lyr(values)\n",
    "            # loss += self.sparsity_loss(torch.tensor([self.sparsity_factor]).to(self.device), values.to(self.device))\n",
    "            loss += self.kl_div(self.sparsity_factor, values.to(self.device))\n",
    "\n",
    "      # Decoder sparsity\n",
    "      lyrs_decoder = list(self.decoder.decoder.children())\n",
    "      for i, lyr in enumerate(lyrs_decoder):\n",
    "          if isinstance(lyr, nn.Linear):\n",
    "              values = lyr(values)\n",
    "              # loss += self.sparsity_loss(torch.tensor([self.sparsity_factor]).to(self.device), values.to(self.device))\n",
    "              loss += self.kl_div(self.sparsity_factor, values.to(self.device))\n",
    "\n",
    "      return loss\n",
    "\n",
    "    def calculate_weight_decay_loss(self):\n",
    "        weight_decay_loss = 0.0\n",
    "        for param in self.parameters():\n",
    "            weight_decay_loss += 0.5 * self.weight_decay * torch.norm(param, p=2) ** 2\n",
    "        return weight_decay_loss\n",
    "\n",
    "    def enforce_non_negativity(self):\n",
    "      for param in self.parameters():\n",
    "        param.data.clamp_(min=0, max=None)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch[0].to(torch.float32) #[bs, input_dim]\n",
    "        _, reconstructions = self(x)\n",
    "\n",
    "        x = x.view(-1) # [bs * input_dim]\n",
    "        reconstructions = reconstructions.view(-1)\n",
    "\n",
    "        loss_mse = nn.MSELoss()(reconstructions, x)\n",
    "        loss = loss_mse\n",
    "\n",
    "        if self.enable_sparsity_loss:\n",
    "          # sparsity_loss = self.sparsity_loss(torch.log(reconstructions).to(self.device), torch.tensor([self.sparsity_factor]).to(self.device))\n",
    "          sparsity_loss = self.sparse_loss(x) * self.sparsity_loss_coef\n",
    "          loss += sparsity_loss\n",
    "          self.train_sparsity_loss_memory.append(sparsity_loss)\n",
    "\n",
    "        if self.enable_weight_decay_loss:\n",
    "          weight_decay_loss = self.calculate_weight_decay_loss()\n",
    "          loss += weight_decay_loss\n",
    "\n",
    "        self.train_loss_memory.append(loss)\n",
    "        self.train_rec_loss_memory.append(loss_mse)\n",
    "\n",
    "        if self.wandb_log:\n",
    "          wandb.log({\"train_total_loss\": loss})\n",
    "          wandb.log({\"train_reconstruction_loss\": loss_mse})\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "      x = batch[0].to(torch.float32)\n",
    "      _, reconstructions = self(x)\n",
    "\n",
    "      x = x.view(-1) #[]\n",
    "      reconstructions = reconstructions.view(-1)\n",
    "\n",
    "      loss_mse = nn.MSELoss()(reconstructions, x)\n",
    "      # For early stop and Model checkpoint callbacks\n",
    "      self.log(\"val_reconstruction_loss\",loss_mse)\n",
    "      \n",
    "      \n",
    "      \n",
    "      loss = loss_mse\n",
    "\n",
    "      if self.enable_sparsity_loss:\n",
    "        # sparsity_loss = self.sparsity_loss(torch.log(reconstructions).to(self.device), torch.tensor([self.sparsity_factor]).to(self.device))\n",
    "        sparsity_loss = self.sparse_loss(x) * self.sparsity_loss_coef\n",
    "        loss += sparsity_loss\n",
    "        self.val_sparsity_loss_memory.append(sparsity_loss)\n",
    "\n",
    "      if self.enable_weight_decay_loss:\n",
    "        weight_decay_loss = self.calculate_weight_decay_loss()\n",
    "        loss += weight_decay_loss\n",
    "\n",
    "      if self.enable_non_negativity_constraint:\n",
    "        self.enforce_non_negativity()\n",
    "\n",
    "\n",
    "      self.val_loss_memory.append(loss)\n",
    "      self.val_rec_loss_memory.append(loss_mse)\n",
    "      \n",
    "\n",
    "      if self.wandb_log:\n",
    "        wandb.log({\"val_total_loss\": loss})\n",
    "        wandb.log({\"val_reconstruction_loss\": loss_mse})\n",
    "\n",
    "      return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "      x = batch[0].to(torch.float32)\n",
    "      _, reconstructions = self(x)\n",
    "\n",
    "      x = x.view(-1) #[]\n",
    "      reconstructions = reconstructions.view(-1)\n",
    "\n",
    "      loss_mse = nn.MSELoss()(reconstructions, x)\n",
    "      loss = loss_mse\n",
    "\n",
    "      if self.enable_sparsity_loss:\n",
    "        # sparsity_loss = self.sparsity_loss(torch.log(reconstructions).to(self.device), torch.tensor([self.sparsity_factor]).to(self.device))\n",
    "        sparsity_loss = self.sparse_loss(x) * self.sparsity_loss_coef\n",
    "        loss += sparsity_loss\n",
    "        self.test_sparsity_loss_memory.append(sparsity_loss)\n",
    "\n",
    "      if self.enable_weight_decay_loss:\n",
    "        weight_decay_loss = self.calculate_weight_decay_loss()\n",
    "        loss += weight_decay_loss\n",
    "\n",
    "      if self.enable_non_negativity_constraint:\n",
    "        self.enforce_non_negativity()\n",
    "\n",
    "      self.test_loss_memory.append(loss)\n",
    "      self.test_rec_loss_memory.append(loss_mse)\n",
    "\n",
    "\n",
    "      return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=10)  # Adjust T_max as needed\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': {'scheduler': scheduler, 'interval': 'epoch'}}\n",
    "\n",
    "    def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_closure):\n",
    "        # step\n",
    "        optimizer.step(closure=optimizer_closure)\n",
    "\n",
    "        if self.enable_non_negativity_constraint:\n",
    "          self.enforce_non_negativity()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.wandb_log:\n",
    "            wandb.log({'epoch': self.current_epoch})\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # Access the training loss from the outputs\n",
    "        train_loss = torch.stack([x for x in self.train_loss_memory]).mean()\n",
    "        train_rec_loss = torch.stack([x for x in self.train_rec_loss_memory]).mean()\n",
    "\n",
    "        # Print the training loss\n",
    "        print_log = f'Training Loss - Epoch {self.current_epoch}: Total Loss => {train_loss.item()} MSE => {train_rec_loss}'\n",
    "\n",
    "        self.train_loss_memory.clear()\n",
    "        self.train_rec_loss_memory.clear()\n",
    "\n",
    "        if self.enable_sparsity_loss:\n",
    "          train_sparsity_loss = torch.stack([x for x in self.train_sparsity_loss_memory]).mean()\n",
    "          print_log += f' SPARSE => {train_sparsity_loss}'\n",
    "          self.train_sparsity_loss_memory.clear()\n",
    "\n",
    "        if self.wandb_log:\n",
    "          wandb.log({\"train_total_loss\": train_loss})\n",
    "          wandb.log({\"train_reconstruction_loss\": train_rec_loss})\n",
    "          if self.enable_sparsity_loss:\n",
    "            wandb.log({\"train_sparse_loss\": train_sparsity_loss})\n",
    "\n",
    "        print(print_log)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Access the training loss from the outputs\n",
    "        val_loss = torch.stack([x for x in self.val_loss_memory]).mean()\n",
    "        val_rec_loss = torch.stack([x for x in self.val_rec_loss_memory]).mean()\n",
    "\n",
    "        # Print the training loss\n",
    "        print_log = f'Validation Loss - Epoch {self.current_epoch}: Total Loss => {val_loss.item()} MSE => {val_rec_loss}'\n",
    "\n",
    "        self.val_loss_memory.clear()\n",
    "        self.val_rec_loss_memory.clear()\n",
    "\n",
    "        if self.enable_sparsity_loss:\n",
    "          val_sparsity_loss = torch.stack([x for x in self.val_sparsity_loss_memory]).mean()\n",
    "          print_log += f' SPARSE => {val_sparsity_loss}'\n",
    "          self.val_sparsity_loss_memory.clear()\n",
    "\n",
    "        if self.wandb_log:\n",
    "          wandb.log({\"val_total_loss\": val_loss})\n",
    "          wandb.log({\"val_reconstruction_loss\": val_rec_loss})\n",
    "          if self.enable_sparsity_loss:\n",
    "            wandb.log({\"val_sparse_loss\": val_sparsity_loss})\n",
    "\n",
    "        print(print_log)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # Access the training loss from the outputs\n",
    "        test_loss = torch.stack([x for x in self.test_loss_memory]).mean()\n",
    "        test_rec_loss = torch.stack([x for x in self.test_rec_loss_memory]).mean()\n",
    "\n",
    "        # Print the training loss\n",
    "        print_log = f'Test Loss - Epoch {self.current_epoch}: Total Loss => {test_loss.item()} MSE => {test_rec_loss}'\n",
    "\n",
    "        self.test_loss_memory.clear()\n",
    "        self.test_rec_loss_memory.clear()\n",
    "\n",
    "        if self.enable_sparsity_loss:\n",
    "          test_sparsity_loss = torch.stack([x for x in self.test_sparsity_loss_memory]).mean()\n",
    "          print_log += f' SPARSE => {test_sparsity_loss}'\n",
    "          self.test_sparsity_loss_memory.clear()\n",
    "\n",
    "        if self.wandb_log:\n",
    "          wandb.log({\"test_total_loss\": test_loss})\n",
    "          wandb.log({\"test_reconstruction_loss\": test_rec_loss})\n",
    "          if self.enable_sparsity_loss:\n",
    "            wandb.log({\"test_sparse_loss\": test_sparsity_loss})\n",
    "\n",
    "        self.test_rec_loss = test_rec_loss\n",
    "\n",
    "        print(print_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training: HPO with Wandb Sweeps 🔎🔎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WANDB Sweep for HPO\n",
    "sweep_config = {\n",
    "    'method': 'bayes'\n",
    "}\n",
    "metric = {\n",
    "  'name': 'val_reconstruction_loss',\n",
    "  'goal': 'minimize'\n",
    "}\n",
    "sweep_config['metric'] = metric\n",
    "sweep_config['group'] = \"approach_2_AutoEncoder_FeaturesDataset\"\n",
    "parameters_dict = {\n",
    "    'batch_size': {\n",
    "          'values': [64,128,256,512]\n",
    "        },\n",
    "    'epochs': {\n",
    "          'values': [1000]\n",
    "        },\n",
    "    'sparsity_factor': {\n",
    "        'values': [0.1, 0.05, 0.005]\n",
    "      },\n",
    "    'wdecay_loss':{\n",
    "        'values': [True,False]\n",
    "      },\n",
    "    'sparsity_loss':{\n",
    "        'values': [True,False]\n",
    "      },\n",
    "    'non_negative_constraint':{\n",
    "        'values': [True,False]\n",
    "      }\n",
    "}\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "\n",
    "#Create the sweep\n",
    "sweep_id = wandb.sweep(sweep_config,entity=\"rucci-2053183\", project=\"Project_EAI_BrainComputerInterface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "\n",
    "def train(config=None):\n",
    "  global i\n",
    "  with wandb.init(config=config):\n",
    "    i = i + 1\n",
    "    config = wandb.config\n",
    "    # access to the current attempt number from wandb\n",
    "    print(f\"Attempt number: {wandb.run.id}\")\n",
    "    if config.sparsity_loss == True and config.non_negative_constraint == True:\n",
    "      print(f\"Skipping following config becouse not supported combination sparsity_loss =>{config.sparsity_loss}, non_negative_constraint =>{config.non_negative_constraint}\")\n",
    "      print(f\"Config ==>{config}\")\n",
    "    else:\n",
    "      # bs given by the agent\n",
    "      train_dataset = DataFrameApproach2(train_df)\n",
    "      val_dataset = DataFrameApproach2(val_df)\n",
    "      test_dataset = DataFrameApproach2(test_df)\n",
    "      train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "      val_loader = DataLoader(val_dataset, batch_size=config.batch_size,shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "      test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "      batch = next(iter(train_loader))\n",
    "      input_dim = batch[0].shape[-1]\n",
    "\n",
    "      # Model\n",
    "      model = Autoencoder(input_dim=input_dim, batch_size = config.batch_size,sparsity_factor=config.sparsity_factor ,enable_sparsity_loss=config.sparsity_loss, enable_weight_decay_loss=config.wdecay_loss, enable_non_negativity_constraint=config.non_negative_constraint, enable_wandb = True)\n",
    "      early_stop = EarlyStopping(monitor=\"val_reconstruction_loss\", mode=\"min\", check_on_train_epoch_end=False)\n",
    "\n",
    "\n",
    "      # Define the ModelCheckpoint callback to save the best model\n",
    "      checkpoint_callback = ModelCheckpoint(\n",
    "          dirpath=\"saved_models/Approach_2_FeaturesDataset/ae/\"+str(i)+\"/\",\n",
    "          filename=\"best_model\",\n",
    "          monitor=\"val_reconstruction_loss\",\n",
    "          mode=\"min\",\n",
    "          save_top_k=2,\n",
    "          save_last=True,\n",
    "          verbose=False,\n",
    "      )\n",
    "\n",
    "      trainer = Trainer(max_epochs=config.epochs, default_root_dir=\"saved_models/Approach_2_FeaturesDataset/ae/\"+str(i)+\"/\", callbacks=[early_stop, checkpoint_callback],fast_dev_run=False)\n",
    "      trainer.fit(model, train_loader, val_loader)\n",
    "      trainer.test(model, test_loader)\n",
    "\n",
    "\n",
    "wandb.agent(sweep_id, train, count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the BEST AE on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataset = DataFrameApproach2(train_df)\n",
    "val_dataset = DataFrameApproach2(val_df)\n",
    "test_dataset = DataFrameApproach2(test_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_dir = \"saved_models/Approach_2_FeaturesDataset/ae/\"\n",
    "model_to_test_paths = [\n",
    "    \"1/last.ckpt\",\n",
    "    \"1/best_model.ckpt\",\n",
    "    \"1/best_model-v1.ckpt\",\n",
    "    \"5/last.ckpt\",\n",
    "    \"5/best_model-v1.ckpt\",\n",
    "    \"5/best_model.ckpt\",\n",
    "    \"6/last.ckpt\",\n",
    "    \"7/last.ckpt\",\n",
    "    \"7/best_model.ckpt\",\n",
    "    \"7/best_model-v1.ckpt\",\n",
    "    \"9/last.ckpt\",\n",
    "    \"9/best_model.ckpt\",\n",
    "    \"9/best_model-v1.ckpt\",\n",
    "    \"10/last.ckpt\",\n",
    "    \"10/best_model.ckpt\",\n",
    "    \"10/best_model-v1.ckpt\",\n",
    "]\n",
    "      \n",
    "# Test the models\n",
    "print(f\"Models to test: {model_to_test_paths}\")\n",
    "\n",
    "\n",
    "best_metric = 1000000000\n",
    "best_model = \"\"\n",
    "for model_path_ in model_to_test_paths:\n",
    "  version = model_path_\n",
    "  model_path = base_model_dir+model_path_\n",
    "  input_dim = batch[0].shape[-1]\n",
    "\n",
    "  checkpoint_model = Autoencoder(input_dim=input_dim, batch_size = batch_size,sparsity_factor=0.005,enable_sparsity_loss=False, enable_weight_decay_loss=False, enable_non_negativity_constraint=False, enable_wandb = False)\n",
    "\n",
    "  checkpoint_model.load_state_dict(torch.load(model_path, map_location=checkpoint_model.device)['state_dict']) # ------> PyTorch Lightning API\n",
    "\n",
    "  trainer = Trainer(accelerator = 'auto', fast_dev_run=False)\n",
    "  print(f\"Evaluation => {version}\")\n",
    "  trainer.test(checkpoint_model, dataloaders=test_loader)\n",
    "\n",
    "  if(checkpoint_model.test_rec_loss < best_metric):\n",
    "    best_metric = checkpoint_model.test_rec_loss\n",
    "    best_model = version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"BEST MODEL => FILE = {best_model}, MSE = {best_metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Model\n",
    "The same classifier model used in the previous experiments is used here the only difference is the dataset, here we use the extracted features dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a mapping utility to go from label to idx and vice versa\n",
    "label2idx= {}\n",
    "idx2label = {}\n",
    "labels_task = dataset.get_dataframe()['labels'].unique()\n",
    "\n",
    "for i in range(len(labels_task)):\n",
    "  label2idx[labels_task[i]] = i\n",
    "  idx2label[str(i)] = labels_task[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierPerTask_Approach2(LightningModule):\n",
    "    def __init__(self, encoder, text_labels, head_type=1, enable_wandb=False):\n",
    "        super(ClassifierPerTask_Approach2, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.text_labels = text_labels\n",
    "        if(head_type==1):\n",
    "          # HEAD 1\n",
    "          self.classifier = nn.Sequential(\n",
    "              nn.Linear(encoder.z_dim, 128),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(128, len(text_labels))\n",
    "          )\n",
    "        elif (head_type ==2):\n",
    "          # HEAD 2\n",
    "          self.classifier = nn.Sequential(\n",
    "              nn.Linear(encoder.z_dim, 256),\n",
    "              nn.ReLU(),\n",
    "               nn.Dropout(0.2),\n",
    "              nn.Linear(256, 128),\n",
    "              nn.ReLU(),\n",
    "              nn.Dropout(0.2),\n",
    "              nn.Linear(128, len(text_labels))\n",
    "          )\n",
    "        elif (head_type ==3):\n",
    "          # HEAD 3\n",
    "          self.classifier = nn.Sequential(\n",
    "              nn.Linear(encoder.z_dim, 256),\n",
    "              nn.BatchNorm1d(256),  # Batch normalization\n",
    "              nn.ReLU(),\n",
    "              nn.Dropout(0.2),\n",
    "              nn.Linear(256, 128),\n",
    "              nn.BatchNorm1d(128),  # Batch normalization\n",
    "               nn.ReLU(),\n",
    "              nn.Dropout(0.2),\n",
    "              nn.Linear(128, len(text_labels))\n",
    "          )\n",
    "        else:\n",
    "          # HEAD 4\n",
    "          self.classifier = nn.Sequential(\n",
    "              nn.Linear(encoder.z_dim, 256),\n",
    "              nn.LayerNorm(256),  # Apply layer normalization\n",
    "              nn.ReLU(),\n",
    "              nn.Dropout(0.2),\n",
    "              nn.Linear(256, 128),\n",
    "              nn.LayerNorm(128),  # Apply layer normalization\n",
    "              nn.ReLU(),\n",
    "              nn.Dropout(0.2),\n",
    "              nn.Linear(128, len(text_labels))\n",
    "          )\n",
    "\n",
    "        self.train_loss = []\n",
    "        self.train_accuracy = []\n",
    "        self.val_loss = []\n",
    "        self.val_accuracy = []\n",
    "        self.test_loss = []\n",
    "        self.test_accuracy = []\n",
    "\n",
    "        self.enable_wandb = enable_wandb\n",
    "\n",
    "        if self.enable_wandb:\n",
    "          wandb.init(project=\"Project_EAI_BrainComputerInterface\", entity=\"rucci-2053183\", group=\"approach2_classifier\")\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.classifier(z)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(torch.float32)\n",
    "        z = self.encoder(inputs)\n",
    "        outputs = self(z)\n",
    "        labels = self.labels2TargetTensor(labels).to(torch.long).to(outputs.device)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = (preds == labels).float().mean()\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('test_accuracy', acc)\n",
    "\n",
    "        self.train_loss.append(loss)\n",
    "        self.train_accuracy.append(acc)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(torch.float32)\n",
    "        z = self.encoder(inputs)\n",
    "        outputs = self(z)\n",
    "        labels = self.labels2TargetTensor(labels).to(torch.long).to(outputs.device)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = (preds == labels).float().mean()\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_accuracy', acc)\n",
    "\n",
    "        self.test_loss.append(loss)\n",
    "        self.test_accuracy.append(acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(torch.float32)\n",
    "        z = self.encoder(inputs)\n",
    "        outputs = self(z)\n",
    "        labels = self.labels2TargetTensor(labels).to(torch.long).to(outputs.device)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = (preds == labels).float().mean()\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_accuracy', acc)\n",
    "\n",
    "        self.val_loss.append(loss)\n",
    "        self.val_accuracy.append(acc)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "      optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "      scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "      return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "\n",
    "    def labels2TargetTensor(self, labels):\n",
    "      target = []\n",
    "      for item in labels:\n",
    "        target.append(label2idx[item])\n",
    "\n",
    "      return torch.Tensor(target)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        train_loss = torch.stack([x for x in self.train_loss]).mean()\n",
    "        train_acc = torch.stack([x for x in self.train_accuracy]).mean()\n",
    "\n",
    "        # Print the training loss\n",
    "        print_log = f'Training - Epoch {self.current_epoch}: Loss => {train_loss.item()} ACCURACY => {train_acc}'\n",
    "\n",
    "        self.train_loss.clear()\n",
    "        self.train_accuracy.clear()\n",
    "\n",
    "        if self.enable_wandb:\n",
    "            # Log mean training loss\n",
    "            wandb.log({\"epoch_train_loss\": train_loss, \"epoch_train_accuracy\": train_acc})\n",
    "\n",
    "        print(print_log)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        test_loss = torch.stack([x for x in self.test_loss]).mean()\n",
    "        test_acc = torch.stack([x for x in self.test_accuracy]).mean()\n",
    "\n",
    "        # Print the training loss\n",
    "        print_log = f'Test - Epoch {self.current_epoch}: Loss => {test_loss.item()} ACCURACY => {test_acc}'\n",
    "\n",
    "        self.test_loss.clear()\n",
    "        self.test_accuracy.clear()\n",
    "\n",
    "        if self.enable_wandb:\n",
    "            # Log mean test loss and accuracy\n",
    "            wandb.log({\"epoch_test_loss\": test_loss, \"epoch_test_accuracy\": test_acc})\n",
    "\n",
    "        print(print_log)\n",
    "\n",
    "        self.test_acc = test_acc\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_loss = torch.stack([x for x in self.val_loss]).mean()\n",
    "        val_acc = torch.stack([x for x in self.val_accuracy]).mean()\n",
    "\n",
    "        # Print the training loss\n",
    "        print_log = f'Validation - Epoch {self.current_epoch}: Loss => {val_loss.item()} ACCURACY => {val_acc}'\n",
    "\n",
    "        self.val_loss.clear()\n",
    "        self.val_accuracy.clear()\n",
    "        self.log(\"epoch_val_accuracy\", val_acc)\n",
    "        if self.enable_wandb:\n",
    "            # Log mean validation loss and accuracy\n",
    "            wandb.log({\"epoch_val_loss\": val_loss, \"epoch_val_accuracy\": val_acc})\n",
    "            wandb.log({\"epoch\": self.current_epoch})\n",
    "\n",
    "        print(print_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡️ Train the Classifier ⚡️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataset = DataFrameApproach2(train_df)\n",
    "val_dataset = DataFrameApproach2(val_df)\n",
    "test_dataset = DataFrameApproach2(test_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the best AE\n",
    "base_model_dir = \"saved_models/Approach_2_FeaturesDataset\"\n",
    "best_model_path = base_model_dir+\"/ae/6/last.ckpt\"\n",
    "\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "input_dim = batch[0].shape[-1]\n",
    "checkpoint_model = Autoencoder(input_dim=input_dim, batch_size = batch_size,sparsity_factor=0.005,enable_sparsity_loss=False, enable_weight_decay_loss=False, enable_non_negativity_constraint=False, enable_wandb = False)\n",
    "checkpoint_model.load_state_dict(torch.load(best_model_path, map_location=checkpoint_model.device)['state_dict']) # ------> PyTorch Lightning API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Classifier Module for training\n",
    "encoder = checkpoint_model.encoder\n",
    "encoder.z_dim = 128\n",
    "classifier = ClassifierPerTask_Approach2(encoder, labels_task,head_type=4, enable_wandb=True)\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"epoch_val_accuracy\", min_delta=0.00, patience=30, verbose=True, mode=\"max\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "     monitor='epoch_val_accuracy',\n",
    "     dirpath=\"saved_models/Approach_2_FeaturesDataset/classifier/\",\n",
    "     filename='approach2-featsDataset-epoch{epoch:02d}',\n",
    "     auto_insert_metric_name=True,\n",
    "     mode=\"max\",\n",
    "     save_top_k=2,\n",
    "     verbose=True\n",
    ")\n",
    "\n",
    "trainer_classifier = Trainer(max_epochs=100, default_root_dir=\"saved_models/Approach_2_FeaturesDataset/classifier/\", callbacks=[early_stop,checkpoint_callback],fast_dev_run=False)\n",
    "trainer_classifier.fit(classifier, train_loader, val_loader)\n",
    "# trainer.test(classifier, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the Classifier on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataset = DataFrameApproach2(train_df)\n",
    "val_dataset = DataFrameApproach2(val_df)\n",
    "test_dataset = DataFrameApproach2(test_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Using device: cpu\n",
      "Initialized Model on cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the best AE\n",
    "base_model_dir = \"saved_models/Approach_2_FeaturesDataset\"\n",
    "best_model_path = base_model_dir+\"/ae/6/last.ckpt\"\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "input_dim = batch[0].shape[-1]\n",
    "checkpoint_model = Autoencoder(input_dim=input_dim, batch_size = batch_size,sparsity_factor=0.005,enable_sparsity_loss=False, enable_weight_decay_loss=False, enable_non_negativity_constraint=False, enable_wandb = False)\n",
    "checkpoint_model.load_state_dict(torch.load(best_model_path, map_location=checkpoint_model.device)['state_dict']) # ------> PyTorch Lightning API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Head1/approach2-featsDataset-epochepoch=11.ckpt 1\n",
      "Evaluation => /Head1/approach2-featsDataset-epochepoch=11.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 52.54it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 64. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - Epoch 0: Loss => 0.9570581316947937 ACCURACY => 0.6484375\n",
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00,  6.86it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy              0.6484375\n",
      "        test_loss           0.9570581316947937\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Head1/approach2-featsDataset-epochepoch=38.ckpt 1\n",
      "Evaluation => /Head1/approach2-featsDataset-epochepoch=38.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 204.30it/s]Test - Epoch 0: Loss => 0.9763163924217224 ACCURACY => 0.6328125\n",
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00,  8.78it/s] \n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy              0.6328125\n",
      "        test_loss           0.9763163924217224\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Head3/approach2-featsDataset-epochepoch=25.ckpt 3\n",
      "Evaluation => /Head3/approach2-featsDataset-epochepoch=25.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 167.01it/s]Test - Epoch 0: Loss => 0.9083847999572754 ACCURACY => 0.66796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Head3/approach2-featsDataset-epochepoch=33.ckpt 3\n",
      "Evaluation => /Head3/approach2-featsDataset-epochepoch=33.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 153.47it/s]Test - Epoch 0: Loss => 0.9047603607177734 ACCURACY => 0.6640625\n",
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00,  8.86it/s] \n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy              0.6640625\n",
      "        test_loss           0.9047603607177734\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "base_model_dir = \"saved_models/Approach_2_FeaturesDataset/classifier/\"\n",
    "model_to_test_paths = [\n",
    "    \"/Head1/approach2-featsDataset-epochepoch=11.ckpt\",\n",
    "    \"/Head1/approach2-featsDataset-epochepoch=38.ckpt\",\n",
    "    \"/Head3/approach2-featsDataset-epochepoch=25.ckpt\",\n",
    "    \"/Head3/approach2-featsDataset-epochepoch=33.ckpt\",\n",
    "]\n",
    "\n",
    "best_metric = 0\n",
    "best_model = \"\"\n",
    "for model_path_ in model_to_test_paths:\n",
    "  version = model_path_\n",
    "  head_type = int(model_path_.split(\"/\")[1][-1])\n",
    "  model_path = base_model_dir+model_path_\n",
    "  input_dim = batch[0].shape[-1]\n",
    "\n",
    "  checkpoint_model = ClassifierPerTask_Approach2(encoder, labels_task, head_type=head_type, enable_wandb=False)\n",
    "\n",
    "  print(f\"Loading {model_path_} {head_type}\")\n",
    "  checkpoint_model.load_state_dict(torch.load(model_path, map_location=checkpoint_model.device)['state_dict']) # ------> PyTorch Lightning API\n",
    "\n",
    "  trainer = Trainer(accelerator = 'auto', fast_dev_run=False)\n",
    "  print(f\"Evaluation => {version}\")\n",
    "  trainer.test(checkpoint_model, dataloaders=test_loader)\n",
    "\n",
    "  if(checkpoint_model.test_acc > best_metric):\n",
    "    best_metric = checkpoint_model.test_acc\n",
    "    best_model = version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL => FILE = /Head3/approach2-featsDataset-epochepoch=25.ckpt, MSE = 0.66796875\n"
     ]
    }
   ],
   "source": [
    "print(f\"BEST MODEL => FILE = {best_model}, MSE = {best_metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".2f\", cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Import the best Classifier model\n",
    "model_path = base_model_dir+\"/\"+best_model\n",
    "input_dim = batch[0].shape[-1]\n",
    "checkpoint_model = ClassifierPerTask_Approach2.load_from_checkpoint(model_path, head_type=3, enable_wandb=False)\n",
    "checkpoint_model.eval()\n",
    "\n",
    "# Get the predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for batch in test_loader:\n",
    "    inputs, labels = batch\n",
    "    inputs = inputs.to(torch.float32)\n",
    "    z = checkpoint_model.encoder(inputs)\n",
    "    outputs = checkpoint_model(z)\n",
    "    preds = torch.argmax(outputs, dim=1)\n",
    "    y_true.extend(labels)\n",
    "    y_pred.extend(preds)\n",
    "\n",
    "y_true = [label2idx[item] for item in y_true]\n",
    "y_pred = [item.item() for item in y_pred]\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred, labels_task, \"Confusion Matrix - General Model - Features Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetApproach3(Dataset):\n",
    "  def __init__(self, window_size=1):\n",
    "    self.dataset = pd.DataFrame()\n",
    "\n",
    "    # Create a unique dataframe that is composed by the concatenation of all the files that belong to the task\n",
    "    tasks_name = ['task_1','task_2','task_3','task_4']\n",
    "    for task_name in tasks_name:\n",
    "      for file in dataset_task_mapping[task_name]:\n",
    "        df = pd.read_csv(file['file_path'])\n",
    "        # Concatenate the dataframes by rows but remove the first row\n",
    "        df = df.iloc[1:]\n",
    "        self.dataset = pd.concat([self.dataset, df], ignore_index=True)\n",
    "\n",
    "    print(f\"Concatenating the dataframes ({len(self.dataset)})\")\n",
    "    print(f\"Dataset shape: {self.dataset.shape}\")\n",
    "\n",
    "    # Windowing\n",
    "    self.window_size = window_size\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset) - self.window_size\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # return as a tensor\n",
    "    print(f\"Index: {idx}\")\n",
    "    return torch.tensor(self.dataset.iloc[idx].values)\n",
    "\n",
    "  def get_dataframe(self):\n",
    "    return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetApproach4(Dataset):\n",
    "  def __init__(self, window_size=1):\n",
    "    self.dataset = []\n",
    "\n",
    "    # Create a unique dataframe that is composed by the concatenation of all the files that belong to the task + the baselines files\n",
    "    tasks_name = ['task_1','task_2','task_3','task_4']\n",
    "    for task_name in tasks_name:\n",
    "      for file in dataset_task_mapping[task_name]:\n",
    "        df = pd.read_csv(file['file_path'])\n",
    "        self.dataset.append(df)\n",
    "\n",
    "    # Baseline 1\n",
    "    for file in dataset_task_mapping['baseline_1']:\n",
    "      df = pd.read_csv(file['file_path'])\n",
    "      self.dataset.append(df)\n",
    "\n",
    "    # Baseline 2\n",
    "    for file in dataset_task_mapping['baseline_2']:\n",
    "      df = pd.read_csv(file['file_path'])\n",
    "      self.dataset.append(df)\n",
    "\n",
    "    # Concatenate the dataframes\n",
    "    print(f\"Concatenating the dataframes ({len(self.dataset)})\")\n",
    "    self.dataset = pd.concat(self.dataset)\n",
    "    # Create a dataframe\n",
    "    print(f\"Dataset shape: {self.dataset.shape}\")\n",
    "\n",
    "\n",
    "    # Windowing\n",
    "    self.window_size = window_size\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset) - self.window_size\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # return as a tensor\n",
    "    print(f\"Index: {idx}\")\n",
    "    return torch.tensor(self.dataset.iloc[idx].values)\n",
    "\n",
    "  def get_dataframe(self):\n",
    "    return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetApproach3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the rows of the dataset using sklearn (making sure the shuffle is reproducible)\n",
    "from sklearn.utils import shuffle\n",
    "data = shuffle(dataset.get_dataframe(), random_state=0)\n",
    "# Remove the index column\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Splitting into train and test sets (80% training data, 20% testing data)\n",
    "train_df, test_df = train_test_split(data, test_size=0.15, random_state=42)\n",
    "\n",
    "# Splitting the train_df further into train and validation sets (70% training data, 30% validation data)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.15, random_state=42)\n",
    "\n",
    "print(f\"Data: {len(data)} ,Train size: {len(train_df)}, Val size: {len(val_df)}, Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Dataframe class Approach 3\n",
    "class DataFrameApproach3(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe.iloc[:, :-1].values\n",
    "        self.targets = dataframe['labels'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.data[idx])\n",
    "        y = self.targets[idx]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "\n",
    "    # Apply min-max normalization to each column\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(data)\n",
    "\n",
    "    return torch.tensor(normalized_data), targets\n",
    "\n",
    "# Creating datasets and data loaders for each split\n",
    "train_dataset = DataFrameApproach3(train_df)\n",
    "val_dataset = DataFrameApproach3(val_df)\n",
    "test_dataset = DataFrameApproach3(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, window_size = 1, enable_sparsity_loss=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(128),\n",
    "        )\n",
    "\n",
    "        # Apply He initialization to the linear layers\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, input_dim = x.size()  # Obtain the shape of the input [bs, input_dim]\n",
    "        input = x\n",
    "        x = self.encoder(input)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, window_size, enable_sparsity_loss=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, window_size * input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Apply He initialization to the linear layers\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.to(torch.float32)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AE Lightning Module ⚡️⚡️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(LightningModule):\n",
    "    def __init__(self, input_dim, batch_size, sparsity_factor=0.1, sparsity_loss_coef = 1e-3, weight_decay=0.001, window_size=window_size, enable_sparsity_loss=False, enable_weight_decay_loss=False ,enable_non_negativity_constraint=False,enable_wandb = False):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        if( enable_sparsity_loss == True and enable_non_negativity_constraint== True):\n",
    "          print(\"The combination of constraints enable_sparsity_loss and enable_non_negativity_constraint both true leads to error in to the model matrix multiplication. This will be solved by setting enable_non_negativity_constraint to False.\")\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.encoder = Encoder(input_dim=input_dim, window_size=window_size, enable_sparsity_loss = enable_sparsity_loss)\n",
    "        self.decoder = Decoder(input_dim=input_dim, window_size=window_size, enable_sparsity_loss = enable_sparsity_loss)\n",
    "        self.train_loss_memory = []\n",
    "        self.train_rec_loss_memory = []\n",
    "\n",
    "        self.val_loss_memory = []\n",
    "        self.val_rec_loss_memory = []\n",
    "\n",
    "        self.test_loss_memory = []\n",
    "        self.test_rec_loss_memory = []\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "\n",
    "\n",
    "        # --- Loss Settings\n",
    "        self.enable_sparsity_loss = enable_sparsity_loss\n",
    "        if enable_sparsity_loss:\n",
    "          self.sparsity_loss_coef = sparsity_loss_coef\n",
    "          self.sparsity_factor = sparsity_factor\n",
    "          print(f\"Enabled Sparsity term in the loss with sparsity loss coeff => {self.sparsity_loss_coef} and sparsity factor=>{self.sparsity_factor}\")\n",
    "\n",
    "          # self.sparsity_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "          # Memory logs for sparsity\n",
    "          self.train_sparsity_loss_memory = []\n",
    "          self.val_sparsity_loss_memory = []\n",
    "          self.test_sparsity_loss_memory = []\n",
    "\n",
    "          self.enable_non_negativity_constraint = False\n",
    "        else:\n",
    "          self.enable_non_negativity_constraint = enable_non_negativity_constraint\n",
    "          if enable_non_negativity_constraint:\n",
    "            print(\"Enabled non negativity constraint\")\n",
    "\n",
    "\n",
    "        self.enable_weight_decay_loss = enable_weight_decay_loss\n",
    "        if enable_weight_decay_loss:\n",
    "          print(\"Enabled weight decay\")\n",
    "          self.weight_decay = weight_decay\n",
    "\n",
    "        self.wandb_log = enable_wandb\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        if torch.cuda.is_available():\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                device = torch.device('cuda:0')\n",
    "                print('Using device:', device)\n",
    "            else:\n",
    "                device = torch.device('cuda')\n",
    "                print('Using device:', device)\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "            print('Using device:', device)\n",
    "\n",
    "\n",
    "        print('Using device:', device)\n",
    "\n",
    "        self.to(device)\n",
    "        print(f\"Initialized Model on {self.device}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "    def kl_div(self, p, p_hat):\n",
    "      funcs = nn.Sigmoid()\n",
    "      p_hat = torch.mean(funcs(p_hat), 1)\n",
    "      p_tensor = torch.Tensor([p] * p_hat.shape[0]).to(self.device)\n",
    "\n",
    "\n",
    "      return torch.sum(p_tensor * torch.log(p_tensor) - p_tensor * torch.log(p_hat) + (1 - p_tensor) * torch.log(1 - p_tensor) - (1 - p_tensor) * torch.log(1 - p_hat))\n",
    "\n",
    "    def sparse_loss(self, values):\n",
    "      loss = 0\n",
    "      values = values.view(self.batch_size, -1)\n",
    "\n",
    "      # Encoder sparsity\n",
    "      lyrs_encoder = list(self.encoder.encoder.children())\n",
    "      for i, lyr in enumerate(lyrs_encoder):\n",
    "          if isinstance(lyr, nn.Linear):\n",
    "            values = lyr(values)\n",
    "            # loss += self.sparsity_loss(torch.tensor([self.sparsity_factor]).to(self.device), values.to(self.device))\n",
    "            loss += self.kl_div(self.sparsity_factor, values.to(self.device))\n",
    "\n",
    "      # Decoder sparsity\n",
    "      lyrs_decoder = list(self.decoder.decoder.children())\n",
    "      for i, lyr in enumerate(lyrs_decoder):\n",
    "          if isinstance(lyr, nn.Linear):\n",
    "              values = lyr(values)\n",
    "              # loss += self.sparsity_loss(torch.tensor([self.sparsity_factor]).to(self.device), values.to(self.device))\n",
    "              loss += self.kl_div(self.sparsity_factor, values.to(self.device))\n",
    "\n",
    "      return loss\n",
    "\n",
    "    def calculate_weight_decay_loss(self):\n",
    "        weight_decay_loss = 0.0\n",
    "        for param in self.parameters():\n",
    "            weight_decay_loss += 0.5 * self.weight_decay * torch.norm(param, p=2) ** 2\n",
    "        return weight_decay_loss\n",
    "\n",
    "    def enforce_non_negativity(self):\n",
    "      for param in self.parameters():\n",
    "        param.data.clamp_(min=0, max=None)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch[0].to(torch.float32) #[bs, input_dim]\n",
    "        _, reconstructions = self(x)\n",
    "\n",
    "        x = x.view(-1) # [bs * input_dim]\n",
    "        reconstructions = reconstructions.view(-1)\n",
    "\n",
    "        loss_mse = nn.MSELoss()(reconstructions, x)\n",
    "        loss = loss_mse\n",
    "\n",
    "        if self.enable_sparsity_loss:\n",
    "          # sparsity_loss = self.sparsity_loss(torch.log(reconstructions).to(self.device), torch.tensor([self.sparsity_factor]).to(self.device))\n",
    "          sparsity_loss = self.sparse_loss(x) * self.sparsity_loss_coef\n",
    "          loss += sparsity_loss\n",
    "          self.train_sparsity_loss_memory.append(sparsity_loss)\n",
    "\n",
    "        if self.enable_weight_decay_loss:\n",
    "          weight_decay_loss = self.calculate_weight_decay_loss()\n",
    "          loss += weight_decay_loss\n",
    "\n",
    "        self.train_loss_memory.append(loss)\n",
    "        self.train_rec_loss_memory.append(loss_mse)\n",
    "\n",
    "        if self.wandb_log:\n",
    "          wandb.log({\"train_total_loss\": loss})\n",
    "          wandb.log({\"train_reconstruction_loss\": loss_mse})\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "      x = batch[0].to(torch.float32)\n",
    "      _, reconstructions = self(x)\n",
    "\n",
    "      x = x.view(-1) #[]\n",
    "      reconstructions = reconstructions.view(-1)\n",
    "\n",
    "      loss_mse = nn.MSELoss()(reconstructions, x)\n",
    "      loss = loss_mse\n",
    "\n",
    "      if self.enable_sparsity_loss:\n",
    "        # sparsity_loss = self.sparsity_loss(torch.log(reconstructions).to(self.device), torch.tensor([self.sparsity_factor]).to(self.device))\n",
    "        sparsity_loss = self.sparse_loss(x) * self.sparsity_loss_coef\n",
    "        loss += sparsity_loss\n",
    "        self.val_sparsity_loss_memory.append(sparsity_loss)\n",
    "\n",
    "      if self.enable_weight_decay_loss:\n",
    "        weight_decay_loss = self.calculate_weight_decay_loss()\n",
    "        loss += weight_decay_loss\n",
    "\n",
    "      if self.enable_non_negativity_constraint:\n",
    "        self.enforce_non_negativity()\n",
    "\n",
    "      self.val_loss_memory.append(loss)\n",
    "      self.val_rec_loss_memory.append(loss_mse)\n",
    "\n",
    "      if self.wandb_log:\n",
    "        wandb.log({\"val_total_loss\": loss})\n",
    "        wandb.log({\"val_reconstruction_loss\": loss_mse})\n",
    "\n",
    "      # For early stop and Model checkpoint callbacks\n",
    "      self.log(\"val_reconstruction_loss\",loss_mse)\n",
    "\n",
    "      return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "      x = batch[0].to(torch.float32)\n",
    "      _, reconstructions = self(x)\n",
    "\n",
    "      x = x.view(-1) #[]\n",
    "      reconstructions = reconstructions.view(-1)\n",
    "\n",
    "      loss_mse = nn.MSELoss()(reconstructions, x)\n",
    "      loss = loss_mse\n",
    "\n",
    "      if self.enable_sparsity_loss:\n",
    "        # sparsity_loss = self.sparsity_loss(torch.log(reconstructions).to(self.device), torch.tensor([self.sparsity_factor]).to(self.device))\n",
    "        sparsity_loss = self.sparse_loss(x) * self.sparsity_loss_coef\n",
    "        loss += sparsity_loss\n",
    "        self.test_sparsity_loss_memory.append(sparsity_loss)\n",
    "\n",
    "      if self.enable_weight_decay_loss:\n",
    "        weight_decay_loss = self.calculate_weight_decay_loss()\n",
    "        loss += weight_decay_loss\n",
    "\n",
    "      if self.enable_non_negativity_constraint:\n",
    "        self.enforce_non_negativity()\n",
    "\n",
    "      self.test_loss_memory.append(loss)\n",
    "      self.test_rec_loss_memory.append(loss_mse)\n",
    "\n",
    "\n",
    "      return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=10)  # Adjust T_max as needed\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': {'scheduler': scheduler, 'interval': 'epoch'}}\n",
    "\n",
    "    def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_closure):\n",
    "        # step\n",
    "        optimizer.step(closure=optimizer_closure)\n",
    "\n",
    "        if self.enable_non_negativity_constraint:\n",
    "          self.enforce_non_negativity()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.wandb_log:\n",
    "            wandb.log({'epoch': self.current_epoch})\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # Access the training loss from the outputs\n",
    "        train_loss = torch.stack([x for x in self.train_loss_memory]).mean()\n",
    "        train_rec_loss = torch.stack([x for x in self.train_rec_loss_memory]).mean()\n",
    "\n",
    "        # Print the training loss\n",
    "        print_log = f'Training Loss - Epoch {self.current_epoch}: Total Loss => {train_loss.item()} MSE => {train_rec_loss}'\n",
    "\n",
    "        self.train_loss_memory.clear()\n",
    "        self.train_rec_loss_memory.clear()\n",
    "\n",
    "        if self.enable_sparsity_loss:\n",
    "          train_sparsity_loss = torch.stack([x for x in self.train_sparsity_loss_memory]).mean()\n",
    "          print_log += f' SPARSE => {train_sparsity_loss}'\n",
    "          self.train_sparsity_loss_memory.clear()\n",
    "\n",
    "        if self.wandb_log:\n",
    "          wandb.log({\"train_total_loss\": train_loss})\n",
    "          wandb.log({\"train_reconstruction_loss\": train_rec_loss})\n",
    "          if self.enable_sparsity_loss:\n",
    "            wandb.log({\"train_sparse_loss\": train_sparsity_loss})\n",
    "\n",
    "        print(print_log)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Access the training loss from the outputs\n",
    "        val_loss = torch.stack([x for x in self.val_loss_memory]).mean()\n",
    "        val_rec_loss = torch.stack([x for x in self.val_rec_loss_memory]).mean()\n",
    "\n",
    "        # Print the training loss\n",
    "        print_log = f'Validation Loss - Epoch {self.current_epoch}: Total Loss => {val_loss.item()} MSE => {val_rec_loss}'\n",
    "\n",
    "        self.val_loss_memory.clear()\n",
    "        self.val_rec_loss_memory.clear()\n",
    "\n",
    "        if self.enable_sparsity_loss:\n",
    "          val_sparsity_loss = torch.stack([x for x in self.val_sparsity_loss_memory]).mean()\n",
    "          print_log += f' SPARSE => {val_sparsity_loss}'\n",
    "          self.val_sparsity_loss_memory.clear()\n",
    "\n",
    "        if self.wandb_log:\n",
    "          wandb.log({\"val_total_loss\": val_loss})\n",
    "          wandb.log({\"val_reconstruction_loss\": val_rec_loss})\n",
    "          if self.enable_sparsity_loss:\n",
    "            wandb.log({\"val_sparse_loss\": val_sparsity_loss})\n",
    "\n",
    "        print(print_log)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # Access the training loss from the outputs\n",
    "        test_loss = torch.stack([x for x in self.test_loss_memory]).mean()\n",
    "        test_rec_loss = torch.stack([x for x in self.test_rec_loss_memory]).mean()\n",
    "\n",
    "        # Print the training loss\n",
    "        print_log = f'Test Loss - Epoch {self.current_epoch}: Total Loss => {test_loss.item()} MSE => {test_rec_loss}'\n",
    "\n",
    "        self.test_loss_memory.clear()\n",
    "        self.test_rec_loss_memory.clear()\n",
    "\n",
    "        if self.enable_sparsity_loss:\n",
    "          test_sparsity_loss = torch.stack([x for x in self.test_sparsity_loss_memory]).mean()\n",
    "          print_log += f' SPARSE => {test_sparsity_loss}'\n",
    "          self.test_sparsity_loss_memory.clear()\n",
    "\n",
    "        if self.wandb_log:\n",
    "          wandb.log({\"test_total_loss\": test_loss})\n",
    "          wandb.log({\"test_reconstruction_loss\": test_rec_loss})\n",
    "          if self.enable_sparsity_loss:\n",
    "            wandb.log({\"test_sparse_loss\": test_sparsity_loss})\n",
    "\n",
    "        self.test_rec_loss = test_rec_loss\n",
    "\n",
    "        print(print_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Learning with Prototypical Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a mapping utility to go from label to idx and vice versa\n",
    "label2idx= {}\n",
    "idx2label = {}\n",
    "labels_task = dataset.get_dataframe()['labels'].unique()\n",
    "\n",
    "for i in range(len(labels_task)):\n",
    "  label2idx[labels_task[i]] = i\n",
    "  idx2label[str(i)] = labels_task[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prototypes(support, labels, fallback_prototypes, missing_labels=None):\n",
    "    classes = torch.unique(labels)\n",
    "    # Concatenate the missing labels to the classes and sort them\n",
    "    if missing_labels is not None:\n",
    "        classes = torch.cat((classes, torch.tensor(missing_labels)))\n",
    "        classes = torch.sort(classes)[0]\n",
    "\n",
    "    prototypes = torch.zeros(\n",
    "        classes.size(0),\n",
    "        *support.shape[1:],\n",
    "        device=support.device,\n",
    "        dtype=support.dtype,\n",
    "    )\n",
    "    for i, cls in enumerate(classes):\n",
    "        # First you check if cls exist in the labels\n",
    "        if cls in labels:\n",
    "            embeddings = support[labels == cls]\n",
    "            prototypes[i].add_(embeddings.mean(dim=0))\n",
    "        else:\n",
    "            # RETIREVE THE MISSING CLASS FROM THE PRECOMPUTED PROTOTYPES\n",
    "            # embeddings = fallback_prototypes[ cls ]\n",
    "            # print(f\"{cls} not found in the batch, using precomputed prototype of shape {embeddings.shape}\")\n",
    "            embeddings = torch.zeros(support.shape[1])\n",
    "            prototypes[i].add_(embeddings)\n",
    "\n",
    "            prototypes[i].add_(embeddings)\n",
    "\n",
    "    return prototypes #(classes, h_dim)\n",
    "\n",
    "\n",
    "def accuracy(preds, targets):\n",
    "    \"\"\"Computes accuracy\"\"\"\n",
    "    acc = (preds.argmax(dim=1).long() == targets.long()).sum().float()\n",
    "    return acc / preds.size(0)\n",
    "\n",
    "class PrototypicalClassifier(torch.nn.Module):\n",
    "    def __init__( self,support=None,labels=None,fallback_prototypes=None, distance=\"euclidean\",normalize=False):\n",
    "      super(PrototypicalClassifier, self).__init__()\n",
    "      self.distance_metric = distance\n",
    "      self.normalize = normalize\n",
    "\n",
    "      # Select compute_prototypes function\n",
    "      self._compute_prototypes = compute_prototypes\n",
    "\n",
    "      # Assign distance function\n",
    "      if distance == \"euclidean\":\n",
    "        print(\"Using euclidean distance as distance metric\")\n",
    "        self.distance = PrototypicalClassifier.euclidean_distance\n",
    "      elif distance == \"cosine\":\n",
    "        print(\"Using cosine distance as distance metric\")\n",
    "        self.distance = PrototypicalClassifier.cosine_distance\n",
    "        self.normalize = True\n",
    "      else:\n",
    "        print(\"Using custom distance function as distance metric\")\n",
    "        self.distance = distance\n",
    "\n",
    "      # Compute prototypes\n",
    "      self.prototypes = None\n",
    "      if support is not None and labels is not None:\n",
    "          self.fit_(support, labels)\n",
    "      if fallback_prototypes is not None:\n",
    "          self.fallback_prototypes = fallback_prototypes # We set the precomputed prototypes as fallback: when a batch doesn't contain a class, we use the precomputed prototype\n",
    "          print(f\"INFO: Using precomputed prototypes of shape {self.fallback_prototypes.shape}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def euclidean_distance(prototypes, queries):\n",
    "      '''\n",
    "      - prototype is the tensor => [n_prot , hidden_dim] that contains the mean tensor for (presumibly) each class\n",
    "      - queries are the samples that have to be classified => [bs, hidden_dim]\n",
    "      '''\n",
    "      n = prototypes.size(0)\n",
    "      m = queries.size(0)\n",
    "      # The numb_of_protototypes represents the number of classes that have been selected in the current generation of prototypes\n",
    "      prototypes = prototypes.unsqueeze(0).expand(m, n, -1) #[ bs, numb_of_protototypes, h_dim]\n",
    "      queries = queries.unsqueeze(1).expand(m, n, -1) #[ bs, numb_of_protototypes, h_dim]\n",
    "      distance = (prototypes - queries).pow(2).sum(dim=-1)\n",
    "      # print(f\"Distance shape => {distance.shape} , TENSOR => {distance}\")\n",
    "\n",
    "      return distance\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def cosine_distance(prototypes, queries):\n",
    "        # Assumes prototypes and queries are normalized\n",
    "        return -queries @ prototypes.t()\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(x, epsilon=1e-8):\n",
    "        x = x / (x.norm(p=2, dim=-1, keepdim=True) + epsilon)\n",
    "        return x\n",
    "\n",
    "    def fit_(self, support, labels, missing_labels=None):\n",
    "        \"\"\"\n",
    "        **Description**\n",
    "\n",
    "        Computes and updates the prototypes given support embeddings and\n",
    "        corresponding labels.\n",
    "\n",
    "        **Arguments**\n",
    "        missing_labels: list of missing labels (might be None if all labels are present and it is possible to compute the prototypes)\n",
    "        \"\"\"\n",
    "        # TODO: Make a differentiable version? (For Proto-MAML style algorithms)\n",
    "\n",
    "        # Compute new prototypes\n",
    "        prototypes = self._compute_prototypes(support, labels, self.fallback_prototypes, missing_labels)\n",
    "\n",
    "        # Normalize if necessary\n",
    "        if self.normalize:\n",
    "            prototypes = PrototypicalClassifier.normalize(prototypes)\n",
    "\n",
    "        # Assign prototypes and return them\n",
    "        self.prototypes = prototypes\n",
    "        return prototypes\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert (\n",
    "            self.prototypes is not None\n",
    "        ), \"Prototypes not computed, use compute_prototypes(support, labels)\"\n",
    "        if self.normalize:\n",
    "            x = PrototypicalClassifier.normalize(x)\n",
    "        return -self.distance(self.prototypes, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypicalNetwork(LightningModule):\n",
    "    # https://github.com/learnables/learn2learn/blob/master/learn2learn/algorithms/lightning/lightning_protonet.py#L97\n",
    "    # https://github.com/learnables/learn2learn/blob/master/learn2learn/nn/protonet.py#L57\n",
    "    # https://github.com/learnables/learn2learn/blob/master/learn2learn/algorithms/lightning/lightning_episodic_module.py\n",
    "    def __init__(self, encoder, text_labels, train_dataset_split, distance_metric = \"euclidean\",run_name =\"run_1\", enable_wandb=False):\n",
    "      super(PrototypicalNetwork, self).__init__()\n",
    "      self.save_hyperparameters()\n",
    "\n",
    "      self.encoder = encoder\n",
    "      self.text_labels = text_labels\n",
    "      self.idx_labels = [label2idx[label] for label in text_labels]\n",
    "      self.train_dataset_split = train_dataset_split # Create an internal access to the train split\n",
    "\n",
    "      self.train_loss = []\n",
    "      self.train_accuracy = []\n",
    "      self.val_loss = []\n",
    "      self.val_accuracy = []\n",
    "      self.test_loss = []\n",
    "      self.test_accuracy = []\n",
    "      self.best_val_acc = 0.0\n",
    "\n",
    "      self.distance_metric = distance_metric\n",
    "      # Precompute the prototypes to ensure that exist one prototype for each class\n",
    "      self.classifier = PrototypicalClassifier(fallback_prototypes=self.precompute_prototypes(), distance=self.distance_metric)\n",
    "      self.lr = 0.001\n",
    "      self.scheduler_step = 20\n",
    "      self.scheduler_decay = 1.0\n",
    "\n",
    "      self.enable_wandb = enable_wandb\n",
    "      self.loss = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "      self.run_name = run_name\n",
    "\n",
    "      if self.enable_wandb:\n",
    "        wandb.init(project=\"Project_EAI_BrainComputerInterface\", entity=\"rucci-2053183\", group=\"approach3\",name=run_name)\n",
    "\n",
    "    def precompute_prototypes(self):\n",
    "      # For each class in the text_labels, select 10 random samples from the train_dataset_split with the corresponding label\n",
    "      # make those samples pass through the encoder and compute the mean of the embeddings\n",
    "      # return the prototypes in the form #[classes, h_dim]\n",
    "      # Just consider that the train_dataset_split contains the samples as a tuple (data, label)\n",
    "      prototypes = []\n",
    "      for label in self.text_labels:\n",
    "        samples = [sample[0] for sample in self.train_dataset_split if sample[1] == label]\n",
    "        samples = [sample.to(torch.float32) for sample in samples]\n",
    "        samples = torch.stack(samples)\n",
    "        embeddings = self.encoder(samples)\n",
    "        # embeddings do not require the gradient and they shouldn't be in the computation graph\n",
    "        embeddings = embeddings.detach()\n",
    "        prototypes.append(embeddings.mean(dim=0))\n",
    "\n",
    "      return torch.stack(prototypes)\n",
    "\n",
    "    def forward(self, z):\n",
    "      logits = self.classifier(z)\n",
    "      return logits\n",
    "\n",
    "    def labels2TargetTensor(self, labels):\n",
    "      target = []\n",
    "      for item in labels:\n",
    "        target.append(label2idx[item])\n",
    "\n",
    "      return torch.Tensor(target)\n",
    "\n",
    "    def get_count_class_samples(self,labels):\n",
    "      classes = torch.unique(labels)\n",
    "      class_samples = {}\n",
    "      for cls in classes:\n",
    "        num_samples = torch.sum(labels == cls).item()\n",
    "        class_samples[cls.item()] = num_samples\n",
    "\n",
    "      # Find the class with the minimum number of samples\n",
    "      min_samples_class = min(class_samples, key=class_samples.get)\n",
    "\n",
    "      # Convert the min_samples_class to a dictionary with the label as the key\n",
    "      min_samples_class_dict = {min_samples_class: class_samples[min_samples_class]}\n",
    "\n",
    "      return class_samples, min_samples_class_dict\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "      data, labels = batch # (bs,input_dim)\n",
    "      labels = self.labels2TargetTensor(labels).to(torch.long)\n",
    "      data = data.to(torch.float32)\n",
    "\n",
    "      batch_stats, min_samples_class = self.get_count_class_samples(labels)\n",
    "\n",
    "\n",
    "      # Sort data samples by labels\n",
    "      sort = torch.sort(labels)\n",
    "      data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "      labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "\n",
    "\n",
    "      # Initialize support indices\n",
    "      support_indices = np.zeros(data.size(0), dtype=bool) # (bs, true when the sample is in the support set, false when is a query sample)\n",
    "\n",
    "      # for each class in the batch, select the first n random samples as support set for that class and the rest as query, and report that in the support_indices\n",
    "      for _cls in list(batch_stats.keys()):\n",
    "        sample_for_class = batch_stats[_cls]\n",
    "        if sample_for_class > 1:\n",
    "          n =  random.randint(1, int(sample_for_class * 0.3)+1) # Randomly select the first n samples as support set (n is minimum 1 and maximum the 10% of the sample_for_clas)\n",
    "          class_indices = (labels == _cls).nonzero()  # Indices of samples belonging to the current class\n",
    "          support_indices[class_indices[:n]] = True  # Mark the first 'n' elements for the current class as support\n",
    "\n",
    "\n",
    "      # Compute support and query embeddings\n",
    "      embeddings = self.encoder(data) # [bs, encoder.z_dim]\n",
    "\n",
    "      # Select the support and query samples from the embeddings\n",
    "      support = embeddings[support_indices]\n",
    "      support_labels = labels[support_indices]\n",
    "\n",
    "      # support_label is in the form of [0,0,0,1,1,1,2,2,2,3,3,3,4,4,4] where each number represents a class;\n",
    "      # Giving that in the variable self.idx_labels we have a list that contains all the classes of the task\n",
    "      # We have to identify which label is missing from the support_label: consider the unique(support_labels), then check that all the labels in self.idx_labels are present in the unique(support_labels)\n",
    "      # If a label is missing, then we have to add it to the unique(support_labels) and create a prototype with the right function\n",
    "      missing_labels = list(set(self.idx_labels) - set(torch.unique(support_labels).tolist()))\n",
    "\n",
    "      if len(missing_labels) > 0:\n",
    "        # Add the missing labels to the support_labels\n",
    "        # support_labels = torch.cat((support_labels, torch.tensor(missing_labels).to(support_labels.device)))\n",
    "        # Compute the prototypes with the new support_labels\n",
    "        self.classifier.fit_(support, support_labels, missing_labels=missing_labels) # a list of missing labels [13, 12, 5]\n",
    "      else:\n",
    "        self.classifier.fit_(support, support_labels)\n",
    "\n",
    "      logits = self.classifier(embeddings)\n",
    "      loss = F.cross_entropy(logits, labels)\n",
    "      acc = accuracy(logits, labels)\n",
    "\n",
    "\n",
    "      self.log('train_loss', loss)\n",
    "      self.train_loss.append(loss)\n",
    "      self.train_accuracy.append(acc)\n",
    "\n",
    "      return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "      train_loss = torch.stack([x for x in self.train_loss]).mean()\n",
    "      train_acc = torch.stack([x for x in self.train_accuracy]).mean()\n",
    "\n",
    "      # Print the training loss\n",
    "      print_log = f'Training - Epoch {self.current_epoch}: Loss => {train_loss.item()} ACCURACY => {train_acc}'\n",
    "\n",
    "      self.train_loss.clear()\n",
    "      self.train_accuracy.clear()\n",
    "\n",
    "      # Every 10 epochs, compute again the fallback_prototypes\n",
    "      if self.current_epoch % 10 == 0:\n",
    "        self.classifier.fallback_prototypes = self.precompute_prototypes()\n",
    "        print(f\"Prototypes recomputed at epoch {self.current_epoch}\")\n",
    "\n",
    "      # Every 20 epochs save in a file the prototypes and call the file with the epoch number\n",
    "      if self.current_epoch % 20 == 0:\n",
    "        # Create a folder to save the prototypes if it doesn't exist MyDrive/ColabNotebooks/EAI_Napoli/saved_models/Approach_3/{self.run_name}/saved_prototypes/\n",
    "        # avoid in any case the error \"Parent directory /content/mydrive/MyDrive/ColabNotebooks/EAI_Napoli/saved_models/Approach_3/run_1/saved_prototypes does not exist.\"\n",
    "        os.makedirs(f\"saved_models/Approach_3_FeaturesDataset/{self.run_name}/saved_prototypes/\", exist_ok=True)\n",
    "\n",
    "        torch.save(self.classifier.fallback_prototypes, f\"saved_models/Approach_3_FeaturesDataset/{self.run_name}/saved_prototypes/prototypes_epoch_{self.current_epoch}.pt\")\n",
    "        print(f\"Prototypes saved at epoch {self.current_epoch}\")\n",
    "\n",
    "      if self.enable_wandb:\n",
    "          # Log mean training loss\n",
    "          wandb.log({\"epoch_train_loss\": train_loss, \"epoch_train_accuracy\": train_acc})\n",
    "\n",
    "      if self.current_epoch % 10 == 0:\n",
    "        print(print_log)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Same logic as the training step\n",
    "        data, labels = batch\n",
    "        labels = self.labels2TargetTensor(labels).to(torch.long)\n",
    "        data = data.to(torch.float32)\n",
    "\n",
    "        batch_stats, min_samples_class = self.get_count_class_samples(labels)\n",
    "\n",
    "        # Sort data samples by labels\n",
    "        sort = torch.sort(labels)\n",
    "        data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "        labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "\n",
    "        # Initialize support indices\n",
    "        support_indices = np.zeros(data.size(0), dtype=bool) # (bs, true when the sample is in the support set, false when is a query sample)\n",
    "\n",
    "        # for each class in the batch, select the first n random samples as support set for that class and the rest as query, and report that in the support_indices\n",
    "        for _cls in list(batch_stats.keys()):\n",
    "          sample_for_class = batch_stats[_cls]\n",
    "          if sample_for_class > 1:\n",
    "            # Randomly select the first n samples as support set (n is minimum 1 and maximum the 10% of the sample_for_clas)\n",
    "            n =  random.randint(1, int(sample_for_class * 0.3)+1)\n",
    "            class_indices = (labels == _cls).nonzero()\n",
    "            support_indices[class_indices[:n]] = True\n",
    "\n",
    "\n",
    "        # Compute support and query embeddings\n",
    "        embeddings = self.encoder(data)\n",
    "\n",
    "        # Select the support and query samples from the embeddings\n",
    "        support = embeddings[support_indices]\n",
    "        support_labels = labels[support_indices]\n",
    "\n",
    "        missing_labels = list(set(self.idx_labels) - set(torch.unique(support_labels).tolist()))\n",
    "\n",
    "        if len(missing_labels) > 0:\n",
    "          # Add the missing labels to the support_labels\n",
    "          # support_labels = torch.cat((support_labels, torch.tensor(missing_labels).to(support_labels.device)))\n",
    "          # Compute the prototypes with the new support_labels\n",
    "          proto = self.classifier.fit_(support, support_labels, missing_labels=missing_labels)\n",
    "        else:\n",
    "          proto = self.classifier.fit_(support, support_labels)\n",
    "\n",
    "        logits = self.classifier(embeddings)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        acc = accuracy(logits, labels)\n",
    "\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_accuracy', acc)\n",
    "        self.val_loss.append(loss)\n",
    "        self.val_accuracy.append(acc)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_loss = torch.stack([x for x in self.val_loss]).mean()\n",
    "        val_acc = torch.stack([x for x in self.val_accuracy]).mean()\n",
    "\n",
    "        # Print the training loss\n",
    "        print_log = f'Validation - Epoch {self.current_epoch}: Loss => {val_loss.item()} ACCURACY => {val_acc}'\n",
    "\n",
    "        self.val_loss.clear()\n",
    "        self.val_accuracy.clear()\n",
    "\n",
    "        self.log('epoch_val_loss', val_loss)\n",
    "        self.log('epoch_val_accuracy', val_acc)\n",
    "\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            # Save the fallback_prototypes\n",
    "            print(f\"Saving new prototypes that yield to the new (VAL) best accuracy: {self.best_val_acc} at epoch {self.current_epoch}\")\n",
    "            os.makedirs(f\"saved_models/Approach_3/{self.run_name}/saved_prototypes/\", exist_ok=True)\n",
    "            torch.save(self.classifier.fallback_prototypes, f\"saved_models/Approach_3/{self.run_name}/saved_prototypes/BEST_prototypes.pt\")\n",
    "\n",
    "        if self.enable_wandb:\n",
    "            # Log mean val loss\n",
    "            wandb.log({\"epoch_val_loss\": val_loss, \"epoch_val_accuracy\": val_acc})\n",
    "\n",
    "        if self.current_epoch % 10 == 0:\n",
    "          print(print_log)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "      # Same logic as the training step\n",
    "      data, labels = batch\n",
    "      labels = self.labels2TargetTensor(labels).to(torch.long)\n",
    "      data = data.to(torch.float32)\n",
    "\n",
    "      batch_stats, min_samples_class = self.get_count_class_samples(labels)\n",
    "\n",
    "      # Sort data samples by labels\n",
    "      sort = torch.sort(labels)\n",
    "      data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "      labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "\n",
    "      # It Is ok to use the same logic of the training and validation step becouse even if i'm using\n",
    "      # the test set samples to create the support set, this is equivalent of using any other set of samples\n",
    "\n",
    "      # Initialize support indices\n",
    "      support_indices = np.zeros(data.size(0), dtype=bool)\n",
    "\n",
    "      for _cls in list(batch_stats.keys()):\n",
    "        sample_for_class = batch_stats[_cls]\n",
    "        if sample_for_class > 1:\n",
    "          n =  random.randint(1, int(sample_for_class * 0.3)+1)\n",
    "          class_indices = (labels == _cls).nonzero()\n",
    "          support_indices[class_indices[:n]] = True\n",
    "\n",
    "      # Compute support and query embeddings\n",
    "      embeddings = self.encoder(data)\n",
    "      # Select the support and query samples from the embeddings\n",
    "      support = embeddings[support_indices]\n",
    "      support_labels = labels[support_indices]\n",
    "\n",
    "      missing_labels = list(set(self.idx_labels) - set(torch.unique(support_labels).tolist()))\n",
    "\n",
    "      if len(missing_labels) > 0:\n",
    "        self.classifier.fit_(support, support_labels, missing_labels=missing_labels)\n",
    "      else:\n",
    "        self.classifier.fit_(support, support_labels)\n",
    "\n",
    "      logits = self.classifier(embeddings)\n",
    "      loss = F.cross_entropy(logits, labels)\n",
    "      acc = accuracy(logits, labels)\n",
    "\n",
    "      self.log('test_loss', loss)\n",
    "      self.test_loss.append(loss)\n",
    "      self.log('test_accuracy', acc)\n",
    "      self.test_accuracy.append(acc)\n",
    "\n",
    "      return loss\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "      test_loss = torch.stack([x for x in self.test_loss]).mean()\n",
    "      test_acc = torch.stack([x for x in self.test_accuracy]).mean()\n",
    "\n",
    "      # Print the training loss\n",
    "      print_log = f'Test - Epoch {self.current_epoch}: Loss => {test_loss.item()} ACCURACY => {test_acc}'\n",
    "\n",
    "      self.test_loss.clear()\n",
    "      self.test_accuracy.clear()\n",
    "\n",
    "      if self.enable_wandb:\n",
    "          # Log mean test loss\n",
    "          wandb.log({\"epoch_test_loss\": test_loss, \"epoch_test_accuracy\": test_acc})\n",
    "\n",
    "      print(print_log)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "      optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "      lr_scheduler = optim.lr_scheduler.StepLR(\n",
    "          optimizer,\n",
    "          step_size=self.scheduler_step,\n",
    "          gamma=self.scheduler_decay,\n",
    "      )\n",
    "      return [optimizer], [lr_scheduler]\n",
    "\n",
    "\n",
    "      # optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "      # scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "      # return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"train_loss\"}\n",
    "      # return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run 1 \n",
    "Best Pretrained with euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 1\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "# Import Best Autoencoder\n",
    "base_model_dir = \"saved_models/Approach_2_FeaturesDataset\"\n",
    "best_model_path = base_model_dir+\"/ae/6/last.ckpt\"\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "input_dim = batch[0].shape[-1]\n",
    "checkpoint_model = Autoencoder(input_dim=input_dim, batch_size = batch_size,sparsity_factor=0.005,enable_sparsity_loss=False, enable_weight_decay_loss=False, enable_non_negativity_constraint=False, enable_wandb = False)\n",
    "checkpoint_model.load_state_dict(torch.load(best_model_path, map_location=checkpoint_model.device)['state_dict']) # ------> PyTorch Lightning API\n",
    "\n",
    "encoder = checkpoint_model.encoder\n",
    "encoder.z_dim = 128\n",
    "classifier = PrototypicalNetwork(encoder, labels_task, train_dataset, distance_metric=\"euclidean\", run_name=\"run_1_feats_dataset\", enable_wandb=True)\n",
    "\n",
    "# 100 Epochs patience early stopping with min delta of 0.001 over the epoch_val_accuracy\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='epoch_val_accuracy',\n",
    "    min_delta=0.001,\n",
    "    patience=100,\n",
    "    verbose=True,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# Model checkpoint callback to save the best model\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='epoch_val_accuracy',\n",
    "    dirpath=\"saved_models/Approach_3_FeaturesDataset/run_1\",\n",
    "    filename=\"BEST_{epoch}\",\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "trainer_classifier = Trainer(max_epochs=10000, default_root_dir=\"saved_models/Approach_3_FeaturesDataset/run_1\", fast_dev_run=False, callbacks=[early_stop_callback, checkpoint_callback])\n",
    "trainer_classifier.fit(classifier, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run 2\n",
    "Best Pretrained with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 2\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "# Import Best Autoencoder\n",
    "base_model_dir = \"saved_models/Approach_2_FeaturesDataset\"\n",
    "best_model_path = base_model_dir+\"/ae/6/last.ckpt\"\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "input_dim = batch[0].shape[-1]\n",
    "checkpoint_model = Autoencoder(input_dim=input_dim, batch_size = batch_size,sparsity_factor=0.005,enable_sparsity_loss=False, enable_weight_decay_loss=False, enable_non_negativity_constraint=False, enable_wandb = False)\n",
    "checkpoint_model.load_state_dict(torch.load(best_model_path, map_location=checkpoint_model.device)['state_dict']) # ------> PyTorch Lightning API\n",
    "\n",
    "encoder = checkpoint_model.encoder\n",
    "encoder.z_dim = 128\n",
    "classifier = PrototypicalNetwork(encoder, labels_task, train_dataset, distance_metric=\"cosine\", run_name=\"run_2_feats_dataset\", enable_wandb=True)\n",
    "\n",
    "# 100 Epochs patience early stopping with min delta of 0.001 over the epoch_val_accuracy\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='epoch_val_accuracy',\n",
    "    min_delta=0.001,\n",
    "    patience=100,\n",
    "    verbose=True,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# Model checkpoint callback to save the best model\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='epoch_val_accuracy',\n",
    "    dirpath=\"saved_models/Approach_3_FeaturesDataset/run_2\",\n",
    "    filename=\"BEST_{epoch}\",\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "trainer_classifier = Trainer(max_epochs=10000, default_root_dir=\"saved_models/Approach_3_FeaturesDataset/run_2\", fast_dev_run=False, callbacks=[early_stop_callback, checkpoint_callback])\n",
    "trainer_classifier.fit(classifier, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run 3\n",
    "AE from scratch with euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 3\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "input_dim = batch[0].shape[-1]\n",
    "model = Autoencoder(input_dim=input_dim, batch_size = batch_size,sparsity_factor=0.005,enable_sparsity_loss=False, enable_weight_decay_loss=False, enable_non_negativity_constraint=False, enable_wandb = False)\n",
    "\n",
    "encoder = model.encoder\n",
    "encoder.z_dim = 128\n",
    "classifier = PrototypicalNetwork(encoder, labels_task, train_dataset, distance_metric=\"euclidean\", run_name=\"run_3_feats_dataset\", enable_wandb=True)\n",
    "\n",
    "# 100 Epochs patience early stopping with min delta of 0.001 over the epoch_val_accuracy\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='epoch_val_accuracy',\n",
    "    min_delta=0.001,\n",
    "    patience=300,\n",
    "    verbose=True,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# Model checkpoint callback to save the best model\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='epoch_val_accuracy',\n",
    "    dirpath=\"saved_models/Approach_3_FeaturesDataset/run_3\",\n",
    "    filename=\"BEST_{epoch}\",\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "trainer_classifier = Trainer(max_epochs=10000, default_root_dir=\"saved_models/Approach_3_FeaturesDataset/run_3\", fast_dev_run=False, callbacks=[early_stop_callback, checkpoint_callback])\n",
    "trainer_classifier.fit(classifier, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run 4\n",
    "AE from scratch with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 4\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "input_dim = batch[0].shape[-1]\n",
    "model = Autoencoder(input_dim=input_dim, batch_size = batch_size,sparsity_factor=0.005,enable_sparsity_loss=False, enable_weight_decay_loss=False, enable_non_negativity_constraint=False, enable_wandb = False)\n",
    "\n",
    "encoder = model.encoder\n",
    "encoder.z_dim = 128\n",
    "classifier = PrototypicalNetwork(encoder, labels_task, train_dataset, distance_metric=\"cosine\", run_name=\"run_4_feats_dataset\", enable_wandb=True)\n",
    "\n",
    "# 100 Epochs patience early stopping with min delta of 0.001 over the epoch_val_accuracy\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='epoch_val_accuracy',\n",
    "    min_delta=0.001,\n",
    "    patience=300,\n",
    "    verbose=True,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# Model checkpoint callback to save the best model\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='epoch_val_accuracy',\n",
    "    dirpath=\"saved_models/Approach_3_FeaturesDataset/run_4\",\n",
    "    filename=\"BEST_{epoch}\",\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "trainer_classifier = Trainer(max_epochs=10000, default_root_dir=\"saved_models/Approach_3_FeaturesDataset/run_4\", fast_dev_run=False, callbacks=[early_stop_callback, checkpoint_callback])\n",
    "trainer_classifier.fit(classifier, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Meta learning zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the models\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "\n",
    "model_to_test_paths = [\n",
    "    \"saved_models/Approach_3_FeaturesDataset/run_1/BEST_epoch=138.ckpt\",\n",
    "    \"saved_models/Approach_3_FeaturesDataset/run_2/BEST_epoch=135.ckpt\",\n",
    "    \"saved_models/Approach_3_FeaturesDataset/run_3/BEST_epoch=499.ckpt\",\n",
    "    \"saved_models/Approach_3_FeaturesDataset/run_4/BEST_epoch=297.ckpt\",\n",
    "]\n",
    "\n",
    "for model_path in model_to_test_paths:\n",
    "  print(f\"Testing model {model_path}\")\n",
    "  classifier = PrototypicalNetwork.load_from_checkpoint(model_path, text_labels=labels_task, train_dataset_split=train_dataset, enable_wandb = False)\n",
    "\n",
    "  trainer = Trainer(accelerator=\"auto\")\n",
    "  trainer.test(classifier, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 4\n",
    "1 Contrastive pretrained autoencoder + classifier\n",
    "\n",
    "2 Contrastive pretrained autoencoder + Prototypical Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetApproach4(Dataset):\n",
    "  def __init__(self, window_size=1):\n",
    "    self.dataset = pd.DataFrame()\n",
    "\n",
    "    # Create a unique dataframe that is composed by the concatenation of all the files that belong to the task\n",
    "    tasks_name = ['task_1','task_2','task_3','task_4']\n",
    "    for task_name in tasks_name:\n",
    "      for file in dataset_task_mapping[task_name]:\n",
    "        df = pd.read_csv(file['file_path'])\n",
    "        # Concatenate the dataframes by rows but remove the first row\n",
    "        df = df.iloc[1:]\n",
    "        self.dataset = pd.concat([self.dataset, df], ignore_index=True)\n",
    "\n",
    "    print(f\"Concatenating the dataframes ({len(self.dataset)})\")\n",
    "    print(f\"Dataset shape: {self.dataset.shape}\")\n",
    "\n",
    "    # Windowing\n",
    "    self.window_size = window_size\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset) - self.window_size\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # return as a tensor\n",
    "    print(f\"Index: {idx}\")\n",
    "    return torch.tensor(self.dataset.iloc[idx].values)\n",
    "\n",
    "  def get_dataframe(self):\n",
    "    return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating the dataframes (1953)\n",
      "Dataset shape: (1953, 71)\n",
      "Dataset length: 1952, Number of files used (Task 1: 1 + Task 2: 1 + Task 3: 1 + Task 4: 1)\n",
      "Unique values of the labels: [1 2 3 4]\n",
      "Data: 1953 ,Train size: 1411, Val size: 249, Test size: 293\n"
     ]
    }
   ],
   "source": [
    "dataset = DatasetApproach4()\n",
    "print(f\"Dataset length: {len(dataset)}, Number of files used (Task 1: {len(dataset_task_mapping['task_1'])} + Task 2: {len(dataset_task_mapping['task_2'])} + Task 3: {len(dataset_task_mapping['task_3'])} + Task 4: {len(dataset_task_mapping['task_4'])})\")\n",
    "print(f\"Unique values of the labels: {dataset.get_dataframe()['labels'].unique()}\")\n",
    "dataset_labels = dataset.get_dataframe()['labels'].unique().tolist()\n",
    "\n",
    "# Shuffle the rows of the dataset using sklearn (making sure the shuffle is reproducible)\n",
    "from sklearn.utils import shuffle\n",
    "data = shuffle(dataset.get_dataframe(), random_state=0)\n",
    "# Remove the index column\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Splitting into train and test sets (80% training data, 20% testing data)\n",
    "train_df, test_df = train_test_split(data, test_size=0.15, random_state=42)\n",
    "\n",
    "# Splitting the train_df further into train and validation sets (70% training data, 30% validation data)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.15, random_state=42)\n",
    "\n",
    "print(f\"Data: {len(data)} ,Train size: {len(train_df)}, Val size: {len(val_df)}, Test size: {len(test_df)}\")\n",
    "\n",
    "#Create the Dataframe class Approach 3\n",
    "class DataFrameApproach4(Dataset):\n",
    "    def __init__(self, dataframe, selected_columns=None):\n",
    "        # Set as data the columns from the parameter selected_columns if are passed, otherwise set all the columns except the last one\n",
    "        if selected_columns:\n",
    "            self.data = dataframe.iloc[:, selected_columns].values\n",
    "        else:\n",
    "            self.data = dataframe.iloc[:, :-1].values\n",
    "\n",
    "        self.targets = dataframe.iloc[:, -1].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.data[idx])\n",
    "        y = self.targets[idx]\n",
    "        return x, y\n",
    "def collate_fn(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "\n",
    "    # Apply min-max normalization to each column\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(data)\n",
    "\n",
    "    return torch.tensor(normalized_data), targets\n",
    "\n",
    "# Creating datasets and data loaders for each split\n",
    "selected_columns = [17,18,19,52,53,54]\n",
    "# train_dataset = DataFrameApproach4(train_df, selected_columns)\n",
    "# val_dataset = DataFrameApproach4(val_df, selected_columns)\n",
    "# test_dataset = DataFrameApproach4(test_df, selected_columns)\n",
    "train_dataset = DataFrameApproach4(train_df)\n",
    "val_dataset = DataFrameApproach4(val_df)\n",
    "test_dataset = DataFrameApproach4(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, window_size = 1, enable_sparsity_loss=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(128),\n",
    "        )\n",
    "\n",
    "        # Apply He initialization to the linear layers\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, input_dim = x.size()  # Obtain the shape of the input [bs, input_dim]\n",
    "        input = x\n",
    "        x = self.encoder(input)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, window_size, enable_sparsity_loss=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, window_size * input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Apply He initialization to the linear layers\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.to(torch.float32)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AE Lightning Module ⚡️⚡️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(LightningModule):\n",
    "    def __init__(self, input_dim, batch_size, sparsity_factor=0.1, sparsity_loss_coef = 1e-3, weight_decay=0.001, window_size=window_size, enable_sparsity_loss=False, enable_weight_decay_loss=False ,enable_non_negativity_constraint=False,enable_wandb = False, decoder_none=False):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        if( enable_sparsity_loss == True and enable_non_negativity_constraint== True):\n",
    "          print(\"The combination of constraints enable_sparsity_loss and enable_non_negativity_constraint both true leads to error in to the model matrix multiplication. This will be solved by setting enable_non_negativity_constraint to False.\")\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.encoder = Encoder(input_dim=input_dim, window_size=window_size, enable_sparsity_loss = enable_sparsity_loss)\n",
    "        if not decoder_none:\n",
    "          self.decoder = Decoder(input_dim=input_dim, window_size=window_size, enable_sparsity_loss = enable_sparsity_loss)\n",
    "        self.train_loss_memory = []\n",
    "        self.train_rec_loss_memory = []\n",
    "\n",
    "        self.val_loss_memory = []\n",
    "        self.val_rec_loss_memory = []\n",
    "\n",
    "        self.test_loss_memory = []\n",
    "        self.test_rec_loss_memory = []\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "\n",
    "\n",
    "        # --- Loss Settings\n",
    "        self.enable_sparsity_loss = enable_sparsity_loss\n",
    "        if enable_sparsity_loss:\n",
    "          self.sparsity_loss_coef = sparsity_loss_coef\n",
    "          self.sparsity_factor = sparsity_factor\n",
    "          print(f\"Enabled Sparsity term in the loss with sparsity loss coeff => {self.sparsity_loss_coef} and sparsity factor=>{self.sparsity_factor}\")\n",
    "\n",
    "          # self.sparsity_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "          # Memory logs for sparsity\n",
    "          self.train_sparsity_loss_memory = []\n",
    "          self.val_sparsity_loss_memory = []\n",
    "          self.test_sparsity_loss_memory = []\n",
    "\n",
    "          self.enable_non_negativity_constraint = False\n",
    "        else:\n",
    "          self.enable_non_negativity_constraint = enable_non_negativity_constraint\n",
    "          if enable_non_negativity_constraint:\n",
    "            print(\"Enabled non negativity constraint\")\n",
    "\n",
    "\n",
    "        self.enable_weight_decay_loss = enable_weight_decay_loss\n",
    "        if enable_weight_decay_loss:\n",
    "          print(\"Enabled weight decay\")\n",
    "          self.weight_decay = weight_decay\n",
    "\n",
    "        self.wandb_log = enable_wandb\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        if torch.cuda.is_available():\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                device = torch.device('cuda:0')\n",
    "                print('Using device:', device)\n",
    "            else:\n",
    "                device = torch.device('cuda')\n",
    "                print('Using device:', device)\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "            print('Using device:', device)\n",
    "\n",
    "\n",
    "        print('Using device:', device)\n",
    "\n",
    "        self.to(device)\n",
    "        print(f\"Initialized Model on {self.device}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "    def kl_div(self, p, p_hat):\n",
    "      funcs = nn.Sigmoid()\n",
    "      p_hat = torch.mean(funcs(p_hat), 1)\n",
    "      p_tensor = torch.Tensor([p] * p_hat.shape[0]).to(self.device)\n",
    "\n",
    "\n",
    "      return torch.sum(p_tensor * torch.log(p_tensor) - p_tensor * torch.log(p_hat) + (1 - p_tensor) * torch.log(1 - p_tensor) - (1 - p_tensor) * torch.log(1 - p_hat))\n",
    "\n",
    "    def sparse_loss(self, values):\n",
    "      loss = 0\n",
    "      values = values.view(self.batch_size, -1)\n",
    "\n",
    "      # Encoder sparsity\n",
    "      lyrs_encoder = list(self.encoder.encoder.children())\n",
    "      for i, lyr in enumerate(lyrs_encoder):\n",
    "          if isinstance(lyr, nn.Linear):\n",
    "            values = lyr(values)\n",
    "            # loss += self.sparsity_loss(torch.tensor([self.sparsity_factor]).to(self.device), values.to(self.device))\n",
    "            loss += self.kl_div(self.sparsity_factor, values.to(self.device))\n",
    "\n",
    "      # Decoder sparsity\n",
    "      lyrs_decoder = list(self.decoder.decoder.children())\n",
    "      for i, lyr in enumerate(lyrs_decoder):\n",
    "          if isinstance(lyr, nn.Linear):\n",
    "              values = lyr(values)\n",
    "              # loss += self.sparsity_loss(torch.tensor([self.sparsity_factor]).to(self.device), values.to(self.device))\n",
    "              loss += self.kl_div(self.sparsity_factor, values.to(self.device))\n",
    "\n",
    "      return loss\n",
    "\n",
    "    def calculate_weight_decay_loss(self):\n",
    "        weight_decay_loss = 0.0\n",
    "        for param in self.parameters():\n",
    "            weight_decay_loss += 0.5 * self.weight_decay * torch.norm(param, p=2) ** 2\n",
    "        return weight_decay_loss\n",
    "\n",
    "    def enforce_non_negativity(self):\n",
    "      for param in self.parameters():\n",
    "        param.data.clamp_(min=0, max=None)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch[0].to(torch.float32) #[bs, input_dim]\n",
    "        _, reconstructions = self(x)\n",
    "\n",
    "        x = x.view(-1) # [bs * input_dim]\n",
    "        reconstructions = reconstructions.view(-1)\n",
    "\n",
    "        loss_mse = nn.MSELoss()(reconstructions, x)\n",
    "        loss = loss_mse\n",
    "\n",
    "        if self.enable_sparsity_loss:\n",
    "          # sparsity_loss = self.sparsity_loss(torch.log(reconstructions).to(self.device), torch.tensor([self.sparsity_factor]).to(self.device))\n",
    "          sparsity_loss = self.sparse_loss(x) * self.sparsity_loss_coef\n",
    "          loss += sparsity_loss\n",
    "          self.train_sparsity_loss_memory.append(sparsity_loss)\n",
    "\n",
    "        if self.enable_weight_decay_loss:\n",
    "          weight_decay_loss = self.calculate_weight_decay_loss()\n",
    "          loss += weight_decay_loss\n",
    "\n",
    "        self.train_loss_memory.append(loss)\n",
    "        self.train_rec_loss_memory.append(loss_mse)\n",
    "\n",
    "        if self.wandb_log:\n",
    "          wandb.log({\"train_total_loss\": loss})\n",
    "          wandb.log({\"train_reconstruction_loss\": loss_mse})\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "      x = batch[0].to(torch.float32)\n",
    "      _, reconstructions = self(x)\n",
    "\n",
    "      x = x.view(-1) #[]\n",
    "      reconstructions = reconstructions.view(-1)\n",
    "\n",
    "      loss_mse = nn.MSELoss()(reconstructions, x)\n",
    "      loss = loss_mse\n",
    "\n",
    "      if self.enable_sparsity_loss:\n",
    "        # sparsity_loss = self.sparsity_loss(torch.log(reconstructions).to(self.device), torch.tensor([self.sparsity_factor]).to(self.device))\n",
    "        sparsity_loss = self.sparse_loss(x) * self.sparsity_loss_coef\n",
    "        loss += sparsity_loss\n",
    "        self.val_sparsity_loss_memory.append(sparsity_loss)\n",
    "\n",
    "      if self.enable_weight_decay_loss:\n",
    "        weight_decay_loss = self.calculate_weight_decay_loss()\n",
    "        loss += weight_decay_loss\n",
    "\n",
    "      if self.enable_non_negativity_constraint:\n",
    "        self.enforce_non_negativity()\n",
    "\n",
    "      self.val_loss_memory.append(loss)\n",
    "      self.val_rec_loss_memory.append(loss_mse)\n",
    "\n",
    "      if self.wandb_log:\n",
    "        wandb.log({\"val_total_loss\": loss})\n",
    "        wandb.log({\"val_reconstruction_loss\": loss_mse})\n",
    "\n",
    "      # For early stop and Model checkpoint callbacks\n",
    "      self.log(\"val_reconstruction_loss\",loss_mse)\n",
    "\n",
    "      return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "      x = batch[0].to(torch.float32)\n",
    "      _, reconstructions = self(x)\n",
    "\n",
    "      x = x.view(-1) #[]\n",
    "      reconstructions = reconstructions.view(-1)\n",
    "\n",
    "      loss_mse = nn.MSELoss()(reconstructions, x)\n",
    "      loss = loss_mse\n",
    "\n",
    "      if self.enable_sparsity_loss:\n",
    "        # sparsity_loss = self.sparsity_loss(torch.log(reconstructions).to(self.device), torch.tensor([self.sparsity_factor]).to(self.device))\n",
    "        sparsity_loss = self.sparse_loss(x) * self.sparsity_loss_coef\n",
    "        loss += sparsity_loss\n",
    "        self.test_sparsity_loss_memory.append(sparsity_loss)\n",
    "\n",
    "      if self.enable_weight_decay_loss:\n",
    "        weight_decay_loss = self.calculate_weight_decay_loss()\n",
    "        loss += weight_decay_loss\n",
    "\n",
    "      if self.enable_non_negativity_constraint:\n",
    "        self.enforce_non_negativity()\n",
    "\n",
    "      self.test_loss_memory.append(loss)\n",
    "      self.test_rec_loss_memory.append(loss_mse)\n",
    "\n",
    "\n",
    "      return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=10)  # Adjust T_max as needed\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': {'scheduler': scheduler, 'interval': 'epoch'}}\n",
    "\n",
    "    def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_closure):\n",
    "        # step\n",
    "        optimizer.step(closure=optimizer_closure)\n",
    "\n",
    "        if self.enable_non_negativity_constraint:\n",
    "          self.enforce_non_negativity()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.wandb_log:\n",
    "            wandb.log({'epoch': self.current_epoch})\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # Access the training loss from the outputs\n",
    "        train_loss = torch.stack([x for x in self.train_loss_memory]).mean()\n",
    "        train_rec_loss = torch.stack([x for x in self.train_rec_loss_memory]).mean()\n",
    "\n",
    "        # Print the training loss\n",
    "        print_log = f'Training Loss - Epoch {self.current_epoch}: Total Loss => {train_loss.item()} MSE => {train_rec_loss}'\n",
    "\n",
    "        self.train_loss_memory.clear()\n",
    "        self.train_rec_loss_memory.clear()\n",
    "\n",
    "        if self.enable_sparsity_loss:\n",
    "          train_sparsity_loss = torch.stack([x for x in self.train_sparsity_loss_memory]).mean()\n",
    "          print_log += f' SPARSE => {train_sparsity_loss}'\n",
    "          self.train_sparsity_loss_memory.clear()\n",
    "\n",
    "        if self.wandb_log:\n",
    "          wandb.log({\"train_total_loss\": train_loss})\n",
    "          wandb.log({\"train_reconstruction_loss\": train_rec_loss})\n",
    "          if self.enable_sparsity_loss:\n",
    "            wandb.log({\"train_sparse_loss\": train_sparsity_loss})\n",
    "\n",
    "        print(print_log)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Access the training loss from the outputs\n",
    "        val_loss = torch.stack([x for x in self.val_loss_memory]).mean()\n",
    "        val_rec_loss = torch.stack([x for x in self.val_rec_loss_memory]).mean()\n",
    "\n",
    "        # Print the training loss\n",
    "        print_log = f'Validation Loss - Epoch {self.current_epoch}: Total Loss => {val_loss.item()} MSE => {val_rec_loss}'\n",
    "\n",
    "        self.val_loss_memory.clear()\n",
    "        self.val_rec_loss_memory.clear()\n",
    "\n",
    "        if self.enable_sparsity_loss:\n",
    "          val_sparsity_loss = torch.stack([x for x in self.val_sparsity_loss_memory]).mean()\n",
    "          print_log += f' SPARSE => {val_sparsity_loss}'\n",
    "          self.val_sparsity_loss_memory.clear()\n",
    "\n",
    "        if self.wandb_log:\n",
    "          wandb.log({\"val_total_loss\": val_loss})\n",
    "          wandb.log({\"val_reconstruction_loss\": val_rec_loss})\n",
    "          if self.enable_sparsity_loss:\n",
    "            wandb.log({\"val_sparse_loss\": val_sparsity_loss})\n",
    "\n",
    "        print(print_log)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # Access the training loss from the outputs\n",
    "        test_loss = torch.stack([x for x in self.test_loss_memory]).mean()\n",
    "        test_rec_loss = torch.stack([x for x in self.test_rec_loss_memory]).mean()\n",
    "\n",
    "        # Print the training loss\n",
    "        print_log = f'Test Loss - Epoch {self.current_epoch}: Total Loss => {test_loss.item()} MSE => {test_rec_loss}'\n",
    "\n",
    "        self.test_loss_memory.clear()\n",
    "        self.test_rec_loss_memory.clear()\n",
    "\n",
    "        if self.enable_sparsity_loss:\n",
    "          test_sparsity_loss = torch.stack([x for x in self.test_sparsity_loss_memory]).mean()\n",
    "          print_log += f' SPARSE => {test_sparsity_loss}'\n",
    "          self.test_sparsity_loss_memory.clear()\n",
    "\n",
    "        if self.wandb_log:\n",
    "          wandb.log({\"test_total_loss\": test_loss})\n",
    "          wandb.log({\"test_reconstruction_loss\": test_rec_loss})\n",
    "          if self.enable_sparsity_loss:\n",
    "            wandb.log({\"test_sparse_loss\": test_sparsity_loss})\n",
    "\n",
    "        self.test_rec_loss = test_rec_loss\n",
    "\n",
    "        print(print_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constrastive Learner Model 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a mapping utility to go from label to idx and vice versa\n",
    "label2idx= {}\n",
    "idx2label = {}\n",
    "labels_task = dataset.get_dataframe()['labels'].unique()\n",
    "\n",
    "for i in range(len(labels_task)):\n",
    "  label2idx[labels_task[i]] = i\n",
    "  idx2label[str(i)] = labels_task[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstrastiveLearner(LightningModule):\n",
    "  def __init__(self, encoder=None, loss=None, run_name=\"finetuning\", enable_wandb=False, input_dim=None):\n",
    "    super(ConstrastiveLearner, self).__init__()\n",
    "    self.save_hyperparameters()\n",
    "\n",
    "    if encoder is None:\n",
    "      print(\"Initialize an encoder from scratch\")\n",
    "      encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.4)\n",
    "      )\n",
    "      self.apply(self._init_weights)\n",
    "\n",
    "    self.encoder = encoder\n",
    "\n",
    "    if loss is None:\n",
    "      loss =  InfoNCE(negative_mode='unpaired') # negative_mode='unpaired' is the default value\n",
    "\n",
    "    self.loss = loss\n",
    "    self.enable_wandb = enable_wandb\n",
    "\n",
    "    self.train_loss = []\n",
    "    self.val_loss = []\n",
    "    self.test_loss = []\n",
    "\n",
    "    self.lr = 0.001\n",
    "    self.scheduler_step = 20\n",
    "    self.scheduler_decay = 1.0\n",
    "\n",
    "    self.run_name = run_name\n",
    "    if self.enable_wandb:\n",
    "        wandb.init(project=\"Project_EAI_BrainComputerInterface\", entity=\"rucci-2053183\", group=\"approach4_contrastive\", name=self.run_name)\n",
    "\n",
    "  def _init_weights(self, module):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    data,labels = batch\n",
    "    data = data.to(torch.float32)\n",
    "    data = self.encoder(data)\n",
    "    labels = self.labels2TargetTensor(labels).to(torch.long)\n",
    "\n",
    "    # Sort data samples by labels\n",
    "    sort = torch.sort(labels)\n",
    "    data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "    labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "\n",
    "    loss = self.loss_computation(data,labels)\n",
    "    self.train_loss.append(loss)\n",
    "\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    data,labels = batch\n",
    "    data = data.to(torch.float32)\n",
    "    data = self.encoder(data)\n",
    "    labels = self.labels2TargetTensor(labels).to(torch.long)\n",
    "\n",
    "    # Sort data samples by labels\n",
    "    sort = torch.sort(labels)\n",
    "    data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "    labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "\n",
    "    loss = self.loss_computation(data,labels)\n",
    "    self.val_loss.append(loss)\n",
    "\n",
    "    return loss\n",
    "\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    data,labels = batch\n",
    "    data = data.to(torch.float32)\n",
    "    data = self.encoder(data)\n",
    "    labels = self.labels2TargetTensor(labels).to(torch.long)\n",
    "\n",
    "    # Sort data samples by labels\n",
    "    sort = torch.sort(labels)\n",
    "    data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "    labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "\n",
    "    loss = self.loss_computation(data,labels)\n",
    "    self.test_loss.append(loss)\n",
    "\n",
    "    return loss\n",
    "\n",
    "  def on_train_epoch_end(self):\n",
    "    train_loss = torch.stack([x for x in self.train_loss]).mean()\n",
    "    print_log = f'Training - Epoch {self.current_epoch}: Loss => {train_loss.item()}'\n",
    "\n",
    "    self.train_loss.clear()\n",
    "\n",
    "    if self.enable_wandb:\n",
    "        wandb.log({\"epoch_train_loss\": train_loss})\n",
    "\n",
    "    print(print_log)\n",
    "\n",
    "  def on_validation_epoch_end(self):\n",
    "    val_loss = torch.stack([x for x in self.val_loss]).mean()\n",
    "    print_log = f'Validation - Epoch {self.current_epoch}: Loss => {val_loss.item()}'\n",
    "\n",
    "    self.val_loss.clear()\n",
    "\n",
    "    self.log(\"epoch_val_loss\",val_loss)\n",
    "    if self.enable_wandb:\n",
    "        wandb.log({\"epoch_val_loss\": val_loss})\n",
    "\n",
    "    print(print_log)\n",
    "\n",
    "  def on_test_epoch_end(self):\n",
    "    test_loss = torch.stack([x for x in self.test_loss]).mean()\n",
    "    print_log = f'Test - Epoch {self.current_epoch}: Loss => {test_loss.item()}'\n",
    "\n",
    "    # self.test_loss.clear()\n",
    "\n",
    "    if self.enable_wandb:\n",
    "        wandb.log({\"epoch_test_loss\": test_loss})\n",
    "\n",
    "    print(print_log)\n",
    "    return test_loss\n",
    "\n",
    "  def labels2TargetTensor(self, labels):\n",
    "    target = []\n",
    "    for item in labels:\n",
    "      target.append(label2idx[item])\n",
    "\n",
    "    return torch.Tensor(target)\n",
    "\n",
    "  def loss_computation(self, data,labels):\n",
    "    '''\n",
    "      data => tensor of size [bs, z_dim]\n",
    "      labels => list of lenght bs\n",
    "    '''\n",
    "\n",
    "    # for each element in the batch, selection of the positive and negative samples\n",
    "    # The positive samples are the ones that have the same label\n",
    "    # The negative samples are the ones that have different labels\n",
    "    sample_losses = []\n",
    "    for i in range (data.size(0)):\n",
    "      # Positive samples\n",
    "      positive_samples = data[labels == labels[i]]\n",
    "      # Negative samples\n",
    "      negative_samples = data[labels != labels[i]]\n",
    "\n",
    "\n",
    "      # From positive samples, take one sample\n",
    "      subset_size = 1\n",
    "      indices = torch.randperm(positive_samples.size(0))[:subset_size]\n",
    "      positive_samples = positive_samples[indices]\n",
    "\n",
    "\n",
    "      # From negative samples, take a random subset composed of 60% of the negative samples\n",
    "      subset_size = int(0.6 * negative_samples.size(0))\n",
    "      indices = torch.randperm(negative_samples.size(0))[:subset_size]\n",
    "      negative_samples = negative_samples[indices]\n",
    "\n",
    "      # Compute the loss\n",
    "      loss = self.loss(data[i].unsqueeze(0), positive_samples, negative_samples)\n",
    "      sample_losses.append(loss)\n",
    "\n",
    "    # Compute the mean loss\n",
    "    loss = torch.mean(torch.stack(sample_losses), dim=-1)\n",
    "    return loss\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=self.scheduler_step,\n",
    "        gamma=self.scheduler_decay,\n",
    "    )\n",
    "    return [optimizer], [lr_scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetuning of pretrained autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model using the pretrained encoder for finetuning\n",
    "\n",
    "# Import the best pretrained encoder\n",
    "base_model_dir = \"saved_models/Approach_2_FeaturesDataset\"\n",
    "best_model_path = base_model_dir+\"/ae/6/last.ckpt\"\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True,)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "input_dim = batch[0].shape[-1]\n",
    "checkpoint_model = Autoencoder(input_dim=input_dim, batch_size = batch_size,sparsity_factor=0.005,enable_sparsity_loss=False, enable_weight_decay_loss=False, enable_non_negativity_constraint=False, enable_wandb = False)\n",
    "checkpoint_model.load_state_dict(torch.load(best_model_path, map_location=checkpoint_model.device)['state_dict']) # ------> PyTorch Lightning API\n",
    "\n",
    "run_name=\"finetuning_features_dataset\"\n",
    "finetuner = ConstrastiveLearner(encoder=checkpoint_model.encoder, enable_wandb=True, run_name=run_name)\n",
    "dirpath = \"saved_models/Approach_4_featuresDataset/finetuning/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train autoencoder from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize an encoder from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrucci-2053183\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/wandb/run-20240605_211931-4lry2vr2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface/runs/4lry2vr2' target=\"_blank\">from_scratch_features_dataset</a></strong> to <a href='https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface' target=\"_blank\">https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface/runs/4lry2vr2' target=\"_blank\">https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface/runs/4lry2vr2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate the model using an encoder that will be trained from scratch\n",
    "run_name=\"from_scratch_features_dataset\"\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True,)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "input_dim = batch[0].shape[-1]\n",
    "finetuner = ConstrastiveLearner(encoder=None, enable_wandb=True, run_name=run_name, input_dim=input_dim)\n",
    "\n",
    "# Generate experiment name taking the last folder in dirpath (version_x) and call the experiment with the next version ( if there is no version, the version will be 0)\n",
    "dirpath = \"saved_models/Approach_4_featuresDataset/from_scratch/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment will be saved in saved_models/Approach_4_featuresDataset/from_scratch/version_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "Missing logger folder: saved_models/Approach_4_featuresDataset/from_scratch/version_2/lightning_logs\n",
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/saved_models/Approach_4_featuresDataset/from_scratch/version_2 exists and is not empty.\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 13.5 K\n",
      "1 | loss    | InfoNCE    | 0     \n",
      "---------------------------------------\n",
      "13.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "13.5 K    Total params\n",
      "0.054     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 18.18it/s]Validation - Epoch 0: Loss => 3.333550453186035\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (22) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 22/22 [00:01<00:00, 17.93it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric epoch_val_loss improved. New best score: 3.614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 0: Loss => 3.6135711669921875\n",
      "Epoch 0: 100%|██████████| 22/22 [00:01<00:00, 16.84it/s, v_num=0]Training - Epoch 0: Loss => 4.68012809753418\n",
      "Epoch 1: 100%|██████████| 22/22 [00:01<00:00, 21.39it/s, v_num=0]Validation - Epoch 1: Loss => 4.5884294509887695\n",
      "Epoch 1: 100%|██████████| 22/22 [00:01<00:00, 19.98it/s, v_num=0]Training - Epoch 1: Loss => 4.6250176429748535\n",
      "Epoch 2: 100%|██████████| 22/22 [00:01<00:00, 21.24it/s, v_num=0]Validation - Epoch 2: Loss => 4.922732830047607\n",
      "Epoch 2: 100%|██████████| 22/22 [00:01<00:00, 19.89it/s, v_num=0]Training - Epoch 2: Loss => 4.668706893920898\n",
      "Epoch 3: 100%|██████████| 22/22 [00:01<00:00, 18.60it/s, v_num=0]Validation - Epoch 3: Loss => 4.9838409423828125\n",
      "Epoch 3: 100%|██████████| 22/22 [00:01<00:00, 17.51it/s, v_num=0]Training - Epoch 3: Loss => 4.624251842498779\n",
      "Epoch 4: 100%|██████████| 22/22 [00:01<00:00, 21.19it/s, v_num=0]Validation - Epoch 4: Loss => 4.834549427032471\n",
      "Epoch 4: 100%|██████████| 22/22 [00:01<00:00, 19.83it/s, v_num=0]Training - Epoch 4: Loss => 4.6070733070373535\n",
      "Epoch 5: 100%|██████████| 22/22 [00:01<00:00, 20.97it/s, v_num=0]Validation - Epoch 5: Loss => 4.863399028778076\n",
      "Epoch 5: 100%|██████████| 22/22 [00:01<00:00, 19.63it/s, v_num=0]Training - Epoch 5: Loss => 4.5190863609313965\n",
      "Epoch 6: 100%|██████████| 22/22 [00:01<00:00, 21.41it/s, v_num=0]Validation - Epoch 6: Loss => 5.107888698577881\n",
      "Epoch 6: 100%|██████████| 22/22 [00:01<00:00, 20.02it/s, v_num=0]Training - Epoch 6: Loss => 4.759817123413086\n",
      "Epoch 7: 100%|██████████| 22/22 [00:01<00:00, 20.52it/s, v_num=0]Validation - Epoch 7: Loss => 4.856482028961182\n",
      "Epoch 7: 100%|██████████| 22/22 [00:01<00:00, 19.01it/s, v_num=0]Training - Epoch 7: Loss => 4.525134563446045\n",
      "Epoch 8: 100%|██████████| 22/22 [00:01<00:00, 18.46it/s, v_num=0]Validation - Epoch 8: Loss => 4.665490627288818\n",
      "Epoch 8: 100%|██████████| 22/22 [00:01<00:00, 17.25it/s, v_num=0]Training - Epoch 8: Loss => 4.468918323516846\n",
      "Epoch 9: 100%|██████████| 22/22 [00:01<00:00, 19.66it/s, v_num=0]Validation - Epoch 9: Loss => 4.755795001983643\n",
      "Epoch 9: 100%|██████████| 22/22 [00:01<00:00, 18.43it/s, v_num=0]Training - Epoch 9: Loss => 4.485691547393799\n",
      "Epoch 10: 100%|██████████| 22/22 [00:01<00:00, 20.71it/s, v_num=0]Validation - Epoch 10: Loss => 5.036919116973877\n",
      "Epoch 10: 100%|██████████| 22/22 [00:01<00:00, 19.44it/s, v_num=0]Training - Epoch 10: Loss => 4.557583808898926\n",
      "Epoch 11: 100%|██████████| 22/22 [00:01<00:00, 21.12it/s, v_num=0]Validation - Epoch 11: Loss => 4.35803747177124\n",
      "Epoch 11: 100%|██████████| 22/22 [00:01<00:00, 19.75it/s, v_num=0]Training - Epoch 11: Loss => 4.532687664031982\n",
      "Epoch 12: 100%|██████████| 22/22 [00:01<00:00, 19.77it/s, v_num=0]Validation - Epoch 12: Loss => 5.0687174797058105\n",
      "Epoch 12: 100%|██████████| 22/22 [00:01<00:00, 18.53it/s, v_num=0]Training - Epoch 12: Loss => 4.5099778175354\n",
      "Epoch 13: 100%|██████████| 22/22 [00:01<00:00, 20.61it/s, v_num=0]Validation - Epoch 13: Loss => 4.855129718780518\n",
      "Epoch 13: 100%|██████████| 22/22 [00:01<00:00, 18.18it/s, v_num=0]Training - Epoch 13: Loss => 4.467981338500977\n",
      "Epoch 14: 100%|██████████| 22/22 [00:01<00:00, 19.82it/s, v_num=0]Validation - Epoch 14: Loss => 4.838907241821289\n",
      "Epoch 14: 100%|██████████| 22/22 [00:01<00:00, 18.51it/s, v_num=0]Training - Epoch 14: Loss => 4.525001525878906\n",
      "Epoch 15: 100%|██████████| 22/22 [00:01<00:00, 19.66it/s, v_num=0]Validation - Epoch 15: Loss => 4.451106548309326\n",
      "Epoch 15: 100%|██████████| 22/22 [00:01<00:00, 18.52it/s, v_num=0]Training - Epoch 15: Loss => 4.48253059387207\n",
      "Epoch 16: 100%|██████████| 22/22 [00:01<00:00, 21.33it/s, v_num=0]Validation - Epoch 16: Loss => 4.862704753875732\n",
      "Epoch 16: 100%|██████████| 22/22 [00:01<00:00, 19.95it/s, v_num=0]Training - Epoch 16: Loss => 4.507342338562012\n",
      "Epoch 17: 100%|██████████| 22/22 [00:01<00:00, 20.85it/s, v_num=0]Validation - Epoch 17: Loss => 5.002265453338623\n",
      "Epoch 17: 100%|██████████| 22/22 [00:01<00:00, 19.57it/s, v_num=0]Training - Epoch 17: Loss => 4.395724773406982\n",
      "Epoch 18: 100%|██████████| 22/22 [00:01<00:00, 21.30it/s, v_num=0]Validation - Epoch 18: Loss => 4.906952381134033\n",
      "Epoch 18: 100%|██████████| 22/22 [00:01<00:00, 19.93it/s, v_num=0]Training - Epoch 18: Loss => 4.455657482147217\n",
      "Epoch 19: 100%|██████████| 22/22 [00:01<00:00, 21.09it/s, v_num=0]Validation - Epoch 19: Loss => 4.685945987701416\n",
      "Epoch 19: 100%|██████████| 22/22 [00:01<00:00, 19.77it/s, v_num=0]Training - Epoch 19: Loss => 4.4400553703308105\n",
      "Epoch 20: 100%|██████████| 22/22 [00:01<00:00, 20.25it/s, v_num=0]Validation - Epoch 20: Loss => 4.502020835876465\n",
      "Epoch 20: 100%|██████████| 22/22 [00:01<00:00, 18.83it/s, v_num=0]Training - Epoch 20: Loss => 4.4231672286987305\n",
      "Epoch 21: 100%|██████████| 22/22 [00:01<00:00, 20.59it/s, v_num=0]Validation - Epoch 21: Loss => 4.5734405517578125\n",
      "Epoch 21: 100%|██████████| 22/22 [00:01<00:00, 19.35it/s, v_num=0]Training - Epoch 21: Loss => 4.375464916229248\n",
      "Epoch 22: 100%|██████████| 22/22 [00:01<00:00, 21.25it/s, v_num=0]Validation - Epoch 22: Loss => 4.2288408279418945\n",
      "Epoch 22: 100%|██████████| 22/22 [00:01<00:00, 19.90it/s, v_num=0]Training - Epoch 22: Loss => 4.3052473068237305\n",
      "Epoch 23: 100%|██████████| 22/22 [00:01<00:00, 21.01it/s, v_num=0]Validation - Epoch 23: Loss => 4.670110702514648\n",
      "Epoch 23: 100%|██████████| 22/22 [00:01<00:00, 19.65it/s, v_num=0]Training - Epoch 23: Loss => 4.377245903015137\n",
      "Epoch 24: 100%|██████████| 22/22 [00:01<00:00, 17.79it/s, v_num=0]Validation - Epoch 24: Loss => 4.954641819000244\n",
      "Epoch 24: 100%|██████████| 22/22 [00:01<00:00, 16.67it/s, v_num=0]Training - Epoch 24: Loss => 4.222233295440674\n",
      "Epoch 25: 100%|██████████| 22/22 [00:01<00:00, 19.13it/s, v_num=0]Validation - Epoch 25: Loss => 4.7148356437683105\n",
      "Epoch 25: 100%|██████████| 22/22 [00:01<00:00, 17.86it/s, v_num=0]Training - Epoch 25: Loss => 4.294522285461426\n",
      "Epoch 26: 100%|██████████| 22/22 [00:01<00:00, 19.50it/s, v_num=0]Validation - Epoch 26: Loss => 4.53640604019165\n",
      "Epoch 26: 100%|██████████| 22/22 [00:01<00:00, 18.33it/s, v_num=0]Training - Epoch 26: Loss => 4.388793468475342\n",
      "Epoch 27: 100%|██████████| 22/22 [00:01<00:00, 18.90it/s, v_num=0]Validation - Epoch 27: Loss => 4.723369121551514\n",
      "Epoch 27: 100%|██████████| 22/22 [00:01<00:00, 17.64it/s, v_num=0]Training - Epoch 27: Loss => 4.356130123138428\n",
      "Epoch 28: 100%|██████████| 22/22 [00:01<00:00, 18.00it/s, v_num=0]Validation - Epoch 28: Loss => 4.551693439483643\n",
      "Epoch 28: 100%|██████████| 22/22 [00:01<00:00, 17.03it/s, v_num=0]Training - Epoch 28: Loss => 4.336360454559326\n",
      "Epoch 29: 100%|██████████| 22/22 [00:01<00:00, 20.74it/s, v_num=0]Validation - Epoch 29: Loss => 4.185123920440674\n",
      "Epoch 29: 100%|██████████| 22/22 [00:01<00:00, 19.43it/s, v_num=0]Training - Epoch 29: Loss => 4.282254695892334\n",
      "Epoch 30: 100%|██████████| 22/22 [00:01<00:00, 20.61it/s, v_num=0]Validation - Epoch 30: Loss => 4.590074062347412\n",
      "Epoch 30: 100%|██████████| 22/22 [00:01<00:00, 19.33it/s, v_num=0]Training - Epoch 30: Loss => 4.280959606170654\n",
      "Epoch 31: 100%|██████████| 22/22 [00:01<00:00, 20.97it/s, v_num=0]Validation - Epoch 31: Loss => 4.96926736831665\n",
      "Epoch 31: 100%|██████████| 22/22 [00:01<00:00, 19.63it/s, v_num=0]Training - Epoch 31: Loss => 4.247614860534668\n",
      "Epoch 32: 100%|██████████| 22/22 [00:01<00:00, 21.37it/s, v_num=0]Validation - Epoch 32: Loss => 4.2446064949035645\n",
      "Epoch 32: 100%|██████████| 22/22 [00:01<00:00, 19.92it/s, v_num=0]Training - Epoch 32: Loss => 4.334144115447998\n",
      "Epoch 33: 100%|██████████| 22/22 [00:01<00:00, 21.25it/s, v_num=0]Validation - Epoch 33: Loss => 4.827798366546631\n",
      "Epoch 33: 100%|██████████| 22/22 [00:01<00:00, 19.90it/s, v_num=0]Training - Epoch 33: Loss => 4.278125286102295\n",
      "Epoch 34: 100%|██████████| 22/22 [00:01<00:00, 20.98it/s, v_num=0]Validation - Epoch 34: Loss => 4.859231472015381\n",
      "Epoch 34: 100%|██████████| 22/22 [00:01<00:00, 19.65it/s, v_num=0]Training - Epoch 34: Loss => 4.261873245239258\n",
      "Epoch 35: 100%|██████████| 22/22 [00:01<00:00, 21.32it/s, v_num=0]Validation - Epoch 35: Loss => 4.4661173820495605\n",
      "Epoch 35: 100%|██████████| 22/22 [00:01<00:00, 19.88it/s, v_num=0]Training - Epoch 35: Loss => 4.307699203491211\n",
      "Epoch 36: 100%|██████████| 22/22 [00:01<00:00, 21.28it/s, v_num=0]Validation - Epoch 36: Loss => 4.291252613067627\n",
      "Epoch 36: 100%|██████████| 22/22 [00:01<00:00, 19.91it/s, v_num=0]Training - Epoch 36: Loss => 4.186699390411377\n",
      "Epoch 37: 100%|██████████| 22/22 [00:01<00:00, 20.96it/s, v_num=0]Validation - Epoch 37: Loss => 4.445723533630371\n",
      "Epoch 37: 100%|██████████| 22/22 [00:01<00:00, 19.58it/s, v_num=0]Training - Epoch 37: Loss => 4.357956409454346\n",
      "Epoch 38: 100%|██████████| 22/22 [00:01<00:00, 21.23it/s, v_num=0]Validation - Epoch 38: Loss => 4.709483623504639\n",
      "Epoch 38: 100%|██████████| 22/22 [00:01<00:00, 19.87it/s, v_num=0]Training - Epoch 38: Loss => 4.245096206665039\n",
      "Epoch 39: 100%|██████████| 22/22 [00:01<00:00, 21.34it/s, v_num=0]Validation - Epoch 39: Loss => 4.712250232696533\n",
      "Epoch 39: 100%|██████████| 22/22 [00:01<00:00, 19.95it/s, v_num=0]Training - Epoch 39: Loss => 4.2714643478393555\n",
      "Epoch 40: 100%|██████████| 22/22 [00:01<00:00, 20.19it/s, v_num=0]Validation - Epoch 40: Loss => 4.653870105743408\n",
      "Epoch 40: 100%|██████████| 22/22 [00:01<00:00, 18.96it/s, v_num=0]Training - Epoch 40: Loss => 4.216569900512695\n",
      "Epoch 41: 100%|██████████| 22/22 [00:01<00:00, 21.32it/s, v_num=0]Validation - Epoch 41: Loss => 4.302144527435303\n",
      "Epoch 41: 100%|██████████| 22/22 [00:01<00:00, 19.98it/s, v_num=0]Training - Epoch 41: Loss => 4.2614426612854\n",
      "Epoch 42: 100%|██████████| 22/22 [00:01<00:00, 21.38it/s, v_num=0]Validation - Epoch 42: Loss => 4.677134037017822\n",
      "Epoch 42: 100%|██████████| 22/22 [00:01<00:00, 19.90it/s, v_num=0]Training - Epoch 42: Loss => 4.294083118438721\n",
      "Epoch 43: 100%|██████████| 22/22 [00:01<00:00, 20.94it/s, v_num=0]Validation - Epoch 43: Loss => 4.808129787445068\n",
      "Epoch 43: 100%|██████████| 22/22 [00:01<00:00, 19.63it/s, v_num=0]Training - Epoch 43: Loss => 4.1689934730529785\n",
      "Epoch 44: 100%|██████████| 22/22 [00:01<00:00, 20.85it/s, v_num=0]Validation - Epoch 44: Loss => 4.496978282928467\n",
      "Epoch 44: 100%|██████████| 22/22 [00:01<00:00, 19.54it/s, v_num=0]Training - Epoch 44: Loss => 4.2091450691223145\n",
      "Epoch 45: 100%|██████████| 22/22 [00:01<00:00, 13.88it/s, v_num=0]Validation - Epoch 45: Loss => 4.726179599761963\n",
      "Epoch 45: 100%|██████████| 22/22 [00:01<00:00, 13.29it/s, v_num=0]Training - Epoch 45: Loss => 4.212291240692139\n",
      "Epoch 46: 100%|██████████| 22/22 [00:01<00:00, 21.38it/s, v_num=0]Validation - Epoch 46: Loss => 4.360603332519531\n",
      "Epoch 46: 100%|██████████| 22/22 [00:01<00:00, 19.99it/s, v_num=0]Training - Epoch 46: Loss => 4.152790546417236\n",
      "Epoch 47: 100%|██████████| 22/22 [00:01<00:00, 21.25it/s, v_num=0]Validation - Epoch 47: Loss => 4.467340469360352\n",
      "Epoch 47: 100%|██████████| 22/22 [00:01<00:00, 19.90it/s, v_num=0]Training - Epoch 47: Loss => 4.146664619445801\n",
      "Epoch 48: 100%|██████████| 22/22 [00:01<00:00, 20.81it/s, v_num=0]Validation - Epoch 48: Loss => 3.955064058303833\n",
      "Epoch 48: 100%|██████████| 22/22 [00:01<00:00, 19.43it/s, v_num=0]Training - Epoch 48: Loss => 4.096139907836914\n",
      "Epoch 49: 100%|██████████| 22/22 [00:01<00:00, 21.17it/s, v_num=0]Validation - Epoch 49: Loss => 4.337584018707275\n",
      "Epoch 49: 100%|██████████| 22/22 [00:01<00:00, 19.79it/s, v_num=0]Training - Epoch 49: Loss => 4.080260753631592\n",
      "Epoch 50: 100%|██████████| 22/22 [00:01<00:00, 20.97it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric epoch_val_loss did not improve in the last 50 records. Best score: 3.614. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 50: Loss => 4.399031162261963\n",
      "Epoch 50: 100%|██████████| 22/22 [00:01<00:00, 19.62it/s, v_num=0]Training - Epoch 50: Loss => 4.127140522003174\n",
      "Epoch 50: 100%|██████████| 22/22 [00:01<00:00, 19.25it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "versions = [0]\n",
    "for folder in os.listdir(dirpath):\n",
    "  if \"version\" in folder:\n",
    "    versions.append(int(folder.split(\"_\")[-1]))\n",
    "\n",
    "dirpath = dirpath + \"version_\" + str(max(versions) + 1)\n",
    "print(f\"Experiment will be saved in {dirpath}\")\n",
    "\n",
    "# Callbacks\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='epoch_val_loss',\n",
    "   min_delta=0.00,\n",
    "   patience=50,\n",
    "   verbose=True,\n",
    "   mode='min',\n",
    "   check_on_train_epoch_end=False\n",
    ")\n",
    "\n",
    "# Model checkpoint\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='epoch_val_loss',\n",
    "    dirpath=dirpath,\n",
    "    filename=\"BEST_{epoch:02d}\",\n",
    "    save_top_k=1,\n",
    "    mode='min',\n",
    "    auto_insert_metric_name=True\n",
    ")\n",
    "\n",
    "# Instantiate the trainer\n",
    "trainer_CL = Trainer(max_epochs=10000, default_root_dir=dirpath, fast_dev_run=False, callbacks=[early_stop_callback, checkpoint_callback])\n",
    "# Train the model\n",
    "trainer_CL.fit(finetuner, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_train_loss</td><td>▇▇▇▇▅█▆▅▆▆▅▆▅▅▄▅▄▄▄▂▃▄▄▃▃▄▃▃▃▄▃▃▃▃▂▂▂▂▁▁</td></tr><tr><td>epoch_val_loss</td><td>▁▂▆▇▇▇█▆▇██▇▇▇█▇▆▆▅▆▆▆▆▄▆▇▇▇▅▅▆▆▆▆▇▆▅▅▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_train_loss</td><td>4.12714</td></tr><tr><td>epoch_val_loss</td><td>4.39903</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">from_scratch_features_dataset</strong> at: <a href='https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface/runs/4lry2vr2' target=\"_blank\">https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface/runs/4lry2vr2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240605_211931-4lry2vr2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the contrastive autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation => from_scratch/version_1/BEST_epoch=00.ckpt\n",
      "Initialize an encoder from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 52.24it/s]Test - Epoch 0: Loss => 3.547311782836914\n",
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 51.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation => finetuning/version_1/BEST_epoch=109.ckpt\n",
      "Using device: cpu\n",
      "Using device: cpu\n",
      "Initialized Model on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 45.91it/s]Test - Epoch 0: Loss => 3.6740336418151855\n",
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 45.33it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_dataset = DataFrameApproach4(train_df)\n",
    "val_dataset = DataFrameApproach4(val_df)\n",
    "test_dataset = DataFrameApproach4(test_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "batch = next(iter(test_loader))\n",
    "input_dim = batch[0].shape[-1]\n",
    "\n",
    "base_model_dir = \"saved_models/Approach_4_FeaturesDataset/\"\n",
    "model_to_test_paths = [\n",
    "    \"from_scratch/version_1/BEST_epoch=00.ckpt\",\n",
    "    \"finetuning/version_1/BEST_epoch=109.ckpt\",\n",
    "]\n",
    "\n",
    "\n",
    "best_metric = 1000000000\n",
    "best_model = \"\"\n",
    "for i,model_path_ in enumerate(model_to_test_paths):\n",
    "  version = model_path_\n",
    "  model_path = base_model_dir+model_path_\n",
    "  input_dim = batch[0].shape[-1]\n",
    "  print(f\"Evaluation => {version}\")\n",
    "\n",
    "  if(i==1):\n",
    "    checkpoint_autoencoder = Autoencoder(input_dim=input_dim, batch_size = batch_size,sparsity_factor=0.005,enable_sparsity_loss=False, enable_weight_decay_loss=False, enable_non_negativity_constraint=False, enable_wandb = False, decoder_none=True)\n",
    "    checkpoint_autoencoder.load_state_dict(torch.load(model_path, map_location=checkpoint_model.device)['state_dict'])\n",
    "    checkpoint_autoencoder.requires_grad = False\n",
    "    \n",
    "    checkpoint_model = ConstrastiveLearner(encoder=checkpoint_autoencoder.encoder, enable_wandb=False, input_dim=input_dim)\n",
    "  else:\n",
    "    checkpoint_model = ConstrastiveLearner(input_dim=input_dim, enable_wandb=False)\n",
    "    checkpoint_model.load_state_dict(torch.load(model_path, map_location=checkpoint_model.device)['state_dict'])\n",
    "\n",
    "\n",
    "  trainer = Trainer(accelerator = 'auto', fast_dev_run=False)\n",
    "  trainer.test(checkpoint_model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive + Classifier\n",
    "This is the same of the approach 2, reporting just the projection head 3 which is the one that work better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a mapping utility to go from label to idx and vice versa\n",
    "label2idx= {}\n",
    "idx2label = {}\n",
    "labels_task = dataset.get_dataframe()['labels'].unique()\n",
    "\n",
    "for i in range(len(labels_task)):\n",
    "  label2idx[labels_task[i]] = i\n",
    "  idx2label[str(i)] = labels_task[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierPerTask_Approach4(LightningModule):\n",
    "    def __init__(self, encoder, text_labels, enable_wandb=False, run_name=\"AE_Contrastive+Classifier\"):\n",
    "        super(ClassifierPerTask_Approach4, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.text_labels = text_labels\n",
    "\n",
    "        # HEAD 3\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(encoder.z_dim, 256),\n",
    "            nn.BatchNorm1d(256),  # Batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),  # Batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, len(text_labels))\n",
    "        )\n",
    "\n",
    "\n",
    "        self.train_loss = []\n",
    "        self.train_accuracy = []\n",
    "        self.val_loss = []\n",
    "        self.val_accuracy = []\n",
    "        self.test_loss = []\n",
    "        self.test_accuracy = []\n",
    "\n",
    "        self.enable_wandb = enable_wandb\n",
    "\n",
    "        if self.enable_wandb:\n",
    "          wandb.init(project=\"Project_EAI_BrainComputerInterface\", entity=\"rucci-2053183\", group=\"approach4_classifier\", name=run_name)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.classifier(z)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(torch.float32)\n",
    "        z = self.encoder(inputs)\n",
    "        outputs = self(z)\n",
    "        labels = self.labels2TargetTensor(labels).to(torch.long).to(outputs.device)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = (preds == labels).float().mean()\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('test_accuracy', acc)\n",
    "\n",
    "        self.train_loss.append(loss)\n",
    "        self.train_accuracy.append(acc)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(torch.float32)\n",
    "        z = self.encoder(inputs)\n",
    "        outputs = self(z)\n",
    "        labels = self.labels2TargetTensor(labels).to(torch.long).to(outputs.device)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = (preds == labels).float().mean()\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_accuracy', acc)\n",
    "\n",
    "        self.test_loss.append(loss)\n",
    "        self.test_accuracy.append(acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(torch.float32)\n",
    "        z = self.encoder(inputs)\n",
    "        outputs = self(z)\n",
    "        labels = self.labels2TargetTensor(labels).to(torch.long).to(outputs.device)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = (preds == labels).float().mean()\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_accuracy', acc)\n",
    "\n",
    "        self.val_loss.append(loss)\n",
    "        self.val_accuracy.append(acc)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "      optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "      scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "      return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"train_loss\"}\n",
    "\n",
    "    def labels2TargetTensor(self, labels):\n",
    "      target = []\n",
    "      for item in labels:\n",
    "        target.append(label2idx[item])\n",
    "\n",
    "      return torch.Tensor(target)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        train_loss = torch.stack([x for x in self.train_loss]).mean()\n",
    "        train_acc = torch.stack([x for x in self.train_accuracy]).mean()\n",
    "\n",
    "        # Print the training loss\n",
    "        print_log = f'Training - Epoch {self.current_epoch}: Loss => {train_loss.item()} ACCURACY => {train_acc}'\n",
    "\n",
    "        self.train_loss.clear()\n",
    "        self.train_accuracy.clear()\n",
    "\n",
    "        if self.enable_wandb:\n",
    "            # Log mean training loss\n",
    "            wandb.log({\"epoch_train_loss\": train_loss, \"epoch_train_accuracy\": train_acc})\n",
    "\n",
    "        print(print_log)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        test_loss = torch.stack([x for x in self.test_loss]).mean()\n",
    "        test_acc = torch.stack([x for x in self.test_accuracy]).mean()\n",
    "\n",
    "        # Print the training loss\n",
    "        print_log = f'Test - Epoch {self.current_epoch}: Loss => {test_loss.item()} ACCURACY => {test_acc}'\n",
    "\n",
    "        self.test_loss.clear()\n",
    "        self.test_accuracy.clear()\n",
    "\n",
    "        if self.enable_wandb:\n",
    "            # Log mean test loss and accuracy\n",
    "            wandb.log({\"epoch_test_loss\": test_loss, \"epoch_test_accuracy\": test_acc})\n",
    "\n",
    "        print(print_log)\n",
    "\n",
    "        self.test_acc = test_acc\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_loss = torch.stack([x for x in self.val_loss]).mean()\n",
    "        val_acc = torch.stack([x for x in self.val_accuracy]).mean()\n",
    "\n",
    "        # Print the training loss\n",
    "        print_log = f'Validation - Epoch {self.current_epoch}: Loss => {val_loss.item()} ACCURACY => {val_acc}'\n",
    "\n",
    "        self.val_loss.clear()\n",
    "        self.val_accuracy.clear()\n",
    "        self.log(\"epoch_val_accuracy\", val_acc)\n",
    "        if self.enable_wandb:\n",
    "            # Log mean validation loss and accuracy\n",
    "            wandb.log({\"epoch_val_loss\": val_loss, \"epoch_val_accuracy\": val_acc})\n",
    "            wandb.log({\"epoch\": self.current_epoch})\n",
    "\n",
    "        print(print_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier using the contrastive pretrained autoencoder\n",
    "batch_size = 256\n",
    "selected_columns = [17,18,19,52,53,54]\n",
    "train_dataset = DataFrameApproach4(train_df)\n",
    "val_dataset = DataFrameApproach4(val_df)\n",
    "test_dataset = DataFrameApproach4(test_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Using device: cpu\n",
      "Initialized Model on cpu\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      9\u001b[0m checkpoint_autoencoder \u001b[38;5;241m=\u001b[39m Autoencoder(input_dim\u001b[38;5;241m=\u001b[39minput_dim, batch_size \u001b[38;5;241m=\u001b[39m batch_size,sparsity_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.005\u001b[39m,enable_sparsity_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, enable_weight_decay_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, enable_non_negativity_constraint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, enable_wandb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, decoder_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 10\u001b[0m checkpoint_autoencoder\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[43mmodel_path\u001b[49m, map_location\u001b[38;5;241m=\u001b[39mcheckpoint_model\u001b[38;5;241m.\u001b[39mdevice)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     11\u001b[0m checkpoint_autoencoder\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     14\u001b[0m checkpoint_model \u001b[38;5;241m=\u001b[39m ConstrastiveLearner(encoder\u001b[38;5;241m=\u001b[39mcheckpoint_autoencoder\u001b[38;5;241m.\u001b[39mencoder)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_path' is not defined"
     ]
    }
   ],
   "source": [
    "# Import the best contrastive AE\n",
    "base_model_dir = \"saved_models/Approach_4_FeaturesDataset/\"\n",
    "best_model_path = base_model_dir+\"from_scratch/version_1/BEST_epoch=00.ckpt\",\n",
    "\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "input_dim = batch[0].shape[-1]\n",
    "\n",
    "checkpoint_autoencoder = Autoencoder(input_dim=input_dim, batch_size = batch_size,sparsity_factor=0.005,enable_sparsity_loss=False, enable_weight_decay_loss=False, enable_non_negativity_constraint=False, enable_wandb = False, decoder_none=True)\n",
    "checkpoint_autoencoder.load_state_dict(torch.load(model_path, map_location=checkpoint_model.device)['state_dict'])\n",
    "checkpoint_autoencoder.requires_grad = False\n",
    "\n",
    "\n",
    "checkpoint_model = ConstrastiveLearner(encoder=checkpoint_autoencoder.encoder)\n",
    "\n",
    "# Initialize contrastive module for training\n",
    "# Initialize the Classifier Module for training\n",
    "encoder = checkpoint_model.encoder\n",
    "encoder.z_dim = 128\n",
    "classifier = ClassifierPerTask_Approach4(encoder, labels_task, enable_wandb=True, run_name=\"AE_Contrastive+Classifier\")\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"epoch_val_accuracy\", min_delta=0.00, patience=30, verbose=True, mode=\"max\", check_on_train_epoch_end=False)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "     monitor='epoch_val_accuracy',\n",
    "     dirpath=\"saved_models/Approach_4_FeaturesDataset/classifier/\",\n",
    "     filename='approach2-epoch{epoch:02d}',\n",
    "     auto_insert_metric_name=True,\n",
    "     mode=\"max\",\n",
    "     save_top_k=1,\n",
    "     verbose=True\n",
    ")\n",
    "\n",
    "trainer_classifier = Trainer(max_epochs=100, default_root_dir=\"saved_models/Approach_4_FeaturesDataset/classifier/\", callbacks=[early_stop,checkpoint_callback],fast_dev_run=False)\n",
    "trainer_classifier.fit(classifier, train_loader, val_loader)\n",
    "\n",
    "# Evaluate\n",
    "trainer.test(classifier, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_test_accuracy</td><td>▁</td></tr><tr><td>epoch_test_loss</td><td>▁</td></tr><tr><td>epoch_train_accuracy</td><td>▁▆▇▇▇█▇████████▇███████▇████████████████</td></tr><tr><td>epoch_train_loss</td><td>█▃▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_test_accuracy</td><td>0.64062</td></tr><tr><td>epoch_test_loss</td><td>1.12085</td></tr><tr><td>epoch_train_accuracy</td><td>0.93281</td></tr><tr><td>epoch_train_loss</td><td>0.20415</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">AE_Contrastive+Classifier</strong> at: <a href='https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface/runs/4qqysgou' target=\"_blank\">https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface/runs/4qqysgou</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240604_224527-4qqysgou/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = \"saved_models/Approach_4_FeaturesDataset/classifier/ae_contrastive_classifier.ckpt\"\n",
    "# torch.save(classifier.state_dict(), model_path)\n",
    "# Use lightning api to save the model\n",
    "trainer_classifier.save_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to test => 2\n",
      "['saved_models/Approach_4_FeaturesDataset/classifier/ae_contrastive_classifier.ckpt', 'saved_models/Approach_4_FeaturesDataset/classifier/ae_contrastive_classifier_li.ckpt']\n",
      "Evaluation => saved_models/Approach_4_FeaturesDataset/classifier/ae_contrastive_classifier.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.09it/s]Test - Epoch 0: Loss => 1.120847225189209 ACCURACY => 0.640625\n",
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy              0.640625\n",
      "        test_loss            1.120847225189209\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation => saved_models/Approach_4_FeaturesDataset/classifier/ae_contrastive_classifier_li.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 25.10it/s]Test - Epoch 0: Loss => 1.120847225189209 ACCURACY => 0.640625\n",
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy              0.640625\n",
      "        test_loss            1.120847225189209\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier \n",
    "batch_size = 256\n",
    "train_dataset = DataFrameApproach4(train_df)\n",
    "val_dataset = DataFrameApproach4(val_df)\n",
    "test_dataset = DataFrameApproach4(test_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "batch = next(iter(train_loader))\n",
    "input_dim = batch[0].shape[-1]\n",
    "\n",
    "base_model_dir = \"saved_models/Approach_4_FeaturesDataset/classifier\"\n",
    "\n",
    "# Add to the list the models .ckpt from the directory /saved_models/Approach_1/selected_task/classifier/\n",
    "model_to_test_paths=[]\n",
    "for root, dirs, files in os.walk(base_model_dir):\n",
    "  for file in files:\n",
    "    if file.endswith(\".ckpt\"):\n",
    "      model_to_test_paths.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"Models to test => {len(model_to_test_paths)}\")\n",
    "print(model_to_test_paths)\n",
    "\n",
    "best_metric = 0\n",
    "best_model = \"\"\n",
    "for model_path_ in model_to_test_paths:\n",
    "  model_path = model_path_\n",
    "  input_dim = batch[0].shape[-1]\n",
    "  version = model_path\n",
    "\n",
    "  checkpoint_model = ClassifierPerTask_Approach4.load_from_checkpoint(model_path, enable_wandb=False)\n",
    "\n",
    "  trainer = Trainer(accelerator = 'auto', fast_dev_run=False)\n",
    "  print(f\"Evaluation => {version}\")\n",
    "  trainer.test(checkpoint_model, dataloaders=test_loader)\n",
    "\n",
    "  if(checkpoint_model.test_acc > best_metric):\n",
    "    best_metric = checkpoint_model.test_acc\n",
    "    best_model = version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".2f\", cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Import the best Classifier model\n",
    "model_path = best_model\n",
    "input_dim = batch[0].shape[-1]\n",
    "checkpoint_model = ClassifierPerTask_Approach4.load_from_checkpoint(model_path, enable_wandb=False)\n",
    "\n",
    "checkpoint_model.eval()\n",
    "\n",
    "# Get the predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for batch in test_loader:\n",
    "    inputs, labels = batch\n",
    "    inputs = inputs.to(torch.float32)\n",
    "    z = checkpoint_model.encoder(inputs)\n",
    "    outputs = checkpoint_model(z)\n",
    "    preds = torch.argmax(outputs, dim=1)\n",
    "    y_true.extend(labels)\n",
    "    y_pred.extend(preds)\n",
    "\n",
    "y_true = [label2idx[item] for item in y_true]\n",
    "y_pred = [item.item() for item in y_pred]\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred, labels_task, \"Confusion Matrix - General Model Constr.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive + Meta Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a mapping utility to go from label to idx and vice versa\n",
    "label2idx= {}\n",
    "idx2label = {}\n",
    "labels_task = dataset.get_dataframe()['labels'].unique()\n",
    "\n",
    "for i in range(len(labels_task)):\n",
    "  label2idx[labels_task[i]] = i\n",
    "  idx2label[str(i)] = labels_task[i]\n",
    "\n",
    "def compute_prototypes(support, labels, fallback_prototypes, missing_labels=None):\n",
    "    classes = torch.unique(labels)\n",
    "    # Concatenate the missing labels to the classes and sort them\n",
    "    if missing_labels is not None:\n",
    "        classes = torch.cat((classes, torch.tensor(missing_labels)))\n",
    "        classes = torch.sort(classes)[0]\n",
    "\n",
    "    prototypes = torch.zeros(\n",
    "        classes.size(0),\n",
    "        *support.shape[1:],\n",
    "        device=support.device,\n",
    "        dtype=support.dtype,\n",
    "    )\n",
    "    for i, cls in enumerate(classes):\n",
    "        # First you check if cls exist in the labels\n",
    "        if cls in labels:\n",
    "            embeddings = support[labels == cls]\n",
    "            prototypes[i].add_(embeddings.mean(dim=0))\n",
    "        else:\n",
    "            # RETIREVE THE MISSING CLASS FROM THE PRECOMPUTED PROTOTYPES\n",
    "            # embeddings = fallback_prototypes[ cls ]\n",
    "            # print(f\"{cls} not found in the batch, using precomputed prototype of shape {embeddings.shape}\")\n",
    "            embeddings = torch.zeros(support.shape[1])\n",
    "            prototypes[i].add_(embeddings)\n",
    "\n",
    "            prototypes[i].add_(embeddings)\n",
    "\n",
    "    return prototypes #(classes, h_dim)\n",
    "\n",
    "def accuracy(preds, targets):\n",
    "    \"\"\"Computes accuracy\"\"\"\n",
    "    acc = (preds.argmax(dim=1).long() == targets.long()).sum().float()\n",
    "    return acc / preds.size(0)\n",
    "\n",
    "class PrototypicalClassifier(torch.nn.Module):\n",
    "    def __init__( self,support=None,labels=None,fallback_prototypes=None, distance=\"euclidean\",normalize=False):\n",
    "      super(PrototypicalClassifier, self).__init__()\n",
    "      self.distance_metric = distance\n",
    "      self.normalize = normalize\n",
    "\n",
    "      # Select compute_prototypes function\n",
    "      self._compute_prototypes = compute_prototypes\n",
    "\n",
    "      # Assign distance function\n",
    "      if distance == \"euclidean\":\n",
    "        print(\"Using euclidean distance as distance metric\")\n",
    "        self.distance = PrototypicalClassifier.euclidean_distance\n",
    "      elif distance == \"cosine\":\n",
    "        print(\"Using cosine distance as distance metric\")\n",
    "        self.distance = PrototypicalClassifier.cosine_distance\n",
    "        self.normalize = True\n",
    "      else:\n",
    "        print(\"Using custom distance function as distance metric\")\n",
    "        self.distance = distance\n",
    "\n",
    "      # Compute prototypes\n",
    "      self.prototypes = None\n",
    "      if support is not None and labels is not None:\n",
    "          self.fit_(support, labels)\n",
    "      if fallback_prototypes is not None:\n",
    "          self.fallback_prototypes = fallback_prototypes # We set the precomputed prototypes as fallback: when a batch doesn't contain a class, we use the precomputed prototype\n",
    "          print(f\"INFO: Using precomputed prototypes of shape {self.fallback_prototypes.shape}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def euclidean_distance(prototypes, queries):\n",
    "      '''\n",
    "      - prototype is the tensor => [n_prot , hidden_dim] that contains the mean tensor for (presumibly) each class\n",
    "      - queries are the samples that have to be classified => [bs, hidden_dim]\n",
    "      '''\n",
    "      n = prototypes.size(0)\n",
    "      m = queries.size(0)\n",
    "      # The numb_of_protototypes represents the number of classes that have been selected in the current generation of prototypes\n",
    "      prototypes = prototypes.unsqueeze(0).expand(m, n, -1) #[ bs, numb_of_protototypes, h_dim]\n",
    "      queries = queries.unsqueeze(1).expand(m, n, -1) #[ bs, numb_of_protototypes, h_dim]\n",
    "      distance = (prototypes - queries).pow(2).sum(dim=-1)\n",
    "      # print(f\"Distance shape => {distance.shape} , TENSOR => {distance}\")\n",
    "\n",
    "      return distance\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def cosine_distance(prototypes, queries):\n",
    "        # Assumes prototypes and queries are normalized\n",
    "        return -queries @ prototypes.t()\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(x, epsilon=1e-8):\n",
    "        x = x / (x.norm(p=2, dim=-1, keepdim=True) + epsilon)\n",
    "        return x\n",
    "\n",
    "    def fit_(self, support, labels, missing_labels=None):\n",
    "        \"\"\"\n",
    "        **Description**\n",
    "\n",
    "        Computes and updates the prototypes given support embeddings and\n",
    "        corresponding labels.\n",
    "\n",
    "        **Arguments**\n",
    "        missing_labels: list of missing labels (might be None if all labels are present and it is possible to compute the prototypes)\n",
    "        \"\"\"\n",
    "        # TODO: Make a differentiable version? (For Proto-MAML style algorithms)\n",
    "\n",
    "        # Compute new prototypes\n",
    "        prototypes = self._compute_prototypes(support, labels, self.fallback_prototypes, missing_labels)\n",
    "\n",
    "        # Normalize if necessary\n",
    "        if self.normalize:\n",
    "            prototypes = PrototypicalClassifier.normalize(prototypes)\n",
    "\n",
    "        # Assign prototypes and return them\n",
    "        self.prototypes = prototypes\n",
    "        return prototypes\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert (\n",
    "            self.prototypes is not None\n",
    "        ), \"Prototypes not computed, use compute_prototypes(support, labels)\"\n",
    "        if self.normalize:\n",
    "            x = PrototypicalClassifier.normalize(x)\n",
    "        return -self.distance(self.prototypes, x)\n",
    "\n",
    "class PrototypicalNetwork(LightningModule):\n",
    "    # https://github.com/learnables/learn2learn/blob/master/learn2learn/algorithms/lightning/lightning_protonet.py#L97\n",
    "    # https://github.com/learnables/learn2learn/blob/master/learn2learn/nn/protonet.py#L57\n",
    "    # https://github.com/learnables/learn2learn/blob/master/learn2learn/algorithms/lightning/lightning_episodic_module.py\n",
    "    def __init__(self, encoder, text_labels, train_dataset_split, distance_metric = \"euclidean\",run_name =\"run_1\", enable_wandb=False):\n",
    "      super(PrototypicalNetwork, self).__init__()\n",
    "      self.save_hyperparameters()\n",
    "\n",
    "      self.encoder = encoder\n",
    "      self.text_labels = text_labels\n",
    "      self.idx_labels = [label2idx[label] for label in text_labels]\n",
    "      self.train_dataset_split = train_dataset_split # Create an internal access to the train split\n",
    "\n",
    "      self.train_loss = []\n",
    "      self.train_accuracy = []\n",
    "      self.val_loss = []\n",
    "      self.val_accuracy = []\n",
    "      self.test_loss = []\n",
    "      self.test_accuracy = []\n",
    "      self.best_val_acc = 0.0\n",
    "\n",
    "      self.distance_metric = distance_metric\n",
    "      # Precompute the prototypes to ensure that exist one prototype for each class\n",
    "      self.classifier = PrototypicalClassifier(fallback_prototypes=self.precompute_prototypes(), distance=self.distance_metric)\n",
    "      self.lr = 0.001\n",
    "      self.scheduler_step = 20\n",
    "      self.scheduler_decay = 1.0\n",
    "\n",
    "      self.enable_wandb = enable_wandb\n",
    "      self.loss = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "      self.run_name = run_name\n",
    "\n",
    "      if self.enable_wandb:\n",
    "        wandb.init(project=\"Project_EAI_BrainComputerInterface\", entity=\"rucci-2053183\", group=\"approach3\",name=run_name)\n",
    "\n",
    "    def precompute_prototypes(self):\n",
    "      # For each class in the text_labels, select 10 random samples from the train_dataset_split with the corresponding label\n",
    "      # make those samples pass through the encoder and compute the mean of the embeddings\n",
    "      # return the prototypes in the form #[classes, h_dim]\n",
    "      # Just consider that the train_dataset_split contains the samples as a tuple (data, label)\n",
    "      prototypes = []\n",
    "      for label in self.text_labels:\n",
    "        samples = [sample[0] for sample in self.train_dataset_split if sample[1] == label]\n",
    "        samples = [sample.to(torch.float32) for sample in samples]\n",
    "        samples = torch.stack(samples)\n",
    "        embeddings = self.encoder(samples)\n",
    "        # embeddings do not require the gradient and they shouldn't be in the computation graph\n",
    "        embeddings = embeddings.detach()\n",
    "        prototypes.append(embeddings.mean(dim=0))\n",
    "\n",
    "      return torch.stack(prototypes)\n",
    "\n",
    "    def forward(self, z):\n",
    "      logits = self.classifier(z)\n",
    "      return logits\n",
    "\n",
    "    def labels2TargetTensor(self, labels):\n",
    "      target = []\n",
    "      for item in labels:\n",
    "        target.append(label2idx[item])\n",
    "\n",
    "      return torch.Tensor(target)\n",
    "\n",
    "    def get_count_class_samples(self,labels):\n",
    "      classes = torch.unique(labels)\n",
    "      class_samples = {}\n",
    "      for cls in classes:\n",
    "        num_samples = torch.sum(labels == cls).item()\n",
    "        class_samples[cls.item()] = num_samples\n",
    "\n",
    "      # Find the class with the minimum number of samples\n",
    "      min_samples_class = min(class_samples, key=class_samples.get)\n",
    "\n",
    "      # Convert the min_samples_class to a dictionary with the label as the key\n",
    "      min_samples_class_dict = {min_samples_class: class_samples[min_samples_class]}\n",
    "\n",
    "      return class_samples, min_samples_class_dict\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "      data, labels = batch # (bs,input_dim)\n",
    "      labels = self.labels2TargetTensor(labels).to(torch.long)\n",
    "      data = data.to(torch.float32)\n",
    "\n",
    "      batch_stats, min_samples_class = self.get_count_class_samples(labels)\n",
    "\n",
    "\n",
    "      # Sort data samples by labels\n",
    "      sort = torch.sort(labels)\n",
    "      data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "      labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "\n",
    "\n",
    "      # Initialize support indices\n",
    "      support_indices = np.zeros(data.size(0), dtype=bool) # (bs, true when the sample is in the support set, false when is a query sample)\n",
    "\n",
    "      # for each class in the batch, select the first n random samples as support set for that class and the rest as query, and report that in the support_indices\n",
    "      for _cls in list(batch_stats.keys()):\n",
    "        sample_for_class = batch_stats[_cls]\n",
    "        if sample_for_class > 1:\n",
    "          n =  random.randint(1, int(sample_for_class * 0.3)+1) # Randomly select the first n samples as support set (n is minimum 1 and maximum the 10% of the sample_for_clas)\n",
    "          class_indices = (labels == _cls).nonzero()  # Indices of samples belonging to the current class\n",
    "          support_indices[class_indices[:n]] = True  # Mark the first 'n' elements for the current class as support\n",
    "\n",
    "\n",
    "      # Compute support and query embeddings\n",
    "      embeddings = self.encoder(data) # [bs, encoder.z_dim]\n",
    "\n",
    "      # Select the support and query samples from the embeddings\n",
    "      support = embeddings[support_indices]\n",
    "      support_labels = labels[support_indices]\n",
    "\n",
    "      # support_label is in the form of [0,0,0,1,1,1,2,2,2,3,3,3,4,4,4] where each number represents a class;\n",
    "      # Giving that in the variable self.idx_labels we have a list that contains all the classes of the task\n",
    "      # We have to identify which label is missing from the support_label: consider the unique(support_labels), then check that all the labels in self.idx_labels are present in the unique(support_labels)\n",
    "      # If a label is missing, then we have to add it to the unique(support_labels) and create a prototype with the right function\n",
    "      missing_labels = list(set(self.idx_labels) - set(torch.unique(support_labels).tolist()))\n",
    "\n",
    "      if len(missing_labels) > 0:\n",
    "        # Add the missing labels to the support_labels\n",
    "        # support_labels = torch.cat((support_labels, torch.tensor(missing_labels).to(support_labels.device)))\n",
    "        # Compute the prototypes with the new support_labels\n",
    "        self.classifier.fit_(support, support_labels, missing_labels=missing_labels) # a list of missing labels [13, 12, 5]\n",
    "      else:\n",
    "        self.classifier.fit_(support, support_labels)\n",
    "\n",
    "      logits = self.classifier(embeddings)\n",
    "      loss = F.cross_entropy(logits, labels)\n",
    "      acc = accuracy(logits, labels)\n",
    "\n",
    "\n",
    "      self.log('train_loss', loss)\n",
    "      self.train_loss.append(loss)\n",
    "      self.train_accuracy.append(acc)\n",
    "\n",
    "      return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "      train_loss = torch.stack([x for x in self.train_loss]).mean()\n",
    "      train_acc = torch.stack([x for x in self.train_accuracy]).mean()\n",
    "\n",
    "      # Print the training loss\n",
    "      print_log = f'Training - Epoch {self.current_epoch}: Loss => {train_loss.item()} ACCURACY => {train_acc}'\n",
    "\n",
    "      self.train_loss.clear()\n",
    "      self.train_accuracy.clear()\n",
    "\n",
    "      # Every 10 epochs, compute again the fallback_prototypes\n",
    "      if self.current_epoch % 10 == 0:\n",
    "        self.classifier.fallback_prototypes = self.precompute_prototypes()\n",
    "        print(f\"Prototypes recomputed at epoch {self.current_epoch}\")\n",
    "\n",
    "      # Every 20 epochs save in a file the prototypes and call the file with the epoch number\n",
    "      if self.current_epoch % 20 == 0:\n",
    "        # Create a folder to save the prototypes if it doesn't exist MyDrive/ColabNotebooks/EAI_Napoli/saved_models/Approach_3/{self.run_name}/saved_prototypes/\n",
    "        # avoid in any case the error \"Parent directory /content/mydrive/MyDrive/ColabNotebooks/EAI_Napoli/saved_models/Approach_3/run_1/saved_prototypes does not exist.\"\n",
    "        os.makedirs(f\"saved_models/Approach_3_FeaturesDataset/{self.run_name}/saved_prototypes/\", exist_ok=True)\n",
    "\n",
    "        torch.save(self.classifier.fallback_prototypes, f\"saved_models/Approach_3_FeaturesDataset/{self.run_name}/saved_prototypes/prototypes_epoch_{self.current_epoch}.pt\")\n",
    "        print(f\"Prototypes saved at epoch {self.current_epoch}\")\n",
    "\n",
    "      if self.enable_wandb:\n",
    "          # Log mean training loss\n",
    "          wandb.log({\"epoch_train_loss\": train_loss, \"epoch_train_accuracy\": train_acc})\n",
    "\n",
    "      if self.current_epoch % 10 == 0:\n",
    "        print(print_log)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Same logic as the training step\n",
    "        data, labels = batch\n",
    "        labels = self.labels2TargetTensor(labels).to(torch.long)\n",
    "        data = data.to(torch.float32)\n",
    "\n",
    "        batch_stats, min_samples_class = self.get_count_class_samples(labels)\n",
    "\n",
    "        # Sort data samples by labels\n",
    "        sort = torch.sort(labels)\n",
    "        data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "        labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "\n",
    "        # Initialize support indices\n",
    "        support_indices = np.zeros(data.size(0), dtype=bool) # (bs, true when the sample is in the support set, false when is a query sample)\n",
    "\n",
    "        # for each class in the batch, select the first n random samples as support set for that class and the rest as query, and report that in the support_indices\n",
    "        for _cls in list(batch_stats.keys()):\n",
    "          sample_for_class = batch_stats[_cls]\n",
    "          if sample_for_class > 1:\n",
    "            # Randomly select the first n samples as support set (n is minimum 1 and maximum the 10% of the sample_for_clas)\n",
    "            n =  random.randint(1, int(sample_for_class * 0.3)+1)\n",
    "            class_indices = (labels == _cls).nonzero()\n",
    "            support_indices[class_indices[:n]] = True\n",
    "\n",
    "\n",
    "        # Compute support and query embeddings\n",
    "        embeddings = self.encoder(data)\n",
    "\n",
    "        # Select the support and query samples from the embeddings\n",
    "        support = embeddings[support_indices]\n",
    "        support_labels = labels[support_indices]\n",
    "\n",
    "        missing_labels = list(set(self.idx_labels) - set(torch.unique(support_labels).tolist()))\n",
    "\n",
    "        if len(missing_labels) > 0:\n",
    "          # Add the missing labels to the support_labels\n",
    "          # support_labels = torch.cat((support_labels, torch.tensor(missing_labels).to(support_labels.device)))\n",
    "          # Compute the prototypes with the new support_labels\n",
    "          proto = self.classifier.fit_(support, support_labels, missing_labels=missing_labels)\n",
    "        else:\n",
    "          proto = self.classifier.fit_(support, support_labels)\n",
    "\n",
    "        logits = self.classifier(embeddings)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        acc = accuracy(logits, labels)\n",
    "\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_accuracy', acc)\n",
    "        self.val_loss.append(loss)\n",
    "        self.val_accuracy.append(acc)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_loss = torch.stack([x for x in self.val_loss]).mean()\n",
    "        val_acc = torch.stack([x for x in self.val_accuracy]).mean()\n",
    "\n",
    "        # Print the training loss\n",
    "        print_log = f'Validation - Epoch {self.current_epoch}: Loss => {val_loss.item()} ACCURACY => {val_acc}'\n",
    "\n",
    "        self.val_loss.clear()\n",
    "        self.val_accuracy.clear()\n",
    "\n",
    "        self.log('epoch_val_loss', val_loss)\n",
    "        self.log('epoch_val_accuracy', val_acc)\n",
    "\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            # Save the fallback_prototypes\n",
    "            print(f\"Saving new prototypes that yield to the new (VAL) best accuracy: {self.best_val_acc} at epoch {self.current_epoch}\")\n",
    "            os.makedirs(f\"saved_models/Approach_3_FeaturesDataset/{self.run_name}/saved_prototypes/\", exist_ok=True)\n",
    "            torch.save(self.classifier.fallback_prototypes, f\"saved_models/Approach_3_FeaturesDataset/{self.run_name}/saved_prototypes/BEST_prototypes.pt\")\n",
    "\n",
    "        if self.enable_wandb:\n",
    "            # Log mean val loss\n",
    "            wandb.log({\"epoch_val_loss\": val_loss, \"epoch_val_accuracy\": val_acc})\n",
    "\n",
    "        if self.current_epoch % 10 == 0:\n",
    "          print(print_log)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "      # Same logic as the training step\n",
    "      data, labels = batch\n",
    "      labels = self.labels2TargetTensor(labels).to(torch.long)\n",
    "      data = data.to(torch.float32)\n",
    "\n",
    "      batch_stats, min_samples_class = self.get_count_class_samples(labels)\n",
    "\n",
    "      # Sort data samples by labels\n",
    "      sort = torch.sort(labels)\n",
    "      data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "      labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "\n",
    "      # It Is ok to use the same logic of the training and validation step becouse even if i'm using\n",
    "      # the test set samples to create the support set, this is equivalent of using any other set of samples\n",
    "\n",
    "      # Initialize support indices\n",
    "      support_indices = np.zeros(data.size(0), dtype=bool)\n",
    "\n",
    "      for _cls in list(batch_stats.keys()):\n",
    "        sample_for_class = batch_stats[_cls]\n",
    "        if sample_for_class > 1:\n",
    "          n =  random.randint(1, int(sample_for_class * 0.3)+1)\n",
    "          class_indices = (labels == _cls).nonzero()\n",
    "          support_indices[class_indices[:n]] = True\n",
    "\n",
    "      # Compute support and query embeddings\n",
    "      embeddings = self.encoder(data)\n",
    "      # Select the support and query samples from the embeddings\n",
    "      support = embeddings[support_indices]\n",
    "      support_labels = labels[support_indices]\n",
    "\n",
    "      missing_labels = list(set(self.idx_labels) - set(torch.unique(support_labels).tolist()))\n",
    "\n",
    "      if len(missing_labels) > 0:\n",
    "        self.classifier.fit_(support, support_labels, missing_labels=missing_labels)\n",
    "      else:\n",
    "        self.classifier.fit_(support, support_labels)\n",
    "\n",
    "      logits = self.classifier(embeddings)\n",
    "      loss = F.cross_entropy(logits, labels)\n",
    "      acc = accuracy(logits, labels)\n",
    "\n",
    "      self.log('test_loss', loss)\n",
    "      self.test_loss.append(loss)\n",
    "      self.log('test_accuracy', acc)\n",
    "      self.test_accuracy.append(acc)\n",
    "\n",
    "      return loss\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "      test_loss = torch.stack([x for x in self.test_loss]).mean()\n",
    "      test_acc = torch.stack([x for x in self.test_accuracy]).mean()\n",
    "\n",
    "      # Print the training loss\n",
    "      print_log = f'Test - Epoch {self.current_epoch}: Loss => {test_loss.item()} ACCURACY => {test_acc}'\n",
    "\n",
    "      self.test_loss.clear()\n",
    "      self.test_accuracy.clear()\n",
    "\n",
    "      if self.enable_wandb:\n",
    "          # Log mean test loss\n",
    "          wandb.log({\"epoch_test_loss\": test_loss, \"epoch_test_accuracy\": test_acc})\n",
    "\n",
    "      print(print_log)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "      optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "      lr_scheduler = optim.lr_scheduler.StepLR(\n",
    "          optimizer,\n",
    "          step_size=self.scheduler_step,\n",
    "          gamma=self.scheduler_decay,\n",
    "      )\n",
    "      return [optimizer], [lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Using device: cpu\n",
      "Initialized Model on cpu\n",
      "Using euclidean distance as distance metric\n",
      "INFO: Using precomputed prototypes of shape torch.Size([4, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/wandb/run-20240605_212942-q8dxhm3k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface/runs/q8dxhm3k' target=\"_blank\">run_metalearning_ae_feats_dataset</a></strong> to <a href='https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface' target=\"_blank\">https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface/runs/q8dxhm3k' target=\"_blank\">https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface/runs/q8dxhm3k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: saved_models/Approach_4_FeaturesDataset/meta_learning/lightning_logs\n",
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/saved_models/Approach_4_FeaturesDataset/meta_learning exists and is not empty.\n",
      "\n",
      "  | Name       | Type                   | Params\n",
      "------------------------------------------------------\n",
      "0 | encoder    | Encoder                | 51.8 K\n",
      "1 | classifier | PrototypicalClassifier | 0     \n",
      "2 | loss       | CrossEntropyLoss       | 0     \n",
      "------------------------------------------------------\n",
      "51.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "51.8 K    Total params\n",
      "0.207     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:104: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 5/5 [00:00<00:00, 46.44it/s, v_num=0]Prototypes recomputed at epoch 0\n",
      "Prototypes saved at epoch 0\n",
      "Training - Epoch 0: Loss => 27.750696182250977 ACCURACY => 0.37421876192092896\n",
      "Epoch 1:  20%|██        | 1/5 [00:00<00:00, 55.45it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:383: `ModelCheckpoint(monitor='epoch_val_accuracy')` could not find the monitored key in the returned metrics: ['train_loss', 'epoch', 'step']. HINT: Did you call `log('epoch_val_accuracy', value)` in the `LightningModule`?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 5/5 [00:00<00:00, 32.21it/s, v_num=0]Prototypes recomputed at epoch 10\n",
      "Training - Epoch 10: Loss => 12.441949844360352 ACCURACY => 0.4828124940395355\n",
      "Epoch 20: 100%|██████████| 5/5 [00:00<00:00, 53.92it/s, v_num=0]Prototypes recomputed at epoch 20\n",
      "Prototypes saved at epoch 20\n",
      "Training - Epoch 20: Loss => 8.05703353881836 ACCURACY => 0.5015624761581421\n",
      "Epoch 30: 100%|██████████| 5/5 [00:00<00:00, 57.17it/s, v_num=0]Prototypes recomputed at epoch 30\n",
      "Training - Epoch 30: Loss => 13.841728210449219 ACCURACY => 0.4375\n",
      "Epoch 40: 100%|██████████| 5/5 [00:00<00:00, 56.92it/s, v_num=0]Prototypes recomputed at epoch 40\n",
      "Prototypes saved at epoch 40\n",
      "Training - Epoch 40: Loss => 11.197107315063477 ACCURACY => 0.46562498807907104\n",
      "Epoch 50: 100%|██████████| 5/5 [00:00<00:00, 54.10it/s, v_num=0]Prototypes recomputed at epoch 50\n",
      "Training - Epoch 50: Loss => 7.07266092300415 ACCURACY => 0.500781238079071\n",
      "Epoch 60: 100%|██████████| 5/5 [00:00<00:00, 55.04it/s, v_num=0]Prototypes recomputed at epoch 60\n",
      "Prototypes saved at epoch 60\n",
      "Training - Epoch 60: Loss => 9.741500854492188 ACCURACY => 0.5140625238418579\n",
      "Epoch 70: 100%|██████████| 5/5 [00:00<00:00, 51.41it/s, v_num=0]Prototypes recomputed at epoch 70\n",
      "Training - Epoch 70: Loss => 14.574167251586914 ACCURACY => 0.504687488079071\n",
      "Epoch 80: 100%|██████████| 5/5 [00:00<00:00, 43.79it/s, v_num=0]Prototypes recomputed at epoch 80\n",
      "Prototypes saved at epoch 80\n",
      "Training - Epoch 80: Loss => 9.746880531311035 ACCURACY => 0.534375011920929\n",
      "Epoch 90: 100%|██████████| 5/5 [00:00<00:00, 39.46it/s, v_num=0]Prototypes recomputed at epoch 90\n",
      "Training - Epoch 90: Loss => 9.885025024414062 ACCURACY => 0.4906249940395355\n",
      "Epoch 100: 100%|██████████| 5/5 [00:00<00:00, 49.79it/s, v_num=0]Prototypes recomputed at epoch 100\n",
      "Prototypes saved at epoch 100\n",
      "Training - Epoch 100: Loss => 10.470541000366211 ACCURACY => 0.48750001192092896\n",
      "Epoch 110: 100%|██████████| 5/5 [00:00<00:00, 51.52it/s, v_num=0]Prototypes recomputed at epoch 110\n",
      "Training - Epoch 110: Loss => 11.357314109802246 ACCURACY => 0.5101562738418579\n",
      "Epoch 120: 100%|██████████| 5/5 [00:00<00:00, 55.88it/s, v_num=0]Prototypes recomputed at epoch 120\n",
      "Prototypes saved at epoch 120\n",
      "Training - Epoch 120: Loss => 10.436914443969727 ACCURACY => 0.503125011920929\n",
      "Epoch 130: 100%|██████████| 5/5 [00:00<00:00, 54.92it/s, v_num=0]Prototypes recomputed at epoch 130\n",
      "Training - Epoch 130: Loss => 4.692327499389648 ACCURACY => 0.590624988079071\n",
      "Epoch 140: 100%|██████████| 5/5 [00:00<00:00, 52.72it/s, v_num=0]Prototypes recomputed at epoch 140\n",
      "Prototypes saved at epoch 140\n",
      "Training - Epoch 140: Loss => 4.423454284667969 ACCURACY => 0.5882812738418579\n",
      "Epoch 150: 100%|██████████| 5/5 [00:00<00:00, 46.31it/s, v_num=0]Prototypes recomputed at epoch 150\n",
      "Training - Epoch 150: Loss => 8.990903854370117 ACCURACY => 0.547656238079071\n",
      "Epoch 160: 100%|██████████| 5/5 [00:00<00:00, 55.02it/s, v_num=0]Prototypes recomputed at epoch 160\n",
      "Prototypes saved at epoch 160\n",
      "Training - Epoch 160: Loss => 6.718204498291016 ACCURACY => 0.6148437261581421\n",
      "Epoch 170: 100%|██████████| 5/5 [00:00<00:00, 48.27it/s, v_num=0]Prototypes recomputed at epoch 170\n",
      "Training - Epoch 170: Loss => 3.4336647987365723 ACCURACY => 0.614062488079071\n",
      "Epoch 180: 100%|██████████| 5/5 [00:00<00:00, 55.06it/s, v_num=0]Prototypes recomputed at epoch 180\n",
      "Prototypes saved at epoch 180\n",
      "Training - Epoch 180: Loss => 3.7590954303741455 ACCURACY => 0.5882812738418579\n",
      "Epoch 190: 100%|██████████| 5/5 [00:00<00:00, 31.51it/s, v_num=0]Prototypes recomputed at epoch 190\n",
      "Training - Epoch 190: Loss => 4.906673908233643 ACCURACY => 0.5765625238418579\n",
      "Epoch 200: 100%|██████████| 5/5 [00:00<00:00, 41.78it/s, v_num=0]Prototypes recomputed at epoch 200\n",
      "Prototypes saved at epoch 200\n",
      "Training - Epoch 200: Loss => 3.56054425239563 ACCURACY => 0.585156261920929\n",
      "Epoch 210: 100%|██████████| 5/5 [00:00<00:00, 55.04it/s, v_num=0]Prototypes recomputed at epoch 210\n",
      "Training - Epoch 210: Loss => 5.7110795974731445 ACCURACY => 0.553906261920929\n",
      "Epoch 220: 100%|██████████| 5/5 [00:00<00:00, 28.82it/s, v_num=0]Prototypes recomputed at epoch 220\n",
      "Prototypes saved at epoch 220\n",
      "Training - Epoch 220: Loss => 5.00836706161499 ACCURACY => 0.58203125\n",
      "Epoch 230: 100%|██████████| 5/5 [00:00<00:00, 55.64it/s, v_num=0]Prototypes recomputed at epoch 230\n",
      "Training - Epoch 230: Loss => 5.072030544281006 ACCURACY => 0.567187488079071\n",
      "Epoch 240: 100%|██████████| 5/5 [00:00<00:00, 49.37it/s, v_num=0]Prototypes recomputed at epoch 240\n",
      "Prototypes saved at epoch 240\n",
      "Training - Epoch 240: Loss => 2.9874274730682373 ACCURACY => 0.6195312738418579\n",
      "Epoch 250: 100%|██████████| 5/5 [00:00<00:00, 50.78it/s, v_num=0]Prototypes recomputed at epoch 250\n",
      "Training - Epoch 250: Loss => 6.53000020980835 ACCURACY => 0.608593761920929\n",
      "Epoch 260: 100%|██████████| 5/5 [00:00<00:00, 54.92it/s, v_num=0]Prototypes recomputed at epoch 260\n",
      "Prototypes saved at epoch 260\n",
      "Training - Epoch 260: Loss => 8.21148681640625 ACCURACY => 0.5492187738418579\n",
      "Epoch 270: 100%|██████████| 5/5 [00:00<00:00, 51.50it/s, v_num=0]Prototypes recomputed at epoch 270\n",
      "Training - Epoch 270: Loss => 5.371089935302734 ACCURACY => 0.55859375\n",
      "Epoch 280: 100%|██████████| 5/5 [00:00<00:00, 38.72it/s, v_num=0]Prototypes recomputed at epoch 280\n",
      "Prototypes saved at epoch 280\n",
      "Training - Epoch 280: Loss => 5.177790641784668 ACCURACY => 0.5960937738418579\n",
      "Epoch 290: 100%|██████████| 5/5 [00:00<00:00, 51.69it/s, v_num=0]Prototypes recomputed at epoch 290\n",
      "Training - Epoch 290: Loss => 5.319394588470459 ACCURACY => 0.6171875\n",
      "Epoch 300: 100%|██████████| 5/5 [00:00<00:00, 51.58it/s, v_num=0]Prototypes recomputed at epoch 300\n",
      "Prototypes saved at epoch 300\n",
      "Training - Epoch 300: Loss => 2.5504677295684814 ACCURACY => 0.6328125\n",
      "Epoch 310: 100%|██████████| 5/5 [00:00<00:00, 41.44it/s, v_num=0]Prototypes recomputed at epoch 310\n",
      "Training - Epoch 310: Loss => 4.575484275817871 ACCURACY => 0.655468761920929\n",
      "Epoch 320: 100%|██████████| 5/5 [00:00<00:00, 52.39it/s, v_num=0]Prototypes recomputed at epoch 320\n",
      "Prototypes saved at epoch 320\n",
      "Training - Epoch 320: Loss => 3.3326637744903564 ACCURACY => 0.6421874761581421\n",
      "Epoch 330: 100%|██████████| 5/5 [00:00<00:00, 52.37it/s, v_num=0]Prototypes recomputed at epoch 330\n",
      "Training - Epoch 330: Loss => 4.051366329193115 ACCURACY => 0.596875011920929\n",
      "Epoch 340: 100%|██████████| 5/5 [00:00<00:00, 54.57it/s, v_num=0]Prototypes recomputed at epoch 340\n",
      "Prototypes saved at epoch 340\n",
      "Training - Epoch 340: Loss => 2.826263427734375 ACCURACY => 0.571093738079071\n",
      "Epoch 350: 100%|██████████| 5/5 [00:00<00:00, 51.86it/s, v_num=0]Prototypes recomputed at epoch 350\n",
      "Training - Epoch 350: Loss => 1.676897644996643 ACCURACY => 0.6812499761581421\n",
      "Epoch 360: 100%|██████████| 5/5 [00:00<00:00, 54.86it/s, v_num=0]Prototypes recomputed at epoch 360\n",
      "Prototypes saved at epoch 360\n",
      "Training - Epoch 360: Loss => 1.134153127670288 ACCURACY => 0.715624988079071\n",
      "Epoch 370: 100%|██████████| 5/5 [00:00<00:00, 49.82it/s, v_num=0]Prototypes recomputed at epoch 370\n",
      "Training - Epoch 370: Loss => 2.569690227508545 ACCURACY => 0.62890625\n",
      "Epoch 380: 100%|██████████| 5/5 [00:00<00:00, 37.11it/s, v_num=0]Prototypes recomputed at epoch 380\n",
      "Prototypes saved at epoch 380\n",
      "Training - Epoch 380: Loss => 1.9797840118408203 ACCURACY => 0.6078125238418579\n",
      "Epoch 390: 100%|██████████| 5/5 [00:00<00:00, 54.94it/s, v_num=0]Prototypes recomputed at epoch 390\n",
      "Training - Epoch 390: Loss => 2.2066264152526855 ACCURACY => 0.612500011920929\n",
      "Epoch 400: 100%|██████████| 5/5 [00:00<00:00, 55.00it/s, v_num=0]Prototypes recomputed at epoch 400\n",
      "Prototypes saved at epoch 400\n",
      "Training - Epoch 400: Loss => 2.3727645874023438 ACCURACY => 0.586718738079071\n",
      "Epoch 410: 100%|██████████| 5/5 [00:00<00:00, 57.37it/s, v_num=0]Prototypes recomputed at epoch 410\n",
      "Training - Epoch 410: Loss => 3.6481564044952393 ACCURACY => 0.6695312261581421\n",
      "Epoch 420: 100%|██████████| 5/5 [00:00<00:00, 55.60it/s, v_num=0]Prototypes recomputed at epoch 420\n",
      "Prototypes saved at epoch 420\n",
      "Training - Epoch 420: Loss => 1.713019609451294 ACCURACY => 0.664843738079071\n",
      "Epoch 430: 100%|██████████| 5/5 [00:00<00:00, 52.75it/s, v_num=0]Prototypes recomputed at epoch 430\n",
      "Training - Epoch 430: Loss => 1.547590732574463 ACCURACY => 0.66796875\n",
      "Epoch 440: 100%|██████████| 5/5 [00:00<00:00, 49.01it/s, v_num=0]Prototypes recomputed at epoch 440\n",
      "Prototypes saved at epoch 440\n",
      "Training - Epoch 440: Loss => 1.4565984010696411 ACCURACY => 0.672656238079071\n",
      "Epoch 450: 100%|██████████| 5/5 [00:00<00:00, 52.34it/s, v_num=0]Prototypes recomputed at epoch 450\n",
      "Training - Epoch 450: Loss => 1.609045386314392 ACCURACY => 0.67578125\n",
      "Epoch 460: 100%|██████████| 5/5 [00:00<00:00, 19.22it/s, v_num=0]Prototypes recomputed at epoch 460\n",
      "Prototypes saved at epoch 460\n",
      "Training - Epoch 460: Loss => 1.4289273023605347 ACCURACY => 0.6625000238418579\n",
      "Epoch 470: 100%|██████████| 5/5 [00:00<00:00, 42.56it/s, v_num=0]Prototypes recomputed at epoch 470\n",
      "Training - Epoch 470: Loss => 1.1834774017333984 ACCURACY => 0.696093738079071\n",
      "Epoch 480: 100%|██████████| 5/5 [00:00<00:00,  9.41it/s, v_num=0]Prototypes recomputed at epoch 480\n",
      "Prototypes saved at epoch 480\n",
      "Training - Epoch 480: Loss => 0.8808351755142212 ACCURACY => 0.725781261920929\n",
      "Epoch 490: 100%|██████████| 5/5 [00:00<00:00, 16.40it/s, v_num=0]Prototypes recomputed at epoch 490\n",
      "Training - Epoch 490: Loss => 1.2645868062973022 ACCURACY => 0.671875\n",
      "Epoch 500: 100%|██████████| 5/5 [00:00<00:00, 35.15it/s, v_num=0]Prototypes recomputed at epoch 500\n",
      "Prototypes saved at epoch 500\n",
      "Training - Epoch 500: Loss => 2.9085538387298584 ACCURACY => 0.561718761920929\n",
      "Epoch 510: 100%|██████████| 5/5 [00:00<00:00, 51.69it/s, v_num=0]Prototypes recomputed at epoch 510\n",
      "Training - Epoch 510: Loss => 0.9822677373886108 ACCURACY => 0.7085937261581421\n",
      "Epoch 520: 100%|██████████| 5/5 [00:00<00:00, 20.98it/s, v_num=0]Prototypes recomputed at epoch 520\n",
      "Prototypes saved at epoch 520\n",
      "Training - Epoch 520: Loss => 0.932532012462616 ACCURACY => 0.7289062738418579\n",
      "Epoch 530: 100%|██████████| 5/5 [00:00<00:00, 34.79it/s, v_num=0]Prototypes recomputed at epoch 530\n",
      "Training - Epoch 530: Loss => 0.8431159853935242 ACCURACY => 0.734375\n",
      "Epoch 540: 100%|██████████| 5/5 [00:00<00:00, 51.02it/s, v_num=0]Prototypes recomputed at epoch 540\n",
      "Prototypes saved at epoch 540\n",
      "Training - Epoch 540: Loss => 1.288764238357544 ACCURACY => 0.715624988079071\n",
      "Epoch 550: 100%|██████████| 5/5 [00:00<00:00, 53.51it/s, v_num=0]Prototypes recomputed at epoch 550\n",
      "Training - Epoch 550: Loss => 1.8714978694915771 ACCURACY => 0.729687511920929\n",
      "Epoch 560: 100%|██████████| 5/5 [00:00<00:00, 42.25it/s, v_num=0]Prototypes recomputed at epoch 560\n",
      "Prototypes saved at epoch 560\n",
      "Training - Epoch 560: Loss => 1.5670783519744873 ACCURACY => 0.682812511920929\n",
      "Epoch 570: 100%|██████████| 5/5 [00:00<00:00, 37.00it/s, v_num=0]Prototypes recomputed at epoch 570\n",
      "Training - Epoch 570: Loss => 0.9663147926330566 ACCURACY => 0.703906238079071\n",
      "Epoch 580: 100%|██████████| 5/5 [00:00<00:00, 48.03it/s, v_num=0]Prototypes recomputed at epoch 580\n",
      "Prototypes saved at epoch 580\n",
      "Training - Epoch 580: Loss => 1.1386582851409912 ACCURACY => 0.7054687738418579\n",
      "Epoch 590: 100%|██████████| 5/5 [00:00<00:00, 37.44it/s, v_num=0]Prototypes recomputed at epoch 590\n",
      "Training - Epoch 590: Loss => 0.8250061273574829 ACCURACY => 0.7445312738418579\n",
      "Epoch 600: 100%|██████████| 5/5 [00:00<00:00, 25.05it/s, v_num=0]Prototypes recomputed at epoch 600\n",
      "Prototypes saved at epoch 600\n",
      "Training - Epoch 600: Loss => 0.7604498267173767 ACCURACY => 0.729687511920929\n",
      "Epoch 610: 100%|██████████| 5/5 [00:00<00:00, 51.54it/s, v_num=0]Prototypes recomputed at epoch 610\n",
      "Training - Epoch 610: Loss => 0.8426342010498047 ACCURACY => 0.725781261920929\n",
      "Epoch 620: 100%|██████████| 5/5 [00:00<00:00, 19.66it/s, v_num=0]Prototypes recomputed at epoch 620\n",
      "Prototypes saved at epoch 620\n",
      "Training - Epoch 620: Loss => 3.1823830604553223 ACCURACY => 0.6812499761581421\n",
      "Epoch 630: 100%|██████████| 5/5 [00:00<00:00, 39.01it/s, v_num=0]Prototypes recomputed at epoch 630\n",
      "Training - Epoch 630: Loss => 1.1268765926361084 ACCURACY => 0.710156261920929\n",
      "Epoch 640: 100%|██████████| 5/5 [00:00<00:00, 33.51it/s, v_num=0]Prototypes recomputed at epoch 640\n",
      "Prototypes saved at epoch 640\n",
      "Training - Epoch 640: Loss => 0.8937230110168457 ACCURACY => 0.7445312738418579\n",
      "Epoch 650: 100%|██████████| 5/5 [00:00<00:00, 27.39it/s, v_num=0]Prototypes recomputed at epoch 650\n",
      "Training - Epoch 650: Loss => 0.7802900671958923 ACCURACY => 0.758593738079071\n",
      "Epoch 660: 100%|██████████| 5/5 [00:00<00:00, 20.21it/s, v_num=0]Prototypes recomputed at epoch 660\n",
      "Prototypes saved at epoch 660\n",
      "Training - Epoch 660: Loss => 1.0147202014923096 ACCURACY => 0.723437488079071\n",
      "Epoch 670: 100%|██████████| 5/5 [00:00<00:00, 51.22it/s, v_num=0]Prototypes recomputed at epoch 670\n",
      "Training - Epoch 670: Loss => 0.9069158434867859 ACCURACY => 0.72265625\n",
      "Epoch 680: 100%|██████████| 5/5 [00:00<00:00, 36.93it/s, v_num=0]Prototypes recomputed at epoch 680\n",
      "Prototypes saved at epoch 680\n",
      "Training - Epoch 680: Loss => 0.931265652179718 ACCURACY => 0.7132812738418579\n",
      "Epoch 690: 100%|██████████| 5/5 [00:00<00:00, 24.83it/s, v_num=0]Prototypes recomputed at epoch 690\n",
      "Training - Epoch 690: Loss => 0.7916454672813416 ACCURACY => 0.7359374761581421\n",
      "Epoch 700: 100%|██████████| 5/5 [00:00<00:00, 55.00it/s, v_num=0]Prototypes recomputed at epoch 700\n",
      "Prototypes saved at epoch 700\n",
      "Training - Epoch 700: Loss => 0.922886073589325 ACCURACY => 0.7203124761581421\n",
      "Epoch 710: 100%|██████████| 5/5 [00:00<00:00, 45.75it/s, v_num=0]Prototypes recomputed at epoch 710\n",
      "Training - Epoch 710: Loss => 2.618730068206787 ACCURACY => 0.629687488079071\n",
      "Epoch 720: 100%|██████████| 5/5 [00:00<00:00, 38.13it/s, v_num=0]Prototypes recomputed at epoch 720\n",
      "Prototypes saved at epoch 720\n",
      "Training - Epoch 720: Loss => 0.9118552207946777 ACCURACY => 0.733593761920929\n",
      "Epoch 730: 100%|██████████| 5/5 [00:00<00:00, 47.90it/s, v_num=0]Prototypes recomputed at epoch 730\n",
      "Training - Epoch 730: Loss => 0.6638519167900085 ACCURACY => 0.7710937261581421\n",
      "Epoch 740: 100%|██████████| 5/5 [00:00<00:00, 28.48it/s, v_num=0]Prototypes recomputed at epoch 740\n",
      "Prototypes saved at epoch 740\n",
      "Training - Epoch 740: Loss => 0.7750545740127563 ACCURACY => 0.71875\n",
      "Epoch 750: 100%|██████████| 5/5 [00:00<00:00, 52.44it/s, v_num=0]Prototypes recomputed at epoch 750\n",
      "Training - Epoch 750: Loss => 0.8328851461410522 ACCURACY => 0.746874988079071\n",
      "Epoch 760: 100%|██████████| 5/5 [00:00<00:00, 43.36it/s, v_num=0]Prototypes recomputed at epoch 760\n",
      "Prototypes saved at epoch 760\n",
      "Training - Epoch 760: Loss => 0.6166104078292847 ACCURACY => 0.7828124761581421\n",
      "Epoch 770: 100%|██████████| 5/5 [00:00<00:00, 29.67it/s, v_num=0]Prototypes recomputed at epoch 770\n",
      "Training - Epoch 770: Loss => 1.4193460941314697 ACCURACY => 0.7265625\n",
      "Epoch 780: 100%|██████████| 5/5 [00:00<00:00, 25.71it/s, v_num=0]Prototypes recomputed at epoch 780\n",
      "Prototypes saved at epoch 780\n",
      "Training - Epoch 780: Loss => 0.7091177701950073 ACCURACY => 0.7718750238418579\n",
      "Epoch 790: 100%|██████████| 5/5 [00:00<00:00, 55.72it/s, v_num=0]Prototypes recomputed at epoch 790\n",
      "Training - Epoch 790: Loss => 0.4879691004753113 ACCURACY => 0.823437511920929\n",
      "Epoch 800: 100%|██████████| 5/5 [00:00<00:00, 27.78it/s, v_num=0]Prototypes recomputed at epoch 800\n",
      "Prototypes saved at epoch 800\n",
      "Training - Epoch 800: Loss => 1.0325969457626343 ACCURACY => 0.750781238079071\n",
      "Epoch 810: 100%|██████████| 5/5 [00:00<00:00, 35.04it/s, v_num=0]Prototypes recomputed at epoch 810\n",
      "Training - Epoch 810: Loss => 1.1717612743377686 ACCURACY => 0.7328125238418579\n",
      "Epoch 820: 100%|██████████| 5/5 [00:00<00:00, 52.99it/s, v_num=0]Prototypes recomputed at epoch 820\n",
      "Prototypes saved at epoch 820\n",
      "Training - Epoch 820: Loss => 0.6229034066200256 ACCURACY => 0.772656261920929\n",
      "Epoch 830: 100%|██████████| 5/5 [00:00<00:00, 31.53it/s, v_num=0]Prototypes recomputed at epoch 830\n",
      "Training - Epoch 830: Loss => 0.7857494950294495 ACCURACY => 0.765625\n",
      "Epoch 840: 100%|██████████| 5/5 [00:00<00:00, 38.40it/s, v_num=0]Prototypes recomputed at epoch 840\n",
      "Prototypes saved at epoch 840\n",
      "Training - Epoch 840: Loss => 0.5275665521621704 ACCURACY => 0.805468738079071\n",
      "Epoch 850: 100%|██████████| 5/5 [00:00<00:00, 49.41it/s, v_num=0]Prototypes recomputed at epoch 850\n",
      "Training - Epoch 850: Loss => 1.4283121824264526 ACCURACY => 0.75\n",
      "Epoch 860: 100%|██████████| 5/5 [00:00<00:00, 46.16it/s, v_num=0]Prototypes recomputed at epoch 860\n",
      "Prototypes saved at epoch 860\n",
      "Training - Epoch 860: Loss => 0.7593967318534851 ACCURACY => 0.76171875\n",
      "Epoch 870: 100%|██████████| 5/5 [00:00<00:00, 49.81it/s, v_num=0]Prototypes recomputed at epoch 870\n",
      "Training - Epoch 870: Loss => 0.6798092126846313 ACCURACY => 0.7554687261581421\n",
      "Epoch 880: 100%|██████████| 5/5 [00:00<00:00, 14.56it/s, v_num=0]Prototypes recomputed at epoch 880\n",
      "Prototypes saved at epoch 880\n",
      "Training - Epoch 880: Loss => 0.5446977615356445 ACCURACY => 0.803906261920929\n",
      "Epoch 890: 100%|██████████| 5/5 [00:00<00:00, 43.93it/s, v_num=0]Prototypes recomputed at epoch 890\n",
      "Training - Epoch 890: Loss => 0.6370304226875305 ACCURACY => 0.796875\n",
      "Epoch 899: 100%|██████████| 5/5 [00:00<00:00, 51.73it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/Desktop/Sapienza/Materie/EAI_Napoli/Progetto/.conda/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 256. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - Epoch 899: Loss => 1.1331701278686523 ACCURACY => 0.578125\n",
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:04<00:00,  0.23it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy              0.578125\n",
      "        test_loss           1.1331701278686523\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.1331701278686523, 'test_accuracy': 0.578125}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier using the contrastive pretrained autoencoder\n",
    "batch_size = 256\n",
    "train_dataset = DataFrameApproach4(train_df)\n",
    "val_dataset = DataFrameApproach4(val_df)\n",
    "test_dataset = DataFrameApproach4(test_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "input_dim = batch[0].shape[-1]\n",
    "\n",
    "#Initialize the autoencoder from scratch becouse it didnt converge the from scratch training\n",
    "checkpoint_autoencoder = Autoencoder(input_dim=input_dim, batch_size=batch_size, sparsity_factor=0.005, enable_sparsity_loss=False, enable_weight_decay_loss=False, enable_non_negativity_constraint=False, enable_wandb=False, decoder_none=True)\n",
    "\n",
    "\n",
    "checkpoint_model = ConstrastiveLearner(encoder=checkpoint_autoencoder.encoder, enable_wandb=False, input_dim=input_dim)\n",
    "\n",
    "encoder = checkpoint_autoencoder.encoder  # Fixed reference to checkpoint_autoencoder\n",
    "encoder.z_dim = 128\n",
    "classifier = PrototypicalNetwork(encoder, dataset_labels, train_dataset, distance_metric=\"euclidean\", run_name=\"run_metalearning_ae_feats_dataset\", enable_wandb=True)\n",
    "\n",
    "# 300 Epochs patience early stopping with min delta of 0.001 over the epoch_val_accuracy\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='epoch_val_accuracy',\n",
    "    min_delta=0.001,\n",
    "    patience=300,\n",
    "    verbose=True,\n",
    "    mode='max',\n",
    "    check_on_train_epoch_end=False\n",
    ")\n",
    "\n",
    "# Model checkpoint callback to save the best model\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='epoch_val_accuracy',\n",
    "    dirpath=\"saved_models/Approach_4_FeaturesDataset/meta_learning\",\n",
    "    filename=\"BEST_{epoch}\",\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "trainer_classifier = Trainer(max_epochs=10000, default_root_dir=\"saved_models/Approach_4_FeaturesDataset/meta_learning\", callbacks=[early_stop_callback, checkpoint_callback], fast_dev_run=False)\n",
    "trainer_classifier.fit(classifier, train_loader, val_loader)\n",
    "\n",
    "# Evaluate\n",
    "trainer_classifier.test(classifier, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_test_accuracy</td><td>▁</td></tr><tr><td>epoch_test_loss</td><td>▁</td></tr><tr><td>epoch_train_accuracy</td><td>▁▂▃▃▂▃▅▃▃▅▄▅▅▅▄▅▄▅▅▆▄▆▆▅▆▇▇▆▆▇▆▆▆▇▇███▇█</td></tr><tr><td>epoch_train_loss</td><td>█▇▆▇▄▅▄▄█▂▃▃▃▂▂▂▂▃▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_test_accuracy</td><td>0.57812</td></tr><tr><td>epoch_test_loss</td><td>1.13317</td></tr><tr><td>epoch_train_accuracy</td><td>0.77734</td></tr><tr><td>epoch_train_loss</td><td>0.66275</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_metalearning_ae_feats_dataset</strong> at: <a href='https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface/runs/q8dxhm3k' target=\"_blank\">https://wandb.ai/rucci-2053183/Project_EAI_BrainComputerInterface/runs/q8dxhm3k</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240605_212942-q8dxhm3k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
